{"paper_id": "1bdf3c4613936ba022e38f126f620c770e18b9ca", "metadata": {"title": "Deep Sentiment Classification and Topic Discovery on Novel Coronavirus or COVID-19 Online Discussions: NLP Using LSTM Recurrent Neural Network Approach", "authors": [{"first": "Hamed", "middle": [], "last": "Jelodar", "suffix": "", "affiliation": {"laboratory": "", "institution": "Nanjing University of Science and Technology", "location": {"postCode": "210094", "settlement": "Nanjing", "country": "China"}}, "email": "jelodar@njust.edu.cn"}, {"first": "Yongli", "middle": [], "last": "Wang", "suffix": "", "affiliation": {"laboratory": "", "institution": "Nanjing University of Science and Technology", "location": {"postCode": "210094", "settlement": "Nanjing", "country": "China"}}, "email": "yongliwang@njust.edu.cn"}, {"first": "Rita", "middle": [], "last": "Orji", "suffix": "", "affiliation": {"laboratory": "", "institution": "Dalhousie University", "location": {"settlement": "Halifax", "region": "NS", "country": "Canada"}}, "email": "rita.orji@dal.ca"}]}, "abstract": [{"text": "Internet forums and public social media, such as online healthcare forums, provide a convenient channel for users (people/patients) concerned about health issues to discuss and share information with each other. In late December 2019, an outbreak of a novel coronavirus (infection from which results in the disease named COVID-19) was reported, and, due to the rapid spread of the virus in other parts of the world, the World Health Organization declared a state of emergency. In this paper, we used automated extraction of COVID-19-related discussions from social media and a natural language process (NLP) method based on topic modeling to uncover various issues related to COVID-19 from public opinions. Moreover, we also investigate how to use LSTM recurrent neural network for sentiment classification of COVID-19 comments. Our findings shed light on the importance of using public opinions and suitable computational techniques to understand issues surrounding COVID-19 and to guide related decision-making. 2 Hamed Jelodar 1 et al.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "Online forums, such as reddit, enable healthcare service providers to collect people/patient experience data. These forums are valuable sources of people's opinions, which can be examined for knowledge discovery and user behaviour analysis. In a typical sub-reddit forum, a user can use keywords and apply search tools to identify relevant questions/answers or comments sent in by other reddit users. Moreover, a registered user can create a topic or post a new question to start discussions with other community members. In answering the questions, users reflect and share their views and experiences. In these online forums, people may express their positive and negative comments, or share questions, problems, and needs related to health issues. By analysing these comments, we can identify valuable recommendations for improving health-services and understanding the problems of users.", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "In late December 2019, the outbreak of a novel coronavirus causing COVID-19 was reported [1] . Due to the rapid spread of the virus, the World Health Organization declared a state of emergency. In this paper, we focused on analysing COVID-19related comments to detect sentiment and semantic ideas relating to COVID-19 based on the public opinions of people on reddit. Specifically, we used automated extraction of COVID-19-related discussions from social media and a natural language process (NLP) method based on topic modeling to uncover various issues related to COVID-19 from public opinions. The main contributions of this paper are as follows:", "cite_spans": [{"start": 89, "end": 92, "text": "[1]", "ref_id": "BIBREF0"}], "ref_spans": [], "section": "Introduction"}, {"text": "-We present a systematic framework based on NLP that is capable of extracting meaningful topics from COVID-19-related comments on reddit. -We propose a deep learning model based on Long Short-Term Memory (LSTM) for sentiment classification of COVID-19-related comments, which produces better results compared with several other well-known machine-learning methods. -We detect and uncover meaningful topics that are being discussed on COVID-19-related issues on reddit, as primary research. -We calculate the polarity of the COVID-19 comments related to sentiment and opinion analysis from 10 sub-reddits.", "cite_spans": [{"start": 204, "end": 210, "text": "(LSTM)", "ref_id": null}], "ref_spans": [], "section": "Introduction"}, {"text": "Our findings shed light on the importance of using public opinions and suitable computational techniques to understand issues surrounding COVID-19 and to guide related decision-making. Overall, the paper is structured as follows. First, we provide a brief introduction to online healthcare forums. Discussion of COVID-19-related issues and some similar works is provided in section 2. In section 3, we describe the data pre-processing methods adopted in our research, and the NLP and deeplearning methods applied to the COVID-19 comments database. Next, we present the results and discussion. Finally, we conclude and discuss future works based on NLP approaches for analysing the online community in relation to the topic of COVID-19.", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "Machine and deep-learning approaches based on sentiment and semantic analysis are popular methods of analysing text-content in online health forums. Many researchers have used these methods on social media such as Twitter, reddit [2] - [7] , and health information websites [8] , [9] . For example; Halder and colleagues [10] focused on exploring linguistic changes to analyse the emotional status of a user over time.", "cite_spans": [{"start": 236, "end": 239, "text": "[7]", "ref_id": "BIBREF6"}, {"start": 274, "end": 277, "text": "[8]", "ref_id": "BIBREF7"}, {"start": 280, "end": 283, "text": "[9]", "ref_id": "BIBREF8"}, {"start": 321, "end": 325, "text": "[10]", "ref_id": "BIBREF9"}], "ref_spans": [], "section": "Related Work"}, {"text": "They utilized a recurrent neural network (RNN) to investigate user-content in a huge dataset from the mental-health online forums of healthboards.com. McRoy and colleagues [11] investigated ways to automate identification of the information needs of breast cancer survivors based on user-posts of online health forums. Chakravorti and colleagues [12] extracted topics based on various health issues discussed in online forums by evaluating user posts of several subreddits (e.g., r/Depression, r/Anxiety) from 2012 to 2018. VanDam and colleagues [13] presented a classification approach for identifying clinic-related posts in online health communities. For that dataset, the authors collected 9576 thread-initiating posts from WebMD, which is a health information website.", "cite_spans": [{"start": 172, "end": 176, "text": "[11]", "ref_id": "BIBREF10"}, {"start": 346, "end": 350, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 546, "end": 550, "text": "[13]", "ref_id": "BIBREF12"}], "ref_spans": [], "section": "Related Work"}, {"text": "The COVID-19-related comments from an online healthcare-oriented group can be considered potentially useful for extracting meaningful topics to better understand the opinions and highlight discussions of people/users and improve health strategies. Although there are similar works regarding various health issues in online forums, to the best of our knowledge, this is the first study to utilize NLP methods to evaluate COVID-19-related comments from sub-reddit forums. We propose utilizing the NLP technique based on topic modeling algorithms to automatically extract meaningful topics and design a deep-learning model based on LSTM RNN for sentiment classification on COVID-19 comments and to understand the positive or negative opinions of people as they relate to COVID-19 issues to inform relevant decision-making.", "cite_spans": [], "ref_spans": [], "section": "Related Work"}, {"text": "This section clarifies the methods used to investigate the main contributions to this study, which proposes the use of an unsupervised topic model, with a collaborative deep-learning model based on LSTN RNN to analyse COVID-19-related comments from sub-reddits. The developed framework, shown in Fig. 2 , uses sentiment and semantic analysis for mining and opinion analysis of COVID-19-related comments.", "cite_spans": [], "ref_spans": [{"start": 296, "end": 302, "text": "Fig. 2", "ref_id": "FIGREF1"}], "section": "Framework Methodology"}, {"text": "Reddit is an American social media, a discussion website for various topics that includes web content ratings. In this social media, users are able to post questions and comments, and to respond to each other regarding different subjects, such as COVID-19. The posts are organised by subjects created by online users, called \"subreddits\", which cover a variety of topics like news, science, healthcare, video, books, fitness, food, and image-sharing. This website is an ideal source for collecting healthrelated information about COVID-19-related issues. This paper focuses on COVID-19-related comments of 10 sub-reddits based on an existing dataset as the first step in producing this model.", "cite_spans": [], "ref_spans": [], "section": "Preparing the input data"}, {"text": "One of the most important steps in pre-processing COVID-19-related comments is removing useless words/data, which are defined as stop-words in NLP, from pure text. Moreover, we also decreased the dimensionality of the features space by eliminating stop-words. For example, the most common words in the text comments are words that are usually meaningless and do not effectively influence the output, such as articles, conjunctions, pronouns, and linking verbs. Some examples include: am, is, are, they, the, these, I, that, and, them.", "cite_spans": [], "ref_spans": [], "section": "Removing Noise and Stop-words"}, {"text": "Text-document modeling in NLP is a practical technique that represents an individual document and the set of text-documents based on terms appearing in the textdocuments. Topic modeling based on Latent Dirichlet Allocation (LDA) [14] is one type of document modelling approach. As a third step, we utilized topic modeling based on an LDA Topic model and Gibbs sampling [15] for semantic extraction and latent topic discovery of COVID-19-related comments. COVID-19 comments, however, can depend on various subjects that are discussed by reddit users. In this step we can detect and discover these meaningful subjects or topics. Therefore, based on the LDA model, we considered a collection of documents, such as COVID-19related comments and words, as topics (K), where the discrete topic distributions are drawn from a symmetric Dirichlet distribution. The probability of observed data Step 3: Semantic Processing", "cite_spans": [{"start": 229, "end": 233, "text": "[14]", "ref_id": "BIBREF13"}, {"start": 369, "end": 373, "text": "[15]", "ref_id": "BIBREF14"}], "ref_spans": [], "section": "Semantic Extraction and COVID-19 Comment Mining"}, {"text": "Step 4: Deep Learning and Comment Classification", "cite_spans": [], "ref_spans": [], "section": "Semantic Extraction and COVID-19 Comment Mining"}, {"text": "Step 1: COVID- 19 Comments Defining and applying Stop=words ", "cite_spans": [{"start": 15, "end": 26, "text": "19 Comments", "ref_id": null}], "ref_spans": [], "section": "Semantic Extraction and COVID-19 Comment Mining"}, {"text": "Determined \u03b1 parameters of topic Dirichlet prior and also considered parameters of word Dirichlet prior as \u03b2. M is the number of text-documents, and N is the vocabulary size. Moreover,(\u03b1, \u03b8) was determined for the corpus-level topic distributions with a pair of Dirichlet multinomials. (\u03b2, \u03d5) was also determined for the topic-word distributions with a pair of Dirichlet multinomials. In addition, the document-level variables were defined as \u03b8 d , which may be sampled for each document. The wordlevel variables z dn , w d n , were sampled in each text-document for each word [14] .", "cite_spans": [{"start": 577, "end": 581, "text": "[14]", "ref_id": "BIBREF13"}], "ref_spans": [], "section": "Semantic Extraction and COVID-19 Comment Mining"}, {"text": "Algorithm 1 Pre-processing and removing the noise to prepare the input data word-probability under the topic of sampling --or the word distribution for topic k among COVID-19-related comments 4:", "cite_spans": [], "ref_spans": [], "section": "Semantic Extraction and COVID-19 Comment Mining"}, {"text": "\u03c6 \u223c Dirichlet(\u03b2) 5: end for 6: for each COVID-19-related comments d \u2208 {1, . . . , D} do 7:", "cite_spans": [], "ref_spans": [], "section": "Semantic Extraction and COVID-19 Comment Mining"}, {"text": "The topic distribution for document m 8:", "cite_spans": [], "ref_spans": [], "section": "Semantic Extraction and COVID-19 Comment Mining"}, {"text": "d\u03b8 \u223c Dirichlet(\u03b1) 9:", "cite_spans": [], "ref_spans": [], "section": "Semantic Extraction and COVID-19 Comment Mining"}, {"text": "for Per word in COVID-19-related content-document d do 10:", "cite_spans": [], "ref_spans": [], "section": "Semantic Extraction and COVID-19 Comment Mining"}, {"text": "sampling the distribution of topics in the COVID-19-related comments-documents to obtain the topic of the word: .Z d \u223c Mul(\u03b8) 11:", "cite_spans": [], "ref_spans": [], "section": "Semantic Extraction and COVID-19 Comment Mining"}, {"text": "word-sampling undert the topic, W d \u223c Mul(\u03c6) 12:", "cite_spans": [], "ref_spans": [], "section": "Semantic Extraction and COVID-19 Comment Mining"}, {"text": "end for 13: end for Algorithm 2 describes a general process as part of our framework for extracting latent topics and semantic mining. The input data consists of the number of COVID-19-related comments as the context of the document: Line 1 processes the pure-data to eliminate noise and stop-words based on Algorithm 1. Lines 2-5 compute the probability of the word distribution from Topic K[i]. Lines 6-11 compute the probability of the topic distribution from the COVID-19-Content-Document m [i]. As highlighted in Equation 1, the variables \u03b8 m , w n are computed for document-level and word-level of the framework. In more detail, the LDA handles topics as multinomial distributions in documents and words as a probabilistic mixture of a pre-determined number from latent topics. Lines 1-3 of Algorithm 3 show the semantic mining to extract the latent topics. We then used a sorting function to determine the recommended highlighted topics. Because the Gibbs sampling method is used in this step, the time requested for model inference can be specified as the sum of the time for inferring LDA. Therefore, the time complexity for LDA is O(N K), where N denotes the total size of the corpus (COVID-19-related comments) and K is the topic number. ", "cite_spans": [], "ref_spans": [], "section": "Semantic Extraction and COVID-19 Comment Mining"}, {"text": "Deep neural networks have been successfully employed for different types of machinelearning tasks, such as NLP-based methods utilizing sentiment aspects for deep classification [16] - [21] . Deep neural networks are able to model high-level abstractions and to decrease the dimensions by utilizing multiple processing layers based on complex structures or to be combined with non-linear transformations. RNNs are popular models with demonstrated importance and strength in most NLP works [22] - [24] . The purpose of RNNs is to use consecutive information, and the output is augmented by storing previous calculations. In fact, RNNs are equipped with a memory function that saves formerly calculated information. Basic RNNs, however, have some challenges due to gradient vanishing or exploding, and they are unable to learn long-term dependencies. LSTM [25] , [26] units have the benefit of being able to avoid this challenge by adjusting the information in a cell state using 3 different gates. The formula for each LSTM cell can be formalized as:", "cite_spans": [{"start": 177, "end": 181, "text": "[16]", "ref_id": "BIBREF15"}, {"start": 184, "end": 188, "text": "[21]", "ref_id": "BIBREF21"}, {"start": 488, "end": 492, "text": "[22]", "ref_id": "BIBREF22"}, {"start": 495, "end": 499, "text": "[24]", "ref_id": "BIBREF24"}, {"start": 853, "end": 857, "text": "[25]", "ref_id": "BIBREF25"}, {"start": 860, "end": 864, "text": "[26]", "ref_id": "BIBREF26"}], "ref_spans": [], "section": "Deep-Learning and Sentiment Classification"}, {"text": "The forget ( f t ), input (i t ), and output (o t ) gates for each LSTM cell are determined by these 3 equations, eqs. 2-4, respectively. In an LSTM layer, the forget gate determines which previous information from the cell state is forgotten. The input gate controls or determines the new information that is saved in the memory cell. The output gate controls or determines the amount of information in the internal memory cell to be exposed. The cell-memory/input block equations are:", "cite_spans": [], "ref_spans": [], "section": "Deep-Learning and Sentiment Classification"}, {"text": "In which, C i is the cell state, z t is the hidden output, and x t is an input vector. W and b are the weight matrix and the bias term respectively. \u03c3 is sigmoid and \u03c6 is tanh.", "cite_spans": [], "ref_spans": [], "section": "Deep-Learning and Sentiment Classification"}, {"text": "is element-wise multiplication.", "cite_spans": [], "ref_spans": [], "section": "Deep-Learning and Sentiment Classification"}, {"text": "As the last step of this framework, an LSTM model was utilised to assess the COVID-19-related comments of online users who posted on reddit, in order to recognize the emotion/sentiment elicited from these comments. We designed two LSTMlayers and for pre-trained embeddings, considered the Glove-50 dimension 1 , which were trained over a large corpus of COVID-19-related comments ( Figure 3 ). The processed text from the COVID-19-related comments, however, is changed to vectors with a fixed dimension by converting pre-trained embeddings. Moreover, COVID-19 comments can also be described as a characters-sequence with its corresponding dimension creating a matrix [27] .", "cite_spans": [{"start": 667, "end": 671, "text": "[27]", "ref_id": "BIBREF27"}], "ref_spans": [{"start": 382, "end": 390, "text": "Figure 3", "ref_id": "FIGREF3"}], "section": "Deep-Learning and Sentiment Classification"}, {"text": "In this section, we provide a detailed description of the data collection and experimental results followed by a comprehensive discussion of the results. We assessed 563,079 COVID-19-related comments from reddit. The dataset was collected between January 20, 2020 and March 19, 2020 (the full dataset is available at Kaggle website 2 ). We used MALLET 3 to implement the inference and capture the LDA topic model to retrieve latent topics. We used the Python library Keras 4 to implement our deep-learning model. According to Table 1 and 2 and Figures 4-8 , the following observations were made: Topics 85 and 18 had a similar concept in \"People/Infection\". Topic 85 included words referring to people, such as \"people\", \"virus\", \"day\", \"bad\", \"stop\", \"news\", \"worse\", \"sick\", \"spread\", and \"family\". This topic is the first ranked topic discovered from the generated latent topics, in which most users express their opinion and comment on this issue. Based on Table 1 and Figure 5 (a) in this topic, the terms \"people\" and \"virus\" were the most highlighted words, with word-weights of 0.1295% and 0.0301%, respectively. Also, we can see the importance of the term \"family\" from this topic. In addition, Topic 18 contains the telling words \"virus\", \"people\", \"symptoms\", \"infection\", \"cases\", \"disease\", \"pneumonia\", \"coronavirus\", and \"treatment\". Other revealing words in Topic 18 included \"people\", \"infection\", and \"treatment\". These terms initially suggest a set of user comments about treatment issues. Moreover, the sentiment analysis of the terms suggest that negative words were more highlighted than positive words. Topic 63 also addresses healthcare and hospital issues with the most frequent term being \"hospital\". Words such as \"hospital\", \"medical\", \"healthcare\", \"patients\", \"care\", and \"city\" were included. The terms \"hospital\", \"medical\", and \"healthcare\" were the most highlighted words, with word-weights of 0.0561%, 0.0282%, and 0.0278%, respectively. Other words worth mentioning that were seen for this topic were \"person\", \"patient\", \"staff\", \"workers\", and \"emergency\". Topic 63 was assigned as medical staff issues. Topic 4 included words relating to money, such as \"pay\", \"money\", \"companies\", \"insurance\", \"paid\", \"free\", \"cost\", \"tax\", \"years\", and \"employees\". Moreover, the sentiment analysis of the terms suggested that negative words were more highlighted than positive words.", "cite_spans": [], "ref_spans": [{"start": 526, "end": 533, "text": "Table 1", "ref_id": "TABREF3"}, {"start": 544, "end": 555, "text": "Figures 4-8", "ref_id": "FIGREF8"}, {"start": 961, "end": 968, "text": "Table 1", "ref_id": "TABREF3"}, {"start": 973, "end": 981, "text": "Figure 5", "ref_id": null}], "section": "Experiment Details"}, {"text": "Topic 30 covers user's comments concerning issues related to \"feelings and hopes\" and highlight words such as \"good\", \"hope\", \"feel\", \"house\", \"safe\", \"hard\", \"months\", \"fine\", \"live\", and \"friend\". Moreover, sentiment analysis of terms suggested that positive words were more highlighted than negative words. Positive words such as \"good\", \"hope\", \"safe\", \"fine\", \"kind\", and \"friend\", thus pertain to the phenomenon of \"positive feelings\". For Topic 93, we can see that there was a clear focus on \"people, age, and COVID issues\" with the top words being \"covid\", \"young\", \"risk\", \"fever\", \"immune\", \"age\", \"sick\", \"cough\", \"life\", \"cold\", \"elderly\", and \"older\". The terms \"covid\", \"young\", and \"risk\" were the most highlighted words, with wordweights of 0.0299%, 0.0222%, and 0.0218%, respectively, and this topic had negative polarity.", "cite_spans": [], "ref_spans": [], "section": "Experiment Details"}, {"text": "Topic 48 also addresses \"COVID-19 testing issues\" and contains words like \"people\", \"testing\", \"government\", \"country\", \"tested\", \"test\", \"infected\", \"home\", \"covid\", and \"pandemic\". Based on the results, the terms \"people\" and \"testing\" were the most highlighted words with word weights of 0.0447% and 0.0337%, respectively. Moreover, the opinion words based on sentiment analysis scored high in negative polarity for Topic 17. The top terms of this topic were \"coronavirus\", \"quarantine\", \"stupid\", \"happening\", \"shit\", \"watch\", and \"dangerous\", thus pertaining to the phenomenon \"quarantine issues\". The terms \"coronavirus\" and \"quarantine\" were the most highlighted words, with word-weights of 0.0353% and 0.0346%, respectively.", "cite_spans": [], "ref_spans": [], "section": "Experiment Details"}, {"text": "Sentiment analysis is a practical technique in NLP for opinion mining that can be used to classify text/comments based on word polarities [28] - [30] . This technique has many applications in various disciplines, such as opinion mining in online healthcare communities [31] - [33] . We obtained the sentiment of the COVID-19-related comments using the SentiStrength algorithm [34] - [36] . Therefore, with all COVID-19-related comments tagged with sentiment scores, we calculated the average sentiment of the entire dataset along with comments mentioning only 10 COVID-19 sub-reddits. The main objective of this analysis was to identify the overall sentiment Figure 9 shows the sentiment of all comments in the database along with the average sentiment of comments containing the terms COVID-19. For each of the polar comments in our labelled dataset, we assigned negative and positive scores utilizing SentiStrength, and employed the various scores directly as rules for building inference about the polarity/sentiment of the COVID-19 comments. Based on SentiStrength, we determined that a comment was positive if the positive sentiment score was greater than the negative sentiment score, and also considered a similar rule for determining a positive sentiment. For example, a score of +5 and -4 indicates positive polarity and a score of +4 and -6 indicates negative polarity. Moreover, If the sentiment scores were equal (such as -1 and +1, +4 and -4), we determined that the comment was neutral.", "cite_spans": [{"start": 138, "end": 142, "text": "[28]", "ref_id": "BIBREF28"}, {"start": 145, "end": 149, "text": "[30]", "ref_id": "BIBREF30"}, {"start": 269, "end": 273, "text": "[31]", "ref_id": "BIBREF31"}, {"start": 276, "end": 280, "text": "[33]", "ref_id": "BIBREF33"}, {"start": 376, "end": 380, "text": "[34]", "ref_id": "BIBREF34"}, {"start": 383, "end": 387, "text": "[36]", "ref_id": "BIBREF36"}], "ref_spans": [{"start": 659, "end": 667, "text": "Figure 9", "ref_id": "FIGREF9"}], "section": "Sentiment and Polarity results"}, {"text": "To prepare the dataset to automatically classify the sentiment of the COVID-19 comments for all of the data, we labelled each of the comments as very positive, positive, very negative, negative, and neutral based on the sentiment score obtained using the Sentistrength method. The training set had 338,666 COVID-19-related comments and the testing set had 112,888 comments. In this experiment, we evaluated the proposed LSTM-model and also supervised machine-learning methods using the Support Vector Machine (Senti-ML1), Naive Bayes (Senti-ML2), Logistic Regression (Senti-ML3), K Nearest Neighbors (Senti-ML4) techniques. Figure 4 shows the accuracy of the best model for classifying a COVID-19 comment as either a very positive, positive, very negative, negative, or neutral sentiment. Our approach based on the LSTM model, which classified all COVID-19 comments in the majority class achieved 81.15% accuracy, which was higher than that of traditional machinelearning algorithms. We believe that the sentiment and semantic techniques can provide meaningful results with an overview of how users/people feel about the disaster.", "cite_spans": [], "ref_spans": [{"start": 624, "end": 632, "text": "Figure 4", "ref_id": null}], "section": "Deep classification and Feature Analysis"}, {"text": "Analysing social media comments on platforms such as reddit could provide meaningful information for understanding people's opinions, which might be difficult to achieve through traditional techniques, such as manual methods. The text content on reddit has been analysed in various studies [37] - [39] ; to the best of our knowledge, this is the first study to analyse comments by considering semantic and sentiment aspects of COVID-related comments from reddit for online health communities.", "cite_spans": [{"start": 290, "end": 294, "text": "[37]", "ref_id": "BIBREF37"}, {"start": 297, "end": 301, "text": "[39]", "ref_id": "BIBREF39"}], "ref_spans": [], "section": "Discussion and Practical Findings"}, {"text": "Overall, we extended the analysis to check whether we could find a dependency of semantic aspects of user-comments for different issues on COVID-19-related topics. In this case, we considered an existing dataset that included 563,079 comments from 10 sub-reddits. We found and detected meaningful latent topics of terms about COVID-19 comments related to various issues. Thus, user comments proved to be a valuable source of information, as shown in Tables 1 and 2 and Figures 4-8 . A variety of different visualisations was used to interpret the generated LDA results. As mentioned, LDA is a probabilistic model that, when applied to documents, hypothesises that each document from a collection has been generated as a mixture of This research was limited to English-language text, which was considered a selection criterion. Therefore, the results do not reflect comments made in other languages. In addition, this study was limited to comments retrieved from January 20, 2020 and March 19, 2020. Therefore, the gap between the period in which the research was being completed and the time-frame of our study may have somewhat affected the timeliness of our results. Overall, the study suggests that the systematic framework by combining NLP and deep-learning methods based on topic modelling and an LSTM model enabled us to generate some valuable information from COVID-19-related comments. These kinds of statistical contributions can be useful for determining the positive and negative actions of an online community, and to collect user opinions to help researchers and clinicians better understand the behaviour of people in a critical situation. Regarding future work, we plan to evaluate other social media, such as Twitter, using hybrid fuzzy deep-learning techniques [40] - [41] that can be used in the future for sentiment level classification as a novel method of retrieving meaningful latent topics from public comments.", "cite_spans": [{"start": 1778, "end": 1782, "text": "[40]", "ref_id": "BIBREF40"}, {"start": 1785, "end": 1789, "text": "[41]", "ref_id": "BIBREF41"}], "ref_spans": [{"start": 450, "end": 464, "text": "Tables 1 and 2", "ref_id": "TABREF3"}, {"start": 469, "end": 480, "text": "Figures 4-8", "ref_id": "FIGREF8"}], "section": "Discussion and Practical Findings"}, {"text": "To our knowledge, this is the first study to analyse the association between COVID-19 comments'sentiment and semantic topics on reddit. The main goal of this paper, however, was to show a novel application for NLP based on an LSTM model to detect meaningful latent-topics and sentiment-comment-classification on COVID-19related issues from healthcare forums, such as sub-reddits. We believe that the results of this paper will aid in understanding the concerns and needs of people with respect to COVID-19-related issues. Moreover, our findings may aid in improving practical strategies for public health services and interventions related to COVID-19.", "cite_spans": [], "ref_spans": [], "section": "CONCLUSION"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "The coronavirus 2019-nCoV epidemic: Is hindsight 20/20?", "authors": [{"first": "Monica", "middle": [], "last": "Malta", "suffix": ""}, {"first": "Anne", "middle": ["W"], "last": "Rimoin", "suffix": ""}, {"first": "Steffanie", "middle": ["A"], "last": "Strathdee", "suffix": ""}], "year": 2020, "venue": "EClinicalMedicine", "volume": "20", "issn": "", "pages": "", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "Reddit and Radiation Therapy: A Descriptive Analysis of Posts and Comments Over 7 Years by Patients and Health Care Professionals", "authors": [{"first": "J", "middle": [], "last": "Thomas", "suffix": ""}, {"first": "A", "middle": ["V"], "last": "Prabhu", "suffix": ""}, {"first": "D", "middle": ["E"], "last": "Heron", "suffix": ""}, {"first": "S", "middle": [], "last": "Beriwal", "suffix": ""}], "year": 2019, "venue": "Advances in radiation oncology", "volume": "4", "issn": "", "pages": "345--353", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Sentiment analysis of Twitter data during critical events through Bayesian networks classifiers", "authors": [{"first": "G", "middle": ["A"], "last": "Ruz", "suffix": ""}, {"first": "P", "middle": ["A"], "last": "Henr\u00edquez", "suffix": ""}, {"first": "A", "middle": [], "last": "Mascare\u00f1o", "suffix": ""}], "year": 2020, "venue": "Future Generation Computer Systems", "volume": "106", "issn": "", "pages": "92--104", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Unsupervised Classification of Health Content on Reddit", "authors": [{"first": "J", "middle": ["M"], "last": "Barros", "suffix": ""}, {"first": "P", "middle": [], "last": "Buitelaar", "suffix": ""}, {"first": "J", "middle": [], "last": "Duggan", "suffix": ""}, {"first": "D", "middle": [], "last": "Rebholz-Schuhmann", "suffix": ""}], "year": 2019, "venue": "Proceedings of the 9th International Conference on", "volume": "", "issn": "", "pages": "85--89", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "Ebola and localized blame on social media: analysis of Twitter and Facebook conversations during the 2014-2015 Ebola epidemic", "authors": [{"first": "M", "middle": [], "last": "Roy", "suffix": ""}, {"first": "N", "middle": [], "last": "Moreau", "suffix": ""}, {"first": "C", "middle": [], "last": "Rousseau", "suffix": ""}, {"first": "A", "middle": [], "last": "Mercier", "suffix": ""}, {"first": "A", "middle": [], "last": "Wilson", "suffix": ""}, {"first": "L", "middle": [], "last": "Atlani-Duault", "suffix": ""}], "year": 2020, "venue": "Medicine, and Psychiatry", "volume": "44", "issn": "1", "pages": "56--79", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Deep learning for pollen allergy surveillance from twitter in Australia", "authors": [{"first": "J", "middle": [], "last": "Rong", "suffix": ""}, {"first": "S", "middle": [], "last": "Michalska", "suffix": ""}, {"first": "S", "middle": [], "last": "Subramani", "suffix": ""}, {"first": "J", "middle": [], "last": "Du", "suffix": ""}, {"first": "H", "middle": [], "last": "Wang", "suffix": ""}], "year": 2019, "venue": "BMC medical informatics and decision making", "volume": "19", "issn": "1", "pages": "", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "Ontology-Based Healthcare Named Entity Recognition from Twitter Messages Using a Recurrent Neural Network Approach", "authors": [{"first": "E", "middle": [], "last": "Batbaatar", "suffix": ""}, {"first": "K", "middle": ["H"], "last": "Ryu", "suffix": ""}], "year": 2019, "venue": "International Journal of Environmental Research and Public Health", "volume": "16", "issn": "19", "pages": "", "other_ids": {}}, "BIBREF7": {"ref_id": "b7", "title": "Similarity of medical concepts in question and answering of health communities", "authors": [{"first": "Hamid", "middle": [], "last": "Naderi", "suffix": ""}, {"first": "Sina", "middle": [], "last": "Madani", "suffix": ""}, {"first": "Behzad", "middle": [], "last": "Kiani", "suffix": ""}, {"first": "Kobra", "middle": [], "last": "Etminani", "suffix": ""}], "year": 2019, "venue": "Health informatics journal", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Identifying peer experts in online health forums", "authors": [{"first": "V", "middle": ["V"], "last": "Vydiswaran", "suffix": ""}, {"first": "M", "middle": [], "last": "Reddy", "suffix": ""}], "year": 2019, "venue": "BMC medical informatics and decision making", "volume": "19", "issn": "3", "pages": "", "other_ids": {}}, "BIBREF9": {"ref_id": "b9", "title": "Modeling temporal progression of emotional status in mental health forum: A recurrent neural net approach", "authors": [{"first": "K", "middle": [], "last": "Halder", "suffix": ""}, {"first": "L", "middle": [], "last": "Poddar", "suffix": ""}, {"first": "M", "middle": ["Y"], "last": "Kan", "suffix": ""}], "year": 2017, "venue": "Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis", "volume": "", "issn": "", "pages": "127--135", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "Assessing unmet information needs of breast cancer survivors: Exploratory study of online health forums using text classification and retrieval", "authors": [{"first": "S", "middle": [], "last": "Mcroy", "suffix": ""}, {"first": "M", "middle": [], "last": "Rastegar-Mojarad", "suffix": ""}, {"first": "Y", "middle": [], "last": "Wang", "suffix": ""}, {"first": "K", "middle": ["J"], "last": "Ruddy", "suffix": ""}, {"first": "T", "middle": ["C"], "last": "Haddad", "suffix": ""}, {"first": "H", "middle": [], "last": "Liu", "suffix": ""}], "year": 2018, "venue": "JMIR cancer", "volume": "4", "issn": "1", "pages": "", "other_ids": {}}, "BIBREF11": {"ref_id": "b11", "title": "Detecting and Characterizing Trends in Online Mental Health Discussions", "authors": [{"first": "D", "middle": [], "last": "Chakravorti", "suffix": ""}, {"first": "K", "middle": [], "last": "Law", "suffix": ""}, {"first": "J", "middle": [], "last": "Gemmell", "suffix": ""}, {"first": "D", "middle": [], "last": "Raicu", "suffix": ""}], "year": 2018, "venue": "2018 IEEE International Conference on Data Mining Workshops (ICDMW)", "volume": "", "issn": "", "pages": "697--706", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "Detecting clinically related content in online patient posts", "authors": [{"first": "C", "middle": [], "last": "Kanthawala", "suffix": ""}, {"first": "S", "middle": [], "last": "Pratt", "suffix": ""}, {"first": "W", "middle": [], "last": "Chai", "suffix": ""}, {"first": "J", "middle": [], "last": "Huh", "suffix": ""}, {"first": "J", "middle": [], "last": "", "suffix": ""}], "year": 2017, "venue": "Journal of biomedical informatics", "volume": "75", "issn": "", "pages": "96--106", "other_ids": {}}, "BIBREF13": {"ref_id": "b13", "title": "Latent dirichlet allocation", "authors": [{"first": "D", "middle": ["M"], "last": "Blei", "suffix": ""}, {"first": "A", "middle": ["Y"], "last": "Ng", "suffix": ""}, {"first": "M", "middle": ["I"], "last": "Jordan", "suffix": ""}], "year": 2003, "venue": "Journal of machine Learning research", "volume": "3", "issn": "", "pages": "993--1022", "other_ids": {}}, "BIBREF14": {"ref_id": "b14", "title": "Gibbs sampling for logistic normal topic models with graph-based priors", "authors": [{"first": "D", "middle": [], "last": "Mimno", "suffix": ""}, {"first": "H", "middle": [], "last": "Wallach", "suffix": ""}, {"first": "A", "middle": [], "last": "Mccallum", "suffix": ""}], "year": 2008, "venue": "NIPS Workshop on Analyzing Graphs", "volume": "61", "issn": "", "pages": "", "other_ids": {}}, "BIBREF15": {"ref_id": "b15", "title": "Improving the reliability of deep neural networks in NLP: A review. Knowledge-Based Systems", "authors": [{"first": "B", "middle": [], "last": "Alshemali", "suffix": ""}, {"first": "J", "middle": [], "last": "Kalita", "suffix": ""}], "year": 2020, "venue": "", "volume": "191", "issn": "", "pages": "", "other_ids": {}}, "BIBREF16": {"ref_id": "b16", "title": "Semantic-based padding in convolutional neural networks for improving the performance in natural language processing. A case of study in sentiment analysis", "authors": [{"first": "M", "middle": [], "last": "Gim\u00e9nez", "suffix": ""}, {"first": "J", "middle": [], "last": "Palanca", "suffix": ""}, {"first": "V", "middle": [], "last": "Botti", "suffix": ""}], "year": 2020, "venue": "Neurocomputing", "volume": "378", "issn": "", "pages": "315--323", "other_ids": {}}, "BIBREF18": {"ref_id": "b18", "title": "Gluoncv and gluonnlp: Deep learning in computer vision and natural language processing", "authors": [{"first": "A", "middle": [], "last": "Zhang", "suffix": ""}], "year": 2020, "venue": "Journal of Machine Learning Research", "volume": "21", "issn": "23", "pages": "1--7", "other_ids": {}}, "BIBREF19": {"ref_id": "b19", "title": "Deep learning models and datasets for aspect term sentiment classification: Implementing holistic recurrent attention on target-dependent memories. Knowledge-Based Systems", "authors": [{"first": "H", "middle": ["J"], "last": "Park", "suffix": ""}, {"first": "M", "middle": [], "last": "Song", "suffix": ""}, {"first": "K", "middle": ["S"], "last": "Shin", "suffix": ""}], "year": 2020, "venue": "", "volume": "187", "issn": "", "pages": "", "other_ids": {}}, "BIBREF20": {"ref_id": "b20", "title": "Sentiment Analysis in Healthcare: A Brief Review", "authors": [{"first": "L", "middle": [], "last": "Abualigah", "suffix": ""}, {"first": "H", "middle": ["E"], "last": "Alfar", "suffix": ""}, {"first": "M", "middle": [], "last": "Shehab", "suffix": ""}, {"first": "A", "middle": ["M A"], "last": "Hussein", "suffix": ""}], "year": 2020, "venue": "Recent Advances in NLP: The Case of Arabic Language", "volume": "", "issn": "", "pages": "129--141", "other_ids": {}}, "BIBREF21": {"ref_id": "b21", "title": "Develop a Neural Model to Score Bigram of Words Using Bag-of-Words Model for Sentiment Analysis", "authors": [{"first": "Anumeera", "middle": [], "last": "Balamurali", "suffix": ""}, {"first": "Balamurali", "middle": [], "last": "Ananthanarayanan", "suffix": ""}], "year": 2020, "venue": "Neural Networks for Natural Language Processing", "volume": "", "issn": "", "pages": "122--142", "other_ids": {}}, "BIBREF22": {"ref_id": "b22", "title": "Recurrent neural networks with specialized word embeddings for health-domain named-entity recognition", "authors": [{"first": "I", "middle": ["J"], "last": "Unanue", "suffix": ""}, {"first": "E", "middle": ["Z"], "last": "Borzeshi", "suffix": ""}, {"first": "M", "middle": [], "last": "Piccardi", "suffix": ""}], "year": 2017, "venue": "Journal of biomedical informatics", "volume": "76", "issn": "", "pages": "102--109", "other_ids": {}}, "BIBREF23": {"ref_id": "b23", "title": "Recurrent neural networks for classifying relations in clinical notes", "authors": [{"first": "Y", "middle": [], "last": "Luo", "suffix": ""}], "year": 2017, "venue": "Journal of biomedical informatics", "volume": "72", "issn": "", "pages": "85--95", "other_ids": {}}, "BIBREF24": {"ref_id": "b24", "title": "Optimization of Recurrent Neural Networks on Natural Language Processing", "authors": [{"first": "J", "middle": [], "last": "Huang", "suffix": ""}, {"first": "Y", "middle": [], "last": "Feng", "suffix": ""}], "year": 2019, "venue": "Proceedings of the 2019 8th International Conference on Computing and Pattern Recognition", "volume": "", "issn": "", "pages": "39--45", "other_ids": {}}, "BIBREF25": {"ref_id": "b25", "title": "Long short-term memory", "authors": [{"first": "S", "middle": [], "last": "Hochreiter", "suffix": ""}, {"first": "J", "middle": [], "last": "Schmidhuber", "suffix": ""}], "year": 1997, "venue": "Neural computation", "volume": "9", "issn": "8", "pages": "1735--1780", "other_ids": {}}, "BIBREF26": {"ref_id": "b26", "title": "Convolutional, long short-term memory, fully connected deep neural networks", "authors": [{"first": "T", "middle": ["N"], "last": "Sainath", "suffix": ""}, {"first": "O", "middle": [], "last": "Vinyals", "suffix": ""}, {"first": "A", "middle": [], "last": "Senior", "suffix": ""}, {"first": "H", "middle": [], "last": "Sak", "suffix": ""}], "year": 2015, "venue": "2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "volume": "", "issn": "", "pages": "4580--4584", "other_ids": {}}, "BIBREF27": {"ref_id": "b27", "title": "Sentiment extraction from Consumer-generated noisy short texts", "authors": [{"first": "H", "middle": [], "last": "Meisheri", "suffix": ""}, {"first": "K", "middle": [], "last": "Ranjan", "suffix": ""}, {"first": "L", "middle": [], "last": "Dey", "suffix": ""}], "year": 2017, "venue": "2017 IEEE International Conference on Data Mining Workshops (ICDMW)", "volume": "", "issn": "", "pages": "399--406", "other_ids": {}}, "BIBREF28": {"ref_id": "b28", "title": "Natural Language Processing, Sentiment Analysis, and Clinical Analytics", "authors": [{"first": "Adil", "middle": [], "last": "Rajput", "suffix": ""}], "year": 2020, "venue": "Innovation in Health Informatics", "volume": "", "issn": "", "pages": "79--97", "other_ids": {}}, "BIBREF29": {"ref_id": "b29", "title": "Deep Learning Approaches for Textual Sentiment Analysis", "authors": [{"first": "T", "middle": [], "last": "Sharma", "suffix": ""}, {"first": "A", "middle": [], "last": "Bajaj", "suffix": ""}, {"first": "O", "middle": ["P"], "last": "Sangwan", "suffix": ""}], "year": 2020, "venue": "Handbook of Research on Emerging Trends and Applications of Machine Learning", "volume": "", "issn": "", "pages": "171--182", "other_ids": {}}, "BIBREF30": {"ref_id": "b30", "title": "Sentiment analysis using deep learning approaches: an overview", "authors": [{"first": "Olivier", "middle": [], "last": "Habimana", "suffix": ""}, {"first": "Yuhua", "middle": [], "last": "Li", "suffix": ""}, {"first": "Ruixuan", "middle": [], "last": "Li", "suffix": ""}, {"first": "Xiwu", "middle": [], "last": "Gu", "suffix": ""}, {"first": "Ge", "middle": [], "last": "Yu", "suffix": ""}], "year": 2020, "venue": "Science China Information Sciences", "volume": "63", "issn": "1", "pages": "1--36", "other_ids": {}}, "BIBREF31": {"ref_id": "b31", "title": "WiP] Sentiment Analysis Electronic Healthcare System Based on Heart Rate Monitoring Smart Bracelet", "authors": [{"first": "Iuliana", "middle": [], "last": "Marin", "suffix": ""}, {"first": "Nicolae", "middle": [], "last": "Goga", "suffix": ""}, {"first": "Andrei", "middle": [], "last": "Doncescu", "suffix": ""}], "year": 2018, "venue": "2018 IEEE 11th Conference on Service-Oriented Computing and Applications (SOCA)", "volume": "", "issn": "", "pages": "99--104", "other_ids": {}}, "BIBREF32": {"ref_id": "b32", "title": "Enriching user experience in online health communities through thread recommendations and heterogeneous information network mining", "authors": [{"first": "C", "middle": ["C"], "last": "Yang", "suffix": ""}, {"first": "L", "middle": [], "last": "Jiang", "suffix": ""}], "year": 2018, "venue": "IEEE Transactions on Computational Social Systems", "volume": "5", "issn": "4", "pages": "1049--1060", "other_ids": {}}, "BIBREF33": {"ref_id": "b33", "title": "Sentiment lexicons for health-related opinion mining", "authors": [{"first": "L", "middle": [], "last": "Goeuriot", "suffix": ""}, {"first": "J", "middle": ["C"], "last": "Na", "suffix": ""}, {"first": "W", "middle": ["Y"], "last": "Min Kyaing", "suffix": ""}, {"first": "C", "middle": [], "last": "Khoo", "suffix": ""}, {"first": "Y", "middle": ["K"], "last": "Chang", "suffix": ""}, {"first": "Y", "middle": ["L"], "last": "Theng", "suffix": ""}, {"first": "J", "middle": ["J"], "last": "Kim", "suffix": ""}], "year": 2012, "venue": "Proceedings of the 2nd ACM SIGHIT International Health Informatics Symposium", "volume": "", "issn": "", "pages": "219--226", "other_ids": {}}, "BIBREF34": {"ref_id": "b34", "title": "The Heart and soul of the web? Sentiment strength detection in the social web with SentiStrength", "authors": [{"first": "M", "middle": [], "last": "Thelwall", "suffix": ""}], "year": 2017, "venue": "Cyberemotions", "volume": "", "issn": "", "pages": "119--134", "other_ids": {}}, "BIBREF35": {"ref_id": "b35", "title": "Sentiment strength detection in short informal text", "authors": [{"first": "M", "middle": [], "last": "Thelwall", "suffix": ""}, {"first": "K", "middle": [], "last": "Buckley", "suffix": ""}, {"first": "G", "middle": [], "last": "Paltoglou", "suffix": ""}, {"first": "D", "middle": [], "last": "Cai", "suffix": ""}, {"first": "A", "middle": [], "last": "Kappas", "suffix": ""}], "year": 2010, "venue": "Journal of the American Society for Information Science and Technology", "volume": "", "issn": "12", "pages": "2544--2558", "other_ids": {}}, "BIBREF36": {"ref_id": "b36", "title": "Topic-based sentiment analysis for the Social Web: The role of mood and issue-related words", "authors": [{"first": "M", "middle": [], "last": "Thelwall", "suffix": ""}, {"first": "K", "middle": [], "last": "Buckley", "suffix": ""}], "year": 2013, "venue": "Journal of the American Society for Information Science and Technology", "volume": "64", "issn": "8", "pages": "1608--1617", "other_ids": {}}, "BIBREF37": {"ref_id": "b37", "title": "Natural language processing of Reddit data to evaluate dermatology patient experiences and therapeutics", "authors": [{"first": "E", "middle": [], "last": "Okon", "suffix": ""}, {"first": "V", "middle": [], "last": "Rachakonda", "suffix": ""}, {"first": "H", "middle": ["J"], "last": "Hong", "suffix": ""}, {"first": "C", "middle": [], "last": "Callison-Burch", "suffix": ""}, {"first": "J", "middle": [], "last": "Lipoff", "suffix": ""}], "year": 2019, "venue": "Journal of the American Academy of Dermatology", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF38": {"ref_id": "b38", "title": "Tracking health related discussions on Reddit for public health applications", "authors": [{"first": "A", "middle": [], "last": "Park", "suffix": ""}, {"first": "M", "middle": [], "last": "Conway", "suffix": ""}], "year": 2017, "venue": "AMIA Annual Symposium Proceedings", "volume": "2017", "issn": "", "pages": "", "other_ids": {}}, "BIBREF39": {"ref_id": "b39", "title": "Social media based analysis of opioid epidemic using Reddit", "authors": [{"first": "S", "middle": [], "last": "Pandrekar", "suffix": ""}, {"first": "X", "middle": [], "last": "Chen", "suffix": ""}, {"first": "G", "middle": [], "last": "Gopalkrishna", "suffix": ""}, {"first": "A", "middle": [], "last": "Srivastava", "suffix": ""}, {"first": "M", "middle": [], "last": "Saltz", "suffix": ""}, {"first": "J", "middle": [], "last": "Saltz", "suffix": ""}, {"first": "F", "middle": [], "last": "Wang", "suffix": ""}], "year": 2018, "venue": "AMIA Annual Symposium Proceedings", "volume": "2018", "issn": "", "pages": "", "other_ids": {}}, "BIBREF40": {"ref_id": "b40", "title": "Fuzzy deep belief networks for semi-supervised sentiment classification", "authors": [{"first": "S", "middle": [], "last": "Zhou", "suffix": ""}, {"first": "Q", "middle": [], "last": "Chen", "suffix": ""}, {"first": "X", "middle": [], "last": "Wang", "suffix": ""}], "year": 2014, "venue": "Neurocomputing", "volume": "131", "issn": "", "pages": "312--322", "other_ids": {}}, "BIBREF41": {"ref_id": "b41", "title": "Classification of healthcare data using hybridised fuzzy and convolutional neural network", "authors": [{"first": "B", "middle": [], "last": "Ramasamy", "suffix": ""}, {"first": "A", "middle": ["Z"], "last": "Hameed", "suffix": ""}], "year": 2019, "venue": "Healthcare technology letters", "volume": "6", "issn": "3", "pages": "59--63", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "Example of user-questions about \"COVID-19\"on reddit", "latex": null, "type": "figure"}, "FIGREF1": {"text": "An overview of the research framework for obtaining meaningful results of COVID-19 comments D was computed and obtained from every COVID-19-related comment in a corpus using the following equation:", "latex": null, "type": "figure"}, "FIGREF2": {"text": "Input : A bunch of COVID-19 comments as main document context Output : A bunch of text document in string. 1: d i= Get data(); getting COVID-19 comments as pure data. 2: for d i.row (all record) != last record do 3: d i 2= d i.cleanData(d i); removing stop-words, clean noise 4: d i 2=d i 2.arranged(); processing to arrange dataset. 5: end for 6: return d i 2 as a stringAlgorithm 2 General Process for Semantic-Comment-Mining via Topic ModelInput : A group of COVID-19-related comments as main document context Output : A set of topics from the documents as integer values 1: Pre-process and removing noise and clean data by Algorithm 1. 2: for each topic k \u2208 {1, 2, . . . , k} do 3:", "latex": null, "type": "figure"}, "FIGREF3": {"text": "COVID-19-Related Comments Mining and Topic Recommendation Input : Importing latent-topics through Algoritm 2 Output : Recommended top highlight topics of various aspects of COVID-19 comments 1: Extract semantic contents, trining the LDA Topic Model 2: Detmining the top topics recommended based on the value of the topic probality of all data. 3: Ranking and sorting the most meaningful topics recommended of COVID-19 comments 4: return A list of recommended highlight topics", "latex": null, "type": "figure"}, "FIGREF4": {"text": "Structure of the LSTM designed for COVID-19 sentiment classification.", "latex": null, "type": "figure"}, "FIGREF5": {"text": "Cluster dendrogram of highlight latent topics generated in a COVID-Word cloud visualisation based on the word-weight of the topics.", "latex": null, "type": "figure"}, "FIGREF6": {"text": "Word cloud visualisation based on the word-weight of the topics.", "latex": null, "type": "figure"}, "FIGREF7": {"text": "Word cloud visualisation based on the word-weight of the topics.", "latex": null, "type": "figure"}, "FIGREF8": {"text": "Word cloud visualisation based on the word-weight of the topics.", "latex": null, "type": "figure"}, "FIGREF9": {"text": "Distribution of COVID-19 comments with positive, negative or neutral sentiments of reddit Data of the COVID-19-related comments. We calculated the average sentiment of all comments as negative, positive, or neutral.", "latex": null, "type": "figure"}, "FIGREF10": {"text": "Accuracy performance of the methods for COVID-19 sentimentclassification using various features unobserved (latent) topics, where a topic is defined as a categorical distribution over words. Regarding the top-ranked topics for the COVID-19 comments, it is possible to recognise many words probably related to needs and highlight-discussions of the people or users on reddit.", "latex": null, "type": "figure"}, "TABREF0": {"text": "Semantic Mining of COVID-19 Comments", "latex": null, "type": "table"}, "TABREF3": {"text": "Top 10 topics from COVID-19-related comments on reddit.", "latex": null, "type": "table"}, "TABREF4": {"text": "Topics ranking 11 to 25 from COVID-19-related comments on reddit.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Topic 31 </td><td>\u00a0</td><td>Topic 17 </td><td>Topic 61 </td><td>Topic 1 </td><td>Topic 96\n</td><td>\u00a0</td></tr><tr><td>Rank 11 </td><td>\u00a0</td><td>Rank 12 </td><td>\u00a0</td><td>Rank 13 </td><td>\u00a0</td><td>Rank 14 </td><td>\u00a0</td><td>Rank 15\n</td><td>\u00a0</td></tr><tr><td>cases\n</td><td>Propration : 3.81556 </td><td>Propration : 3.53217 </td><td>Propration : 3.34602 </td><td>Propration : 3.15658 </td><td>Propration : 2.92918\n</td></tr><tr><td>mortality\n</td><td>\u00a0</td><td>shut\n</td><td>virus\n</td><td>test\n</td><td>pretty\n</td><td>food\n</td><td>weeks\n</td><td>\u00a0</td></tr><tr><td>rate\n</td><td>weeks\n</td><td>coronavirus quarantine\n</td><td>\u00a0</td><td>flu\n</td><td>\u00a0</td><td>shit\n</td><td>literally\n</td><td>measures\n</td><td>yesterday action economy spread absolutely closed country expect moment\n</td></tr><tr><td>flu\n</td><td>\u00a0</td><td>years\n</td><td>corona national\n</td><td>country\n</td><td>confirmed control spread singapore\n</td><td>\u00a0</td><td>month\n</td><td>stop\n</td></tr><tr><td>deaths numbers\n</td><td>confirmed population\n</td><td>wait\n</td><td>words\n</td><td>china\n</td><td>america american\n</td><td>guys\n</td><td>panic\n</td></tr><tr><td>wuhan\n</td><td>\u00a0</td><td>mind\n</td><td>countries\n</td><td>stay\n</td><td>real\n</td><td>school\n</td></tr><tr><td>death\n</td><td>good\n</td><td>stupid happening\n</td><td>bet\n</td><td>sars\n</td><td>human\n</td><td>love\n</td><td>live\n</td><td>link\n</td></tr><tr><td>days\n</td><td>\u00a0</td><td>shit\n</td><td>heard\n</td><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>life\n</td><td>close\n</td></tr><tr><td>china\n</td><td>patients reported fatality spread\n</td><td>word\n</td><td>source\n</td><td>pandemic chinese infected\n</td><td>epidemic global remember subreddit\n</td><td>reddit americans\n</td><td>full\n</td><td>early\n</td></tr><tr><td>case\n</td><td>watch\n</td><td>sound\n</td><td>usa\n</td><td>realize\n</td><td>\u00a0</td></tr><tr><td>infected\n</td><td>dangerous\n</td><td>common\n</td><td>bad\n</td><td>death\n</td><td>dude\n</td><td>public lockdown\n</td><td>fine\n</td></tr><tr><td>Topic 93 </td><td>\u00a0</td><td>Topic 4 </td><td>Topic 40 </td><td>Topic 43 </td><td>\u00a0</td><td>Topic 83\n</td><td>\u00a0</td></tr><tr><td>Rank 16 </td><td>\u00a0</td><td>Rank 17 </td><td>Rank 18 </td><td>\u00a0</td><td>Rank 19 </td><td>Rank 20\n</td></tr><tr><td>covid\n</td><td>Propration : 2.22481 </td><td>Propration : 2.1929 </td><td>Propration : 2.09387 </td><td>Propration : 1.91949 </td><td>Propration : 1.73082\n</td></tr><tr><td>elderly\n</td><td>pay\n</td><td>tax\n</td><td>fucking\n</td><td>lmao\n</td><td>trump\n</td><td>\u00a0</td><td>home\n</td><td>\u00a0</td></tr><tr><td>young\n</td><td>older\n</td><td>money\n</td><td>years\n</td><td>fuck\n</td><td>\u00a0</td><td>cdc\n</td><td>states corona federal pandemic united\n</td><td>sick\n</td><td>stores essential company businesses\n</td></tr><tr><td>risk\n</td><td>years\n</td><td>\u00a0</td><td>employees\n</td><td>government\n</td><td>supposed treatment\n</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>fever\n</td><td>healthy\n</td><td>companies company insurance\n</td><td>leave\n</td><td>guy\n</td><td>ass\n</td><td>president government\n</td><td>working workers\n</td></tr><tr><td>immune\n</td><td>long\n</td><td>bill\n</td><td>man\n</td><td>tested\n</td><td>covid\n</td><td>store\n</td><td>told\n</td></tr><tr><td>age\n</td><td>die\n</td><td>paid\n</td><td>taxes\n</td><td>\u00a0</td><td>dumb\n</td><td>\u00a0</td><td>pence\n</td><td>stay\n</td><td>grocery\n</td></tr><tr><td>sick\n</td><td>\u00a0</td><td>paying\n</td><td>healthcare\n</td><td>stupid fucked\n</td><td>sell\n</td><td>country coronavirus administration response america\n</td><td>americans\n</td><td>\u00a0</td><td>jobs\n</td></tr><tr><td>cough\n</td><td>younger coronavirus asthma conditions\n</td><td>free\n</td><td>job\n</td><td>sick\n</td><td>canada\n</td><td>hoax\n</td><td>business employees\n</td><td>paid\n</td></tr><tr><td>life\n</td><td>cost\n</td><td>\u00a0</td><td>rate\n</td><td>damn\n</td><td>\u00a0</td><td>job\n</td><td>\u00a0</td></tr><tr><td>cold\n</td><td>afford\n</td><td>business income\n</td><td>takes\n</td><td>idiots\n</td><td>national million\n</td><td>weeks\n</td><td>restaurants customers\n</td></tr><tr><td>Topic 86 </td><td>\u00a0</td><td>Topic 12 </td><td>Topic 44 </td><td>Topic 99 </td><td>\u00a0</td><td>Topic 88\n</td><td>\u00a0</td></tr><tr><td>Rank 21 </td><td>\u00a0</td><td>Rank 22 </td><td>Rank 23 </td><td>\u00a0</td><td>Rank 24 </td><td>Rank 25\n</td></tr><tr><td>masks\n</td><td>Propration : 1.59421 </td><td>Propration : 1.54827 </td><td>Propration : 1.53468 </td><td>Propration : 1.48268 </td><td>Propration : 1.44486\n</td></tr><tr><td>medical\n</td><td>test\n</td><td>\u00a0</td><td>market\n</td><td>war\n</td><td>school\n</td><td>closed\n</td><td>food\n</td><td>store\n</td></tr><tr><td>mask\n</td><td>sick\n</td><td>\u00a0</td><td>market confirmed numbers\n</td><td>stock\n</td><td>\u00a0</td><td>kids\n</td><td>weeks\n</td><td>buy\n</td><td>days\n</td></tr><tr><td>wearing\n</td><td>\u00a0</td><td>testing tested\n</td><td>economy\n</td><td>global buying\n</td><td>schools\n</td><td>care\n</td><td>water\n</td><td>stuff\n</td></tr><tr><td>wear\n</td><td>public supply shortage\n</td><td>tests\n</td><td>free\n</td><td>buy\n</td><td>parts\n</td><td>flu\n</td><td>\u00a0</td><td>stock\n</td><td>supply\n</td></tr><tr><td>face\n</td><td>\u00a0</td><td>negative\n</td><td>years\n</td><td>chain\n</td><td>home\n</td><td>husband travel students\n</td><td>\u00a0</td><td>panic\n</td></tr><tr><td>\u00a0</td><td>hands\n</td><td>symptoms positive\n</td><td>cases\n</td><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>buying supplies\n</td><td>\u00a0</td></tr><tr><td>surgical protect protection effective infected\n</td><td>\u00a0</td><td>flu\n</td><td>day\n</td><td>supply economic deaths production markets\n</td><td>stocks manufacturing\n</td><td>parents family\n</td><td>cdc\n</td><td>rice\n</td><td>stocked family canned prepping prepared\n</td></tr><tr><td>prevent workers gloves doctors\n</td><td>cdc\n</td><td>doctor\n</td><td>goods\n</td><td>close\n</td><td>closing\n</td><td>bought\n</td></tr><tr><td>kits\n</td><td>cough\n</td><td>panic\n</td><td>sick\n</td><td>told\n</td><td>weeks\n</td></tr><tr><td>fever\n</td><td>labs\n</td><td>run\n</td><td>children\n</td><td>stay\n</td><td>eat\n</td></tr></table></body></html>"}, "TABREF5": {"text": "Examples of COVID-19 comments from the reddit corpus", "latex": null, "type": "table"}}, "back_matter": [{"text": "We acknowledge SciTechEdit International, LLC (Highlands Ranch, CO, USA) for providing pro bono professional English-language editing of this article. This work has been awarded by the National Natural Science ", "cite_spans": [], "ref_spans": [], "section": "Acknowledgements"}, {"text": "All procedures performed in studies involving human participants were in accordance with the ethical standards of the institutional and/or national research committee and with the 1964 Helsinki declaration and its later amendments or comparable ethical standards.Declaration of Conflict of Interest : All authors declare no conflict of interest directly related to the submitted work.", "cite_spans": [], "ref_spans": [], "section": "Ethical Approval"}]}