{"paper_id": "2a2a305bd55d7c04c61446077320478f3402ab32", "metadata": {"title": "Classification Aware Neural Topic Model and its Application on a New COVID-19 Disinformation Corpus", "authors": [{"first": "Xingyi", "middle": [], "last": "Song", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Sheffield", "location": {"settlement": "Sheffield", "country": "UK"}}, "email": "x.song@sheffield.ac.uk"}, {"first": "Johann", "middle": [], "last": "Petrak", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Sheffield", "location": {"settlement": "Sheffield", "country": "UK"}}, "email": "johann.petrak@sheffield.ac.uk"}, {"first": "Ye", "middle": [], "last": "Jiang", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Sheffield", "location": {"settlement": "Sheffield", "country": "UK"}}, "email": "yjiang18@sheffield.ac.uk"}, {"first": "Iknoor", "middle": [], "last": "Singh", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Sheffield", "location": {"settlement": "Sheffield", "country": "UK"}}, "email": "i.singh@sheffield.ac.uk"}, {"first": "Diana", "middle": [], "last": "Maynard", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Sheffield", "location": {"settlement": "Sheffield", "country": "UK"}}, "email": "d.maynard@sheffield.ac.uk"}, {"first": "Kalina", "middle": [], "last": "Bontcheva", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Sheffield", "location": {"settlement": "Sheffield", "country": "UK"}}, "email": "k.bontcheva@sheffield.ac.uk"}]}, "abstract": [{"text": "The explosion of disinformation related to the COVID-19 pandemic has overloaded factcheckers and media worldwide. To help tackle this, we developed computational methods to support COVID-19 disinformation debunking and social impacts research. This paper presents: 1) the currently largest available manually annotated COVID-19 disinformation category dataset; and 2) a classificationaware neural topic model (CANTM) that combines classification and topic modelling under a variational autoencoder framework. We demonstrate that CANTM efficiently improves classification performance with low resources, and is scalable. In addition, the classificationaware topics help researchers and end-users to better understand the classification results.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "COVID-19 is not just a global disease pandemic, but has also led to an 'infodemic' 1 (WHO, 2020) and a 'disinfodemic' 2 (Posetti and Bontcheva, 2020). The increased volume (Brennen et al., 2020) of COVID-19 related disinformation has already caused public mistrust (Clare and Christie, 2020) and even real-life damage to health and 5G masts. 3 Consequently fact-checkers and media worldwide are having to triage carefully their limited resources in order to uncover and debunk quickly and effectively the most damaging kinds of COVID-19 disinformation. For example, Brennen et al. (2020) found that most disinformation in the early stage of the pandemic made false claims related to actions and statements by public authorities.", "cite_spans": [{"start": 172, "end": 194, "text": "(Brennen et al., 2020)", "ref_id": null}, {"start": 265, "end": 291, "text": "(Clare and Christie, 2020)", "ref_id": "BIBREF5"}, {"start": 342, "end": 343, "text": "3", "ref_id": null}, {"start": 566, "end": 587, "text": "Brennen et al. (2020)", "ref_id": null}], "ref_spans": [], "section": "Introduction"}, {"text": "Guided by these needs, we developed an automatic COVID-19 disinformation classifier and made this available for testing and use by professionals at AFP and First Draft. 4 The challenges of this task are that: 1) there is no sufficiently large existing dataset annotated with COVID-19 disinformation categories, which can be used to train and test machine learning models. 2) Due to the time-consuming nature of manual fact-checking and disinformation categorisation, manual corpus annotation is expensive and slow to create. Therefore the classifier should robustly handle training with low resources. 3) COVID-19 disinformation classification is a fast-moving research area, thus the model should provide suggestions to researchers about relevant categories. 4) The classifier and decisions should be self-explanatory, enabling journalists to understand the rationale for the auto-assigned category.", "cite_spans": [{"start": 148, "end": 170, "text": "AFP and First Draft. 4", "ref_id": null}], "ref_spans": [], "section": "Introduction"}, {"text": "To address the first challenge, we created a new COVID-19 disinformation classification dataset. The corpus contains disinformation (e.g. false information or misleading tweets) debunked by the CoronaVirusFacts Alliance led by the International Fact-checking Network (IFCN) and has been manually annotated with the categories defined in the most recent social science research on COVID-19 disinformation (Brennen et al., 2020) .", "cite_spans": [{"start": 404, "end": 426, "text": "(Brennen et al., 2020)", "ref_id": null}], "ref_spans": [], "section": "Introduction"}, {"text": "For the remaining challenges, we propose a Classification Aware Neural Topic Model (CANTM) which combines the benefits of BERT (Devlin et al., 2019) with a Variational Autoencoder (VAE) (Kingma and Welling, 2013; Rezende et al., 2014) based document model (Miao et al., 2016) to provide:", "cite_spans": [{"start": 122, "end": 148, "text": "BERT (Devlin et al., 2019)", "ref_id": null}, {"start": 186, "end": 212, "text": "(Kingma and Welling, 2013;", "ref_id": null}, {"start": 213, "end": 234, "text": "Rezende et al., 2014)", "ref_id": null}, {"start": 256, "end": 275, "text": "(Miao et al., 2016)", "ref_id": null}], "ref_spans": [], "section": "Introduction"}, {"text": "1. Robust classification performance especially on a small training set -instead of training the classifier directly on the original feature representation, the classifier is trained based on generated latent variables from the VAE (Kingma et al., 2014) . In this case the classifier has never seen the 'real' training data during the training, thus reducing the chance of over-fitting. Our experiment shows that combining BERT with the VAE framework improves the classification results on a small dataset, and is also scalable to larger datasets. 2. Ability to discover the hidden topics related to the pre-defined classes -the success of the VAE as a topic model 5 has already been proven in previous research (Miao et al., 2016 (Miao et al., , 2017 Card et al., 2018) . We further adapt the VAE-based topic modelling to be classification-aware, by proposing a stacked VAE and introducing the classification information directly in the latent topic generation. 3. The classifier is self-explaining 6 -in CANTM the same latent variable (topic) is used in both the classifier and topic modelling. The topic can be seen as an explanation of the classification model. We further introduce 'classassociated topics' that directly map the topic words to classifier classes. This enables the inspection of topics related to a class, thus providing a 'global' explanation of the classifier.", "cite_spans": [{"start": 232, "end": 253, "text": "(Kingma et al., 2014)", "ref_id": null}, {"start": 712, "end": 730, "text": "(Miao et al., 2016", "ref_id": null}, {"start": 731, "end": 751, "text": "(Miao et al., , 2017", "ref_id": null}, {"start": 752, "end": 770, "text": "Card et al., 2018)", "ref_id": "BIBREF2"}], "ref_spans": [], "section": "Introduction"}, {"text": "The main contributions of this paper are: 1) A new COVID-19 disinformation corpus with manually annotated categories. 2) A BERT language model with a VAE topic modelling framework, which shows a performance improvement (over using BERT alone) in a low resource classifier training setting.", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "3) The CANTM model, which takes classification information into account for topic generation. 4) The use of topic modelling to introduce 'class-associated' topics as a global explanation of the classifier. The corpus and source code of this work will be open-source, and the web service and API will be publicly available.", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "The corpus was created in three stages. Firstly, we collected COVID-19 related debunks of disinformation until 13th April, 2020 published on the 5 Some researchers distinguish 'document model' from 'topic model ' (Miao et al., 2017; Korshunova et al., 2019) . For simplicity, we consider both as a topic model. 6 BERT attention weights could also be treated to explain the decision, but this is outside the scope of this paper. IFCN Poynter website 7 . The data has the following fields derived from the published html tags:", "cite_spans": [{"start": 211, "end": 232, "text": "' (Miao et al., 2017;", "ref_id": null}, {"start": 233, "end": 257, "text": "Korshunova et al., 2019)", "ref_id": null}, {"start": 311, "end": 312, "text": "6", "ref_id": null}], "ref_spans": [], "section": "COVID-19 Disinformation Category Dataset"}, {"text": "\u2022 'Claim': claim of the disinformation, rephrased by the IFCN fact-checker; \u2022 'Explanation': the explanation of why this is a false claim as provided by the fact checkers; \u2022 Source link': link to original page of the debunk, as published on the fact-checking organisation's website; \u2022 'Date': date of publication on IFC Poynter website.", "cite_spans": [], "ref_spans": [], "section": "COVID-19 Disinformation Category Dataset"}, {"text": "Due to the language restrictions of our human annotators, we could only focus on debunks in English. Thus we applied a language detector 8 over the source of the debunk and filtered out all non-English debunks automatically. In total, 1,480 debunked claims remained. The next stage involved manual annotation, where an adapted version of Label Studio 9 was used as a web-based annotation tool. The claim, explanation and source link were all provided to the annotators, who assigned to each text the most relevant one of 10 COVID-19 disinformation categories (see Table 1 ) and indicated their confidence (from 0-9) in their decision. Originally, these categories were proposed in a recent social science analysis of a small sample of 225 debunks (Brennen et al., 2020) . We adopted them unchanged, except for widening their 'Public preparedness' category to become 'Public Reaction' and to include also disinformation about public protests and other civil disobedience which are a more recent phenomenon. In addition, we added a new category 'Cannot determine (None)' to enable annotators to flag cases of COVID-19 disinformation that did not fit any of the other categories.", "cite_spans": [{"start": 747, "end": 769, "text": "(Brennen et al., 2020)", "ref_id": null}], "ref_spans": [{"start": 564, "end": 571, "text": "Table 1", "ref_id": "TABREF1"}], "section": "COVID-19 Disinformation Category Dataset"}, {"text": "We recruited 27 volunteers for the annotation, and randomly split the data into batches of 20 debunks. In the first round, all annotators worked on unique batches. In the second round, annotators received randomised debunks from the first round, which were then used to measure inter-annotator agreement (IAA) on COVID-19 disinformation classification.", "cite_spans": [], "ref_spans": [], "section": "COVID-19 Disinformation Category Dataset"}, {"text": "The exercise produced 2,192 classified debunks (see Table 2 ). Amongst these, 424 samples were double-or multiple-annotated, from which we calculate the IAA. At this stage, vanilla Cohen's Kappa (Cohen, 1960) was only 0.46.", "cite_spans": [{"start": 195, "end": 208, "text": "(Cohen, 1960)", "ref_id": "BIBREF6"}], "ref_spans": [{"start": 52, "end": 59, "text": "Table 2", "ref_id": "TABREF3"}], "section": "COVID-19 Disinformation Category Dataset"}, {"text": "To increase the data quality and provide a good training sample for our ML model, we applied a cleaning step to filter the annotations. We first measured annotator quality by observing agreement change when removing an (anonymous) annotator. This annotator quality was scored based on the magnitude of score variance. Based on this, we then removed annotations from the two annotators with the lowest scores.", "cite_spans": [], "ref_spans": [], "section": "COVID-19 Disinformation Category Dataset"}, {"text": "We also measured the impact of the annotator confidence score on the annotation agreement and the amount of filtered data, and set a confidence threshold for each annotator, based on the quality check from the first round (for most annotators, this threshold was 6). Any annotation below this threshold was filtered out.", "cite_spans": [], "ref_spans": [], "section": "COVID-19 Disinformation Category Dataset"}, {"text": "Finally, 1,293 debunks remained with at least one reliable classification, and IAA was boosted to 0.7336 (in percentage) and Cohen's Kappa to 0.7040. The final dataset was produced by merging the multiple-annotated debunks on the basis of: 1) majority agreement between the annotators where possible; 2) confidence score -if there is no majority agreement, we use the highest confidence score. Table 3 shows the statistics of the merged dataset in each category. The category distribution is consistent with that found in Brennen et al. (2020) . ", "cite_spans": [{"start": 522, "end": 543, "text": "Brennen et al. (2020)", "ref_id": null}], "ref_spans": [{"start": 394, "end": 401, "text": "Table 3", "ref_id": "TABREF5"}], "section": "COVID-19 Disinformation Category Dataset"}, {"text": "In this section, we review some related work, using this to explain the motivation for our model. Then we describe our CANTM model in Section 3.2.", "cite_spans": [], "ref_spans": [], "section": "Model"}, {"text": "Other related work is reviewed in Section 5.", "cite_spans": [], "ref_spans": [], "section": "Model"}, {"text": "Miao et al. (2016) introduce a generative neural variational document model (NVDM) that models the document (x) likelihood p(x) using a variational autoencoder (VAE), which can be described as:", "cite_spans": [], "ref_spans": [], "section": "Background and Preliminaries"}, {"text": "Where p(z) is the prior distribution of latent variable z. q(z|x) is the inference network (encoder) used to approximate the posterior distributions p(z|x). p(x|z) is the generation network (decoder) to reconstruct the document based on latent variable (topics) z \u223c q(z|x) sampled from the inference network. According to Equation 1, maximising the ELBO (evidence lower bound) is equivalent to maximising the p(x) and minimising the difference between q(z|x) and p(z|x). Therefore, maximising ELBO will be the objective function in the NVDM or VAE framework, or negative ELBO for gradient descent optimisation. The latent variable z then can be treated as the latent topics of the document.", "cite_spans": [], "ref_spans": [], "section": "Background and Preliminaries"}, {"text": "NVDM is an unsupervised model, hence we have no control on the topic generation. In order to uncover the topics related to the target y (e.g. category, sentiment or coherence) in which we are interested, we can consider several previous approaches. The Topic Coherence Regularization (NTR) (Ding et al., 2018) applies the topic coherence as additional loss (i.e. loss L = \u2212ELBO + C) to regularise the model to generate more coherent topics. SCHOLAR (Card et al., 2018) directly inserts the target information into the encoder (i.e. q(z|x, y)), making the latent variable also dependent on the target. However, when target information is missing at application time, SCHOLAR treats the target input as a missing feature (i.e. all zero vector) or all possible combinations. Hence the latent variable becomes less dependent on the target.", "cite_spans": [{"start": 290, "end": 309, "text": "(Ding et al., 2018)", "ref_id": null}, {"start": 449, "end": 468, "text": "(Card et al., 2018)", "ref_id": "BIBREF2"}], "ref_spans": [], "section": "Background and Preliminaries"}, {"text": "Inspired by the stacked VAE of Kingma et al. (2014) , we combined ideas from NTR and SCHOLAR. We stacked a classifier-regularised VAE (M1) and a classifier-aware VAE (M2) enabling the provision of robust latent topic information even at testing time without label information.", "cite_spans": [{"start": 31, "end": 51, "text": "Kingma et al. (2014)", "ref_id": null}], "ref_spans": [], "section": "Background and Preliminaries"}, {"text": "The training sample D = (x, x bow , y) is a triple of the BERT word-pieces sequence representation of the document (x), a bag-of-words representation of the document (x bow ) and its associate target label y.", "cite_spans": [], "ref_spans": [], "section": "Classifier Aware Neural Topic Model (CANTM)"}, {"text": "The general architecture of our model is illustrated in Figure 1 . CANTM is a stacked VAE containing 6 sub-modules:", "cite_spans": [], "ref_spans": [{"start": 56, "end": 64, "text": "Figure 1", "ref_id": "FIGREF0"}], "section": "Classifier Aware Neural Topic Model (CANTM)"}, {"text": "q(z s |x,\u0177) 6. M2 decoder (or M2 generation network)", "cite_spans": [], "ref_spans": [], "section": "Classifier Aware Neural Topic Model (CANTM)"}, {"text": "p(x bow |\u0177, z s ) and p(\u0177|z s ) Sub-modules 1 and 2 implement a VAE similar to NVDM. The modification over original NVDM is that instead of bag-of-words (x bow ) input and output to the model, our input is a BERT word-pieces sequence representation of the original document (x). The reason for this modification is that x can be seen as a grammar-enriched x bow , and we could capture better semantic representation in the hidden layers (e.g. though pre-trained BERT) and benefit the classification and topic generation. Also, q(z|x) is an approximation of p(z|x bow ), and they do not have to follow the same condition (Kingma and Welling, 2013), as our model is still under the VAE framework. Sub-modules 5 and 6 implement another VAE that models the joint probability of document x bow and label\u0177. Note that the label in M2 is a classifier prediction, hence this label information will always be available for M2 VAE.", "cite_spans": [], "ref_spans": [], "section": "Classifier Aware Neural Topic Model (CANTM)"}, {"text": "To apply CANTM to unlabelled test data, we fix the M1 weights that are pre-trained with labelled data, and only train the M2 model. In Sections 3.2.1 to 3.2.5, we will describe the detail of each sub-module.", "cite_spans": [], "ref_spans": [], "section": "Classifier Aware Neural Topic Model (CANTM)"}, {"text": "The M1 encoder is illustrated in the yellow part of Figure 1 . During the encoding process, the input x is first transformed into a BERT-enriched representation h using a pre-trained BERT model. We use the CLS token output from BERT as h. Then linear transformations l 1 (h) and l 2 (h) transform the h into parameters of variational distribution that are used to sample latent variable z. The variational distribution is a Gaussian distribution (N (\u00b5, \u03c3)) The M1 Encoder is represented in Equation 2 q(z|x) = N (\u00b5, \u03c3)", "cite_spans": [], "ref_spans": [{"start": 52, "end": 60, "text": "Figure 1", "ref_id": "FIGREF0"}], "section": "M1 Encoder"}, {"text": "Following previous approaches (Rezende et al., 2014; Kingma and Welling, 2013; Miao et al., 2016) , a re-parameterisation trick is applied to allow back-propagation to go though the random node.", "cite_spans": [{"start": 30, "end": 52, "text": "(Rezende et al., 2014;", "ref_id": null}, {"start": 53, "end": 78, "text": "Kingma and Welling, 2013;", "ref_id": null}, {"start": 79, "end": 97, "text": "Miao et al., 2016)", "ref_id": null}], "ref_spans": [], "section": "M1 Encoder"}, {"text": "where is random noise sampled from a 0 mean and variance 1 Gaussian distribution. In the decoding process (next section), the document is reconstructed from latent variable z, hence z can be considered as the document topic.", "cite_spans": [], "ref_spans": [], "section": "M1 Encoder"}, {"text": "The decoding process (red part in Figure 1 ) is to reconstruct x bow from latent variable z. This is modelled by a fully connected feed-forward (FC) layer with softmax activation (sigmoid activation normalised by softmax function. For the rest of the paper we will describe this as softmax activation for simplicity). The likelihood of the reconstruction p(x bow |z) can be calculated by", "cite_spans": [], "ref_spans": [{"start": 34, "end": 42, "text": "Figure 1", "ref_id": "FIGREF0"}], "section": "M1 Decoder"}, {"text": "Where R \u2208 R |z|\u00d7|V | , and |V | is the vocabulary size. R is a learnable weight for mapping between topics and words. The topic words for each topic can be extracted according to this weight. is the dot product.", "cite_spans": [], "ref_spans": [], "section": "M1 Decoder"}, {"text": "The classifier\u0177 = sof tmax(F C(z)) is a softmax activated FC layer. It is based on the same latent variable z from the M1 encoder. Since the M1 VAE and classifier are jointly trained based on z, it can be seen as a 'class regularized topic' and also serve ", "cite_spans": [], "ref_spans": [], "section": "M1 Classifier and Classifier Decoder"}, {"text": "Where R ct \u2208 R |y|\u00d7|V | is a learnable weight for 'class-associated topic' word mapping.", "cite_spans": [], "ref_spans": [], "section": "M1 Classifier and Classifier Decoder"}, {"text": "The encoding process of M2 (blue part in Figure  1 ) is similar to M1, but instead of only encoding x, M2 encodes both the document and predicted label from the M1 classifier q(z s |x,\u0177). In the M2 encoder process, we first concatenate (\u2295) the BERT representation h and predicted label\u0177, then merge them through a leaky rectifier (LRelu)(Maas et al., 2013) activated FC layer. We refer to this as nonLin in the remainder of the paper.", "cite_spans": [], "ref_spans": [{"start": 41, "end": 50, "text": "Figure  1", "ref_id": "FIGREF0"}], "section": "M2 Encoder"}, {"text": "As for the M1 encoder, a linear transformation then maps the merged feature m to the parameters of the variational distribution represented by the latent variable of M2 model z s . The variational distribution is a Gaussian N (\u00b5 s , \u03c3 s ):", "cite_spans": [], "ref_spans": [], "section": "M2 Encoder"}, {"text": "The decoding process of M2 p(x bow ,\u0177|z s ) is divided into two decoding steps (p(x bow |\u0177, z s ) and p(\u0177|z s )) by Bayes Chain Rule.", "cite_spans": [], "ref_spans": [], "section": "M2 Decoder"}, {"text": "The step p(\u0177|z s ) can be considered as M2 classifier, calculated by softmax FC layer, the likelihood function is modelled as p(\u0177|z s ) = sof tmax(F C(z s )) \u0177. The M2 classifier will not be used for classification in this work, only for the loss calculation (see Section 3.2.6).", "cite_spans": [], "ref_spans": [], "section": "M2 Decoder"}, {"text": "In step p(x bow |\u0177, z s ), we first merge\u0177 and z s using nonLin layer t = nonLin(\u0177 \u2295 z s ) where t is a 'classification aware topic'. Then x bow is reconstructed using a softmax layer. The likelihood function is:", "cite_spans": [], "ref_spans": [], "section": "M2 Decoder"}, {"text": "where R s \u2208 R |zs|\u00d7|V | is a learnable weight for the 'classification aware topic' word mapping.", "cite_spans": [], "ref_spans": [], "section": "M2 Decoder"}, {"text": "The objective of CANTM is to: 1) maximise ELBO x bow for M1 VAE; 2) maximise ELBO x bow,\u0177 for M2 VAE; 3) minimise crossentropy loss L cls for M1 classifier and 4) maximise the log likelihood of M1 class decoder log[p(x bow |\u0177)]. Hence the loss function 10 for", "cite_spans": [], "ref_spans": [], "section": "Loss Function"}, {"text": "where p(z) and p(z s ) are zero mean diagonal multivariate Gaussian priors (N (0, I)), \u03bb = vocabSize/numclass is a hyperparameter controlling the importance classifier loss.", "cite_spans": [], "ref_spans": [], "section": "Loss Function"}, {"text": "In this section, we evaluate the performance of CANTM on both COVID-19 disinformation classification and topic modelling (with 50 topics). Three experiments are presented. We first compare the performance of CANTM against baseline approaches on the COVID-19 corpus (Section 4.1); then we apply CANTM to the IMDB sentiment corpus (Maas et al., 2011) to test its compatibility with other tasks with larger data (Section 4.3.1); finally, in Section 4.3 we discuss topic interpretability by visualising the topic words. We compare to the following: BERT, SCHOLAR, NVDM, and LDA. The settings of CANTM and baselines are: As with CANTM, we use BERT [CLS] output as BERT representation, and an additional 50 dimensional feed-forward hidden layer (with leaky ReLU activation) after that. 12 Only the last transformer encoding layer (layer 11) is unlocked for fine-tuning, the rest of the BERT weights were frozen for this experiment. The Pytorch 13 implementation of the Adam optimiser (Kingma and Ba, 2014) is used in the training with default settings. The batch size for training is 32. All BERT-related (CANTM, NVDMb) implementations in this paper follow the same settings.", "cite_spans": [{"start": 329, "end": 348, "text": "(Maas et al., 2011)", "ref_id": null}], "ref_spans": [], "section": "Experiments"}, {"text": "\u2022 CANTM (our proposed method): We use the same BERT implementation and settings as described above. The sampling size (number of samples z and z s drawn from the encoder) in training and testing are 10 and 1 respectively, and we only use expected value (\u00b5) of q(z|x) for the classification at testing time. Unless mentioned otherwise, the topics reported from CANTM are 'classificationaware'.", "cite_spans": [], "ref_spans": [], "section": "Experiments"}, {"text": "\u2022 NVDM (Miao et al., 2016) : We re-implement NVDM 14 , with two versions: 1) original NVDM as described in (Miao et al., 2016) (\"NVDMo\" in the results ); 2) NVDM with BERT representation (\"NVDMb\" in the results).", "cite_spans": [{"start": 7, "end": 26, "text": "(Miao et al., 2016)", "ref_id": null}, {"start": 107, "end": 126, "text": "(Miao et al., 2016)", "ref_id": null}], "ref_spans": [], "section": "Experiments"}, {"text": "\u2022 SCHOLAR (Card et al., 2018) : We use the original author implementation 15 with all default settings (except the vocabulary size and number of topics).", "cite_spans": [{"start": 10, "end": 29, "text": "(Card et al., 2018)", "ref_id": "BIBREF2"}], "ref_spans": [], "section": "Experiments"}, {"text": "\u2022 Latent Dirichlet Allocation (LDA) (Blei et al., 2003) : the Gensim (\u0158eh\u016f\u0159ek and Sojka, 2010) implementation is used.", "cite_spans": [{"start": 36, "end": 55, "text": "(Blei et al., 2003)", "ref_id": "BIBREF0"}], "ref_spans": [], "section": "Experiments"}, {"text": "All bag-of-words inputs are pre-processed using the script publicly available from Card et al. (2018) . 15 The vocabulary sizes are 2000 for the COVID-19 set and 5000 for the IMDB set (consistent with (Card et al., 2018) to make a fair comparison) based on word counts from each set.", "cite_spans": [{"start": 83, "end": 101, "text": "Card et al. (2018)", "ref_id": "BIBREF2"}, {"start": 104, "end": 106, "text": "15", "ref_id": null}, {"start": 201, "end": 220, "text": "(Card et al., 2018)", "ref_id": "BIBREF2"}], "ref_spans": [], "section": "Experiments"}, {"text": "In this experiment, the input text for each instance is the combination of the Claim and the Explanation (the average text length is 23 words). The results are reported based on 5-fold cross validation. Since class distribution is imbalanced, we report the macro F-1 measure (F-1) 16 and accuracy (Acc.) for the classification task. For the topic modelling task, the metrics reported are perplexity (Perp.) and non-negative point-wise mutual information (NPMI (Chang et al., 2009; Newman et al., 2010) ). As in previous work (Miao et al., 2016; Card et al., 2018) , the perplexity is estimated by ELBO, and NPMI scores were calculated based on the top 10 topic words of each topic. Table 13 . BERT as a strong baseline outperforms SCHOLAR in accuracy by more than 10% and almost 18% F-1 measure. This is expected, because BERT is a discriminative model pre-trained on large corpora and with a much more complex model structure than SCHOLAR. Our model CANTM shows almost 5% increase in accuracy and more than 1% F-1 further improvement over BERT. Training on latent variables with multi-task loss is thus an efficient way to train on a small dataset even with a pre-trained embedding/language model. In the topic modelling task, using BERT in NVDM has better topic coherence than the vanilla NVDM, but also increases the perplexity. LDA has high perplexity in the COVID-19 experiment, which may be because of the relatively small dataset and short document length (average 19 words after pre-processing and vocabulary filtering), but LDA still has relatively better topic coherence than both NVDM versions. CANTM has the best perplexity performance, while SCHOLAR has the best coherence score. It is very difficult to draw conclusions from the topic modelling task performance; in Section 4.3 we will discuss the lack of correlation between topic interpretability and topic coherence.", "cite_spans": [{"start": 281, "end": 283, "text": "16", "ref_id": null}, {"start": 460, "end": 480, "text": "(Chang et al., 2009;", "ref_id": "BIBREF3"}, {"start": 481, "end": 501, "text": "Newman et al., 2010)", "ref_id": null}, {"start": 525, "end": 544, "text": "(Miao et al., 2016;", "ref_id": null}, {"start": 545, "end": 563, "text": "Card et al., 2018)", "ref_id": "BIBREF2"}], "ref_spans": [{"start": 682, "end": 690, "text": "Table 13", "ref_id": "TABREF1"}], "section": "COVID-19 Disinformation Classification"}, {"text": "The IMDB sentiment corpus contains 50,000 movie reviews annotated with positive and negative sentiment. The number of positive and negative labels is balanced in this corpus (25,000 positive, 25,000 negative, average document length is 282 words). We use the original train-test split for evaluation, and report the results on the test set only. All settings including vocabulary size and pre-processing steps exactly follow Card et al. (2018) . Hence the NVDM, LDA and SCHOLAR results are as reported in Card et al. (2018) .", "cite_spans": [{"start": 425, "end": 443, "text": "Card et al. (2018)", "ref_id": "BIBREF2"}, {"start": 505, "end": 523, "text": "Card et al. (2018)", "ref_id": "BIBREF2"}], "ref_spans": [], "section": "IMDB Sentiment Experiment"}, {"text": "The IMDB results are shown in Table 14 shows the topics from CANTM and SCHOLAR with the best and worst NPMI scores. We found there is no strong correlation between coherence score and topic interpretability in supervised topic models. 17 The SCHOLAR topics are included here to demonstrate this is not just the case in CANTM. With knowledge of the predefined classes (see Table 1 ), the lowest coherence topic (Row 2, CANTM 0.04) in Table 14 can be easily interpreted as a mixture of the topics 'General Medical advice' and 'Prominent actors', while the highest two topics (CANTM 0.50 and SCHOLAR 0.58) are more general words appearing in the text. Table 7 shows the CANTM-generated IMDB topics. We select two topics, based on the best and worst topic coherence score. Since IMDB is a sentiment-labelled data set, we can clearly see that the topics generated here are the sentiment and aspect words. Row 1 is the topic related to negative sentiment. Row 2 shows the topics related to positive sentiment in animation movies. Again, the lowest coherence CANTM topic is still highly interpretable.", "cite_spans": [{"start": 235, "end": 237, "text": "17", "ref_id": null}], "ref_spans": [{"start": 30, "end": 38, "text": "Table 14", "ref_id": "TABREF1"}, {"start": 372, "end": 379, "text": "Table 1", "ref_id": "TABREF1"}, {"start": 433, "end": 441, "text": "Table 14", "ref_id": "TABREF1"}, {"start": 649, "end": 656, "text": "Table 7", "ref_id": "TABREF11"}], "section": "IMDB Sentiment Experiment"}, {"text": "In Section 3.2.3 we discussed the Class-Associated Topics, which can be used to visualise the word distribution in the training data associated with the pre-defined classes. Table 8 shows an example of topic words of class-associated topics. As the topics are guided by the classifier, the topic words are strongly associated with the pre-defined classes, and can be used to discover concepts related to the classes. For example, temperature (topic word 'hot' in GenMedAdv) is one of the most connected concepts to GenMedAdv. In addition, this feature could be potentially used to check the biases of the trained classifier. ", "cite_spans": [], "ref_spans": [{"start": 174, "end": 181, "text": "Table 8", "ref_id": "TABREF13"}], "section": "Class-Associated Topics"}, {"text": "To test the CANTM with unlabelled data, we collected further 4587 COVID-19 debunks (until 26th May 2020) from IFCN (the same collection as described in Section 2). In the training, we reuse the pre-trained M1 model (with labelled data), and only train M2 model with \u2212ELBO x bow,\u0177 loss. Table 9 shows the example classification-aware topics trained with newly collected data. We can clearly see these topics are still classification-related even without labels. (Row 1: virus transmission; Row 2:Public authority; Row 3:Medical advice and Row 4:Conspiracies)", "cite_spans": [], "ref_spans": [], "section": "CANTM with Unlabelled COVID-19 Disinformation"}, {"text": "In addition to the work cited in the previous sections, the following research is related to our approach: VAE based topic/document modelling e.g. Mnih and Gregor (2014) trained a VAE based document model using the REINFORCE algorithm police bat cdc spread visit tourists answer data july clip mention conference professor since april quarantined starting spoke supporting please health ever salt swat ginger pope uses welfare hands singapore people vaccine since weapon hospital scientific man group cells working ", "cite_spans": [], "ref_spans": [], "section": "Further Related Work"}, {"text": "In this paper, we introduced the COVID-19 disinformation corpus, which has 10 manually annotated categories of debunked COVID-19 disinformation. After quality control and a filtering process, the inter-annotator agreement average Cohen's Kappa is 0.70. We also present a new classification-aware topic model, that combines the BERT language model with the VAE document model framework and demonstrate improved classification accuracy over a vanilla BERT model. In addition, the classification-aware topics provide class related topics, which are: a) an efficient way to discover the class of (pre-defined) related topics, and b) a proxy explanation of classifier decisions. \u2022 Public authority: Claims about policy, action, or communication by a public authority (e.g. government department, police, fire brigade, government officials), including claims about WHO guidelines and recommendations as well as those about governments' action or advice.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "\u2022 Community spread and impact: Claims about people, groups, or individuals with regard to how the virus is spreading (internationally, regionally, or within more specific communities); impact on people, groups (including religions and ethnic minorities), or individuals; deaths, etc.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "\u2022 Medical advice, self-treatments, and virus effects: Claims about health remedies, self-treatments, self-diagnosis, signs and symptoms, effects of the virus, etc.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "\u2022 Prominent actors: Claims about pharmaceutical companies, media organisations, health-care supply businesses, other companies, or famous people (including celebrities and politicians). Note that this does not include claims made bypoliticians or other famous people unless they are about other prominent actors.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "\u2022 Conspiracies: Claims that the virus was created as a bioweapon, that some organization supposedly created the pandemic, that it was predicted, etc.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "\u2022 Virus transmission: Claims about how the virus is transmitted and how to prevent transmission. This includes cleaning as well as use of specific lighting, appliances, protective equipment, etc.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "\u2022 Virus origins and properties: Claims about the origins of the virus (e.g,. in animals) or its properties.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "\u2022 Public Reaction: Claims that encourage hoarding, buying supplies, practising or avoiding social distancing, compliance or non-compliance with public health measures, protests and civil disobedience against official measures (including government measures). etc.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "\u2022 Vaccines, medical treatments, and tests: Claims about vaccines, tests, and treatments, including the development and availability of a vaccine or a treatment. (Claims about self-treatment fall under the medical advice category, however.)", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "\u2022 Cannot determine: Use this category if the claim does not fit into any category above, if it does not seem to contain misinformation, or if you cannot read the language or understand the text for any reason.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "The COVID-19 Disinformation corpus is organised in Json format with the following fields.", "cite_spans": [], "ref_spans": [], "section": "Appendix B -Corpus Structure"}, {"text": "\u2022 Debunk Date: The date of the disinformation debunked \u2022 Factcheck Org: The organisation of the fact-checker from", "cite_spans": [], "ref_spans": [], "section": "Appendix B -Corpus Structure"}, {"text": "\u2022 annotations: Contains annotations before merge.", "cite_spans": [], "ref_spans": [], "section": "Appendix B -Corpus Structure"}, {"text": "\u2022 selected label: The merged annotation label 9 Appendix C -Deriving the ELBO This section describes the details of ELBO x bow and ELBO x bow,\u0177 derivation and calculation. Where p(z) = p(z s ) = N (0, I) is a zero mean diagonal multivariate Gaussian prior, hence the D KL (q(z|x)||p(z)) and D KL (q(z s |x,\u0177)||p(z s )) will be p(z) = p(zs) = N (0, I) DKL(q(z|x)||p(z)) = 0.5(\u03c3 2 + \u00b5 2 \u2212 log(\u03c3 2 ) \u2212 1) DKL(q(zs|x,\u0177)||p(zs)) = 0.5(\u03c3 2 s + \u00b5 2 s \u2212 log(\u03c3 2 s ) \u2212 1)", "cite_spans": [], "ref_spans": [], "section": "Appendix B -Corpus Structure"}, {"text": "The bag-of-words pre-processing step is the same as (Card et al., 2018) : All characters are transformed to lower case; stopwords 18 , punctuation, all tokens less than 3 characters and all tokens that include numbers are removed. The pre-processing step for BERT representation is different from bag-of-words pre-processing. For the COVID-19 corpus, all characters are lowercased, and tokenised by the BERT tokeniser from Huggingface 19 (Wolf et al., 2019) Library. The IMDB corpus has a longer average document length, and some of the documents are longer than the pre-trained BERT length limitation (510 + CLS and SEP). Therefore, we only keep the first 510 tokens.", "cite_spans": [{"start": 52, "end": 71, "text": "(Card et al., 2018)", "ref_id": "BIBREF2"}], "ref_spans": [], "section": "Appendix D -Experimental Details"}, {"text": "The ADAM optimiser parameters are default from the Pytorch Library: Learning Rate = 0.001, betas=(0.9, 0.999). The number of training epochs are 200 as in Card et al. (2018) , with early stopping when no training loss (classification loss for CANTM) decrease after 4 epochs.", "cite_spans": [{"start": 155, "end": 173, "text": "Card et al. (2018)", "ref_id": "BIBREF2"}], "ref_spans": [], "section": "Appendix D -Experimental Details"}, {"text": "The fine tuning layers for BERT (Huggingface BERT-base implementation) are:", "cite_spans": [], "ref_spans": [], "section": "Appendix D -Experimental Details"}, {"text": "\u2022 encoder.layer.11.attention.self.query.weight,", "cite_spans": [], "ref_spans": [], "section": "Appendix D -Experimental Details"}, {"text": "\u2022 encoder.layer.11.attention.self.query.bias,", "cite_spans": [], "ref_spans": [], "section": "Appendix D -Experimental Details"}, {"text": "\u2022 encoder.layer.11.attention.self.key.weight,", "cite_spans": [], "ref_spans": [], "section": "Appendix D -Experimental Details"}, {"text": "\u2022 encoder.layer.11.attention.self.key.bias,", "cite_spans": [], "ref_spans": [], "section": "Appendix D -Experimental Details"}, {"text": "\u2022 encoder.layer.11.attention.self.value.weight,", "cite_spans": [], "ref_spans": [], "section": "Appendix D -Experimental Details"}, {"text": "\u2022 encoder.layer.11.attention.self.value.bias,", "cite_spans": [], "ref_spans": [], "section": "Appendix D -Experimental Details"}, {"text": "\u2022 encoder.layer.11.attention.output.dense.weight,", "cite_spans": [], "ref_spans": [], "section": "Appendix D -Experimental Details"}, {"text": "\u2022 encoder.layer.11.attention.output.dense.bias, ", "cite_spans": [], "ref_spans": [], "section": "Appendix D -Experimental Details"}, {"text": "To ensure fair comparison between CANTM with the BERT classifier, we first compared: 1) BERT with additional hidden layer that matches the dimension of latent variables (denoted BERT in the result); 2) BERT without additional hidden layer, i.e. applying BERT [CLS] token output directly for classification (denoted BERTraw in the result). The COVID corpus results are shown in Table 11 ; the BERT with additional hidden layer has better performance in both accuracy and F-measure. Therefore, we report the BERT result in the paper. Table 12 shows the class level F1 score of the COVID-19 disinformation corpus. CANTM has the best F1 score over most of the classes (CommSpread, MedAdv, PromActs, Consp, Vacc,None), also with better . This class represents anything that the annotators could not decide on, and therefore it could be anything that does not belong to the other 9 classes. In future work, we might need a better algorithm to handle this problem. Table 13 shows the results of the COVID-19 performance with different baselines. The scores reported are the same as Table 4 in the paper, but standard deviation is added (standard deviation here is the average standard deviation from all classes). According to the results, CANTM not only improves the accuracy and F1 measure over the BERT baseline, but also improves standard deviation. Table 14 shows the topics of the best and worst NPMI scores from CANTM and the baselines. We already discussed the fact that topic interpretability is not strongly associated with the NMPI score in supervised topic models (CANTM and SCHOLAR) in the paper. However, we found additionally that the NPMI score may have a better connection to the topic interpretability with the unsupervised topic modelling (LDA and NVDM). The best NMPI LDA topic (LDA0.149) can be interpreted as a mixed topic of Russian public authority and medical advice. However, the lowest NMPI LDA topic (LDA0.013) is difficult to interpret.", "cite_spans": [], "ref_spans": [{"start": 377, "end": 385, "text": "Table 11", "ref_id": "TABREF1"}, {"start": 532, "end": 540, "text": "Table 12", "ref_id": "TABREF1"}, {"start": 958, "end": 966, "text": "Table 13", "ref_id": "TABREF1"}, {"start": 1075, "end": 1082, "text": "Table 4", "ref_id": "TABREF7"}, {"start": 1347, "end": 1355, "text": "Table 14", "ref_id": "TABREF1"}], "section": "Appendix E -Additional Experiment Results"}, {"text": "In this section we demonstrate the topics generated from CANTM (Table 15 to Table 18 are the COVID-19 topics from CANTM.) Table 15 is Classification-Aware topics Table 16 is Classification-Regularised topics Table 17 is Classification-Associate topics Table 17 : Full list of Classification-Associate topics for COVID-19 corpus, each line is a topic say carry meeting come weed china publicly regularly director consumption mention conference professor since april quarantined starting spoke supporting please fake ministry close study refused february attempt video beaten administration photo post french smoking circulating bank side account eating image police bat cdc spread visit tourists answer data july clip announced lockdown stay school office deadly arrested ground degrees always lockdown every end afp common true islamic concerns rapid undergoing health ever salt swat ginger pope uses welfare hands singapore news president victims use minutes cases day continue laboratory developed corporation denied present force official palau show give post pneumonia says reports elderly infection claimed beijing speech generally reporting experts video french time patient includes place victims threatened forward close leave taken investigation recommendations ventilators exposed organisms people deaths put italy aired patent election malaria pepper working contrary five growing suicide included indicates kansas temperatures staying jamaat communities italy two prayer effective discovered led herbal cov patient article china takes people vaccine since weapon hospital scientific man group cells working prime vaccination worldwide due zone created planning airlines producing ultraviolet evidence human gives even temperature science end claimed across conte video south covid emergency response never chinese seconds changed images leave research conspiracy indian starting individuals though text tanker germany correlation visible sometimes lay produce outright super district initiation six newly hanks definitively last six hence lack barack elizabeth subway modular considering stories gotabaya strewn abdullah vibration ramesh miami commission match preventions relationship indonesia eliminate herbal obama diagnosed bjp japan key screening dung worldwide try teacher carbon thai decisions spokesman key advising physically solutions restriction doh camilla promotes vibration scattered sunday ready netflix production pib telecast cause nazi emergency stopped reports known study findings hospitals movement vaccine garlic family onion stating died gas kill best strain announcing chain mass acid outright experts warm respiratory helps announcements damage factual instead crisis false ago video president cases undergoing clarification chinese bulletin project hours cause jamaat make romania xia stock effort isolation kenyan new medical police city media china social agency also back coronavirus dangerous medicine advise intermediate graphics brazil ebola imposed generator quarantine warm sent claims cells members bill conte soup company government face available outbreak exist proof head service found cruise found suspended man joe congress whatsapp trump weed claim sauna case facebook north used production many protocol context citizens text cures issued onion spokesperson failure even spread actually returned moment virus published confirmed phishing link cure station extension taking spread continues widespread stands visible patrolling mandate strewn violating absolutely sophie trump items blood guard technology told home amid suspended intermediate coffins announcement october protect coast capacity company carry supplies committed shows please war paulo nose road flu refer runny post spain published people south taken showing offering reviewed anything mock police july infected coffins protocol experts receive say world website outbreak social hospital virus bats eligible latest hoax taken risk video north social lemon whole report sources rahul ground ahmad cases lost official found students manipulated support patients thousand forward ", "cite_spans": [], "ref_spans": [{"start": 63, "end": 84, "text": "(Table 15 to Table 18", "ref_id": "TABREF1"}, {"start": 122, "end": 130, "text": "Table 15", "ref_id": "TABREF1"}, {"start": 162, "end": 170, "text": "Table 16", "ref_id": "TABREF1"}, {"start": 208, "end": 216, "text": "Table 17", "ref_id": "TABREF1"}, {"start": 252, "end": 260, "text": "Table 17", "ref_id": "TABREF1"}], "section": "Appendix E -CANTM Topics"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Latent dirichlet allocation", "authors": [{"first": "M", "middle": [], "last": "David", "suffix": ""}, {"first": "", "middle": [], "last": "Blei", "suffix": ""}, {"first": "Y", "middle": [], "last": "Andrew", "suffix": ""}, {"first": "Michael I Jordan", "middle": [], "last": "Ng", "suffix": ""}], "year": 2003, "venue": "Journal of machine Learning research", "volume": "3", "issn": "", "pages": "993--1022", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "Philip Howard, and Rasmus Kleis Nielsen. 2020. Types, sources, and claims of covid-19 misinformation. Technical report", "authors": [{"first": "Scott", "middle": [], "last": "Brennen", "suffix": ""}, {"first": "Felix", "middle": [], "last": "Simon", "suffix": ""}], "year": null, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Neural models for documents with metadata", "authors": [{"first": "Dallas", "middle": [], "last": "Card", "suffix": ""}, {"first": "Chenhao", "middle": [], "last": "Tan", "suffix": ""}, {"first": "Noah A", "middle": [], "last": "Smith", "suffix": ""}], "year": 2018, "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics", "volume": "1", "issn": "", "pages": "2031--2040", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Reading tea leaves: How humans interpret topic models", "authors": [{"first": "Jonathan", "middle": [], "last": "Chang", "suffix": ""}, {"first": "Sean", "middle": [], "last": "Gerrish", "suffix": ""}, {"first": "Chong", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Jordan", "middle": ["L"], "last": "Boyd-Graber", "suffix": ""}, {"first": "David", "middle": ["M"], "last": "Blei", "suffix": ""}], "year": 2009, "venue": "Advances in neural information processing systems", "volume": "", "issn": "", "pages": "288--296", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "Btm: Topic modeling over short texts", "authors": [{"first": "Xueqi", "middle": [], "last": "Cheng", "suffix": ""}, {"first": "Xiaohui", "middle": [], "last": "Yan", "suffix": ""}, {"first": "Yanyan", "middle": [], "last": "Lan", "suffix": ""}, {"first": "Jiafeng", "middle": [], "last": "Guo", "suffix": ""}], "year": 2014, "venue": "IEEE Transactions on Knowledge and Data Engineering", "volume": "26", "issn": "12", "pages": "2928--2941", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Covid-19 misinformation", "authors": [{"first": "Clare", "middle": [], "last": "Clare", "suffix": ""}, {"first": "Lorna", "middle": [], "last": "Christie", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "A coefficient of agreement for nominal scales. Educational and psychological measurement", "authors": [{"first": "Jacob", "middle": [], "last": "Cohen", "suffix": ""}], "year": 1960, "venue": "", "volume": "20", "issn": "", "pages": "37--46", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "Overview of model architecture, Linear is the linear transformation (i.e. Linear(x)=xW+b), nonLin is linear transformation with non-linear activation function f(Linear(.)), Softmax is Softmax activated linear function as a 'global explanation' of the classifier. Furthermore,\u0177 itself can be seen as a compressed topic of z, or 'class-associated topic'. The document can be reconstructed by\u0177 in the same way as the M1 decoder, and the likelihood of p(x bow |\u0177) is given by:", "latex": null, "type": "figure"}, "FIGREF1": {"text": "BERT (Devlin et al., 2019): We use Huggingface 11 (Wolf et al., 2019) 'BERT-baseduncased' pre-trained model and Pytorch implementation in this experiment.", "latex": null, "type": "figure"}, "FIGREF2": {"text": "09 worst waste like boring lousy wasted lame sucks bottom tedious CANTM 0.03 animation movie enjoy better film disney time acting recommend make", "latex": null, "type": "figure"}, "FIGREF3": {"text": "Date: The date of the disinformation first posted online \u2022 Country: Country location of the fact-checker \u2022 Claim: The claim of the disinformation \u2022 Explanation: The explanation from the fact-checker of why this is a disinformation \u2022 Source: The link to the disinformation debunk page \u2022 unique wv id: hash code based on the first 200 words of 'Claim' and 'Explanation'", "latex": null, "type": "figure"}, "FIGREF4": {"text": "zs [log q(z s |x,\u0177)] = E zs [log p(x bow |\u0177, z s )] + E zs [log p(\u0177, z s )] \u2212 E zs [log q(z s )|x,\u0177)] = E zs [log p(x bow |\u0177, z s )] + E zs [log p(\u0177|z s )] + E zs [p(z s )] \u2212 E zs [log q(z s )|x,\u0177)] = E zs [log p(x bow |\u0177, z s )] + E zs [log p(\u0177|z s )] \u2212 D KL (q(z s |x,\u0177)||p(z s ))", "latex": null, "type": "figure"}, "TABREF1": {"text": "Categories for annotation, the abbreviations are in the parentheses", "latex": null, "type": "table"}, "TABREF3": {"text": "", "latex": null, "type": "table"}, "TABREF5": {"text": "Label count after merge in each category", "latex": null, "type": "table", "html": "<html><body><table><tr><td>PubAuthAction </td><td>CommSpread </td><td>PubRec </td><td>PromActs\n</td></tr><tr><td>251 225 </td><td>60 </td><td>221\n</td></tr><tr><td>GenMedAdv </td><td>VirTrans </td><td>Vacc </td><td>Consp\n</td></tr><tr><td>177 80 </td><td>76 </td><td>97\n</td></tr><tr><td>VirOrgn </td><td>None\n</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>63 43\n</td></tr></table></body></html>"}, "TABREF7": {"text": "COVID-19 disinformation results, n/a stands for not applicable for the model The COVID-19 evaluation results are shown in", "latex": null, "type": "table"}, "TABREF8": {"text": "The classification results are consistent with the COVID-19 experiment. Baseline BERT has better", "latex": null, "type": "table"}, "TABREF9": {"text": "IMDB results, n/a stands for not applicable for the model (*NVDM, LDA and Scholar results are borrowed fromCard et al. (2018)) accuracy than SCHOLAR, and CANTM further improves over BERT by about 0.5%. The topic modelling performance of CANTM is almost the same as for NVDM, while LDA and SCHOLAR have the best performance in perplexity and coherence, respectively. .58 article link read please click full ecuador cases guayaquil ecuadorian SCHOLAR 0.07 coronavirus story lab china created website similar general chinese director", "latex": null, "type": "table"}, "TABREF10": {"text": "Topic words of the best and worst coherence topics NPMI score in parentheses", "latex": null, "type": "table", "html": "<html><body><table><tr><td>CANTM 0.50 please patents link ecuador patent read\nclick full article guayaquil cure proven met protection leader pope aa-jtak within elizabeth developed\narticle link read please click full ecuador\ncases guayaquil ecuadorian coronavirus story lab china created website similar general chinese director\n</td></tr><tr><td>CANTM 0.04 </td></tr><tr><td>SCHOLAR 0.58 </td></tr><tr><td>SCHOLAR 0.07 </td></tr></table></body></html>"}, "TABREF11": {"text": "The IMDB topics from the two best and worst topic coherence scores", "latex": null, "type": "table", "html": "<html><body><table><tr><td>CANTM 0.09 worst waste like boring lousy wasted lame sucks bottom tedious\nanimation movie enjoy better film disney\ntime acting recommend make\n</td></tr><tr><td>CANTM 0.03 </td></tr></table></body></html>"}, "TABREF13": {"text": "", "latex": null, "type": "table"}, "TABREF14": {"text": "", "latex": null, "type": "table"}, "TABREF15": {"text": "Jon D Mcauliffe andDavid M Blei. 2008. Supervised topic models. In Advances in neural information processing systems, pages 121-128. variational inference. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 2410-2419. JMLR. org. Yishu Miao, Lei Yu, and Phil Blunsom. 2016. Neural variational inference for text processing. In International conference on machine learning, pages 1727-1736.", "latex": null, "type": "table"}, "TABREF16": {"text": "encoder.layer.11.intermediate.dense.weight, \u2022 encoder.layer.11.intermediate.dense.bias, \u2022 encoder.layer.11.output.dense.weight, \u2022 encoder.layer.11.output.dense.bias The number of parameters in CANTM (include BERT) are 110,464,382 and number of trainable parameters are 8,066,942. The experiment hardware environment are: Intel(R) Xeon(R) Bronze 3204 CPU, TITAN RTX GPU, average epoch run time for COVID corpus is 41 seconds. The full list parameters number and epoch time shown in Table 10. Please note Gensim LDA does not have GPU support, hence it running on single core CPU.", "latex": null, "type": "table"}, "TABREF17": {"text": "Number of parameters and epoch training time. Gensim LDA does not have GPU support", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Model </td><td>num. params </td><td>epoch time (sec.)\n</td></tr><tr><td>CANTM </td><td>110,464,382 </td><td>41\n</td></tr><tr><td>BERTraw </td><td>109,489,930 </td><td>36\n</td></tr><tr><td>BERT </td><td>109,521,200 </td><td>37\n</td></tr><tr><td>SCHOLAR </td><td>740,360 </td><td>0.05\n</td></tr><tr><td>NVDMb </td><td>109,661,140 </td><td>37\n</td></tr><tr><td>NVDMo </td><td>1,152,600 </td><td>20\n</td></tr><tr><td>LDA </td><td>151,750 </td><td>0.6\n</td></tr></table></body></html>"}, "TABREF19": {"text": "BERT setting comparison on COVID-19 disinformation standard deviation in parentheses", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Metrics </td><td>Acc. </td><td>F-1\n</td></tr><tr><td>BERT </td><td>58.78 (3.36) </td><td>54.19 (6.85)\n</td></tr><tr><td>BERTraw </td><td>58.77(3.56) </td><td>49.74 (7.62)\n</td></tr></table></body></html>"}, "TABREF21": {"text": "COVID-19 disinformation class level F1 score, standard deviation in parentheses", "latex": null, "type": "table", "html": "<html><body><table><tr><td>\u00a0</td><td>PubAuth CommSpread </td><td>MedAdv </td><td>PromActs </td><td>Consp\n</td></tr><tr><td>BERT </td><td>61.17(4.50) </td><td>62.27(5.83) </td><td>75.03(6.54) </td><td>60.12(3.25) </td><td>49.92(12.04)\n</td></tr><tr><td>BERTraw SCHOLAR CANTM </td><td>65.64(2.91) 47.92(9.77) 64.35(1.44) </td><td>59.35(4.77) 48.84(11.56) 66.50(3.87) </td><td>75.82(5.53) 71.11(6.99) 79.68(2.12) </td><td>65.51(4.34) 46.93(8.66) 67.21(3.72) </td><td>41.90 (10.46) 31.30(13.78)\n60.06(6.80)\n</td></tr><tr><td>BERT </td><td>VirTrans </td><td>VirOrgn </td><td>PubRec </td><td>Vacc </td><td>None\n</td></tr><tr><td>42.67(8.70) </td><td>57.62(6.72) </td><td>23.68(10.01) </td><td>64.62(9.66) </td><td>12.59(11.35)\n</td></tr><tr><td>BERTraw </td><td>41.42(5.36) </td><td>53.20(15.92) </td><td>27.19(13.55) </td><td>65.48(9.62) </td><td>1.90 (3.8)\n</td></tr><tr><td>SCHOLAR </td><td>11.71(10.06) </td><td>45.15(20.49) </td><td>5.71(11.42) </td><td>55.37(15.78) </td><td>0.0(0.0)\n</td></tr><tr><td>CANTM </td><td>40.21(8.56) </td><td>55.19(3.43) </td><td>25.04(9.87) </td><td>72.28(8.40) </td><td>15.52 (15.0)\n</td></tr></table></body></html>"}, "TABREF22": {"text": "", "latex": null, "type": "table"}, "TABREF23": {"text": "Classification-Aware topics updated from unlabelled data.", "latex": null, "type": "table"}, "TABREF24": {"text": "Topic words of the best and worst coherence topics facebook written letter claims transmission advisory data posts kill ramesh intermediate related viral virus research patented negated book philippines positive confirmed advisory task patient mask pakistan italian remains cases case died sars handling chickens ebola reported dead thousand contaminated steroids advice ministry purported gargling issued issuing colored red warm dry avoiding remedy practices transmission treatments vinegar ways bakery abdullah desai badawi swat lockdown minister force extension region police langowan vatican market indonesia seconds palau wuhan prime roof alkaline trump president donald quote approval forward roche friday felt intermediate breath cause patented seconds garlic vinegar scientific deaths studies bat ministry advisory case bakery aap wash pib notice positive dismissed bat joe match origin palau flu federal bloggers source former click humans viruses full indonesia cattle bat ago two let wife justin multiple illegally bed hospital prayers photo migrants trudeau pib government considering edited disaster issued forward act offense affairs restaurant ahmad uploaded saddam former china nazi pretty mosque xia vinegar india clapping ronaldo salt getting mask wear suggesting message affairs salt vinegar drinking method test lemon fda ministry media woman video hospital patients thanksgiving barcelona drill tribute newly gandhi biden obama bill joe allah china narendra funding giuseppe evers dead lives tribute night circulated photo left italian croatia picture covid said kindly virus known use clearly gargling cure suggest bicarbonate drinking cured dryer effective still eliminates temperature ice lemon dry maximum masks voted outbreaks doctors happens sars temperatures mask click full tested read confirmed vatican dettol please seeks positive positive delhi jan doh january tea chart pope negative strains posts youtube viewed multiple television issue cases based incidents prevention barcelona couple development image photograph happens croatia broiler picture virus link ecuador please article read full lions russian biden saves", "latex": null, "type": "table"}, "TABREF25": {"text": "Full list of Classification-Aware topics for COVID-19 corpus, each line is a topic lace lay manufactured imports treated demonstration strewn pedestrian gas fronts chance indoors supermarket bodies citizens streets items frequently thrown fronts media coronavirus viral taken world social shows video novel man health coronavirus pandemic cases one covid organization italy countries outbreak khan living foundation patents london dinner camilla fictional cornwall actor therefore tony recommendations airborne mouth facial generally copd hair chance shows actually chinese victims photo art august biden italy protesters seconds karnataka enter went husband breath converted bjp colored cuban local click newspaper passengers actor employee corporation link article bank internet went america mumbai related recent worked extended offense june deaths covid number health account cases take state confirmed obama washed wake sea video wife ministry recorded case trudeau department coronavirus new people cases china kill evidence virus article kills world doctors health people medical according food sri misleading facebook found pictures images march viral image old disease along chicken kong hong video wuhan shows clips police suspected bodies seconds often buy allow masks buying lockdown important australian mask march please link alongside full click jair kit crying read article coronavirus claim evidence said twitter novel facebook times posts multiple disease using prevention says whether election official cure study research available president south buy priyanka bill trump testing test vaccine click please full read labs cuban guayaquil ministry ecuador treating number aap severe transmission mers likely centre posts worked philippines china reported internet link francis sars read pope manufactured contain stated scientific various name oil cure made barack israel clarified ahmad weave seek jinping badawi abdullah ultraviolet xia additionally soup place viruses new yet animal products strain sanitizer strains get considering federal ireland announce patrolling passengers wife anti presidential rubbished flu sars inaccurate studies important mers around type runny suggests full medicine ashore items sea wash migrant click ecuadorian organization link covid two full read doctor confirmed created please click purportedly notice doses supermarkets try promotes abortion experts levels earthquake coronavirus ministry novel home caused related video traditional viral youtube indian claim minister india also false misleading claims prime sri italy bodies pictures china prayer mosque plates video allah coffins tested buckingham tourists hand lysol ronaldo advises washington met manufacturer two wuhan china denied chinese center report confirmed reports officials desai visuals dung saddam cow july kills sold older lips satellite accurate sulfur sun dioxide kingdom forecasts translated maps camilla tested positive doctor coronavirus help recent person getting india novel stopped company sanitizer label desai trupti saddam theories entering buying coronavirus different million new family covid say allegedly respiratory death video man covid first circulated claiming false woman least taken shows covid hospital video wuhan doctor photo cure woman test twitter facebook photo times italy claim victims curfew health image key copd recognized tourist antibiotics rabies rumour short emphasized medication year modi india old positive narendra curfew muslim wife announced military full code daniel roche speech event archive please actor spread show patients new covid virus viral also outbreak response movie picture couple italian lions lion photograph volleyball barcelona tom", "latex": null, "type": "table"}, "TABREF26": {"text": "Full list of Classification-Regularised topics for COVID-19 corpus, each line is a topic PubAuthAction china government people claim india march facebook coronavirus outbreak covid CommSpread coronavirus photo covid people shows video claim novel confirmed shared GenMedAdv coronavirus cure experts novel prevent water evidence kill scientific hot PromActs coronavirus said novel trump video shared president media covid hospital Consp coronavirus chinese covid virus lab wuhan outbreak new china posts VirTrans coronavirus covid evidence virus claim spread video said people surfaces VirOrgn coronavirus shows video bat wuhan novel source outbreak virus taken PubPrep video shows facebook image shared show times outbreak false circulated Vacc cure vaccine new covid developed novel scientists claimed coronavirus claims None video image taken shared covid due streets old india reports", "latex": null, "type": "table"}, "TABREF27": {"text": "Full list of Classification-Aware topics for unlabelled COVID-19 corpus, each line is a topic", "latex": null, "type": "table"}}, "back_matter": []}