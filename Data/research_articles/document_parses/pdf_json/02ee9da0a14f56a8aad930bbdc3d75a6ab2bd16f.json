{"paper_id": "02ee9da0a14f56a8aad930bbdc3d75a6ab2bd16f", "metadata": {"title": "EXPLAINABLE-BY-DESIGN APPROACH FOR COVID-19 CLASSIFICATION VIA CT-SCAN A PREPRINT", "authors": [{"first": "Plamen", "middle": [], "last": "Angelov", "suffix": "", "affiliation": {}, "email": "p.angelov@lancaster.ac.uk"}, {"first": "Eduardo", "middle": [], "last": "Soares", "suffix": "", "affiliation": {}, "email": ""}]}, "abstract": [{"text": "The COVID-19 disease has widely spread all over the world since the beginning of 2020. On January 30, 2020 the World Health Organization (WHO) declared a global health emergency. At the time of writing this paper the number of infected about 2 million people worldwide and took over 125,000 lives, the advanced public health systems of European countries as well as of USA were overwhelmed. In this paper, we propose an eXplainable Deep Learning approach to detect COVID-19 from computer tomography (CT) -Scan images. The rapid detection of any COVID-19 case is of supreme importance to ensure timely treatment. From a public health perspective, rapid patient isolation is also extremely important to curtail the rapid spread of the disease. From this point of view the proposed method offers an easy to use and understand tool to the front-line medics. It is of huge importance not only the statistical accuracy and other measures, but also the ability to understand and interpret how the decision was made. The results demonstrate that the proposed approach is able to surpass the other published results which were using standard Deep Neural Network in terms of performance. Moreover, it produce highly interpretable results which may be helpful for the early detection of the disease by specialists.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "In December 2019, an outbreak coronavirus (SARS-CoV-2) infection began in Wuhan, the capital of central China's Hubei province [1, 2, 3] . On January 30, 2020 the World Health Organization (WHO) declared a global health emergency [4] and with some delay and hesitation on 11 March 2020 WHO declared pandemic. By 14 April 2020, accumulative 1,985,135 confirmed cases and 125,344 deaths were documented [5] . USA has become the new epicenter of the disease with 605,354 documented cases and 25,394 deaths (14 April 2020) [5] .", "cite_spans": [{"start": 127, "end": 130, "text": "[1,", "ref_id": "BIBREF0"}, {"start": 131, "end": 133, "text": "2,", "ref_id": "BIBREF1"}, {"start": 134, "end": 136, "text": "3]", "ref_id": "BIBREF2"}, {"start": 401, "end": 404, "text": "[5]", "ref_id": null}, {"start": 519, "end": 522, "text": "[5]", "ref_id": null}], "ref_spans": [], "section": "Introduction"}, {"text": "Researchers of different disciplines work along with public health officials to understand the COVID-19 pathogenesis and jointly with the policymakers urgently develop strategies to control the spread of this new disease [6] . Recent findings have observed imaging patterns on chest radiography and computed tomography (CT) for patients diagnosed with COVID- 19 [7, 8, 9, 10] .", "cite_spans": [{"start": 221, "end": 224, "text": "[6]", "ref_id": null}, {"start": 359, "end": 375, "text": "19 [7, 8, 9, 10]", "ref_id": null}], "ref_spans": [], "section": "Introduction"}, {"text": "Prospective analysis revealed bilateral lung opacities on 40 of 41 (98%) chest CTs in infected patients in Wuhan and described lobular and subsegmental areas of consolidation as the most typical findings [6] . Other investigators found high rates of ground-glass opacities and consolidation, sometimes with a rounded morphology and peripheral lung distribution [11, 10] . Thoracic radiology evaluation is often key to the evaluation of patients suspected of COVID-19 infection [12] . Prompt detection and diagnosis of the disease is invaluable in the efforts to ensure timely treatment. From a public health perspective, rapid patient isolation is crucial for containment of this communicable disease [4] and optimal use of available resources which quickly become scarce and overwhelmed by the exponentially growing number of patients and prolonged periods of treatment.", "cite_spans": [{"start": 204, "end": 207, "text": "[6]", "ref_id": null}, {"start": 361, "end": 365, "text": "[11,", "ref_id": null}, {"start": 366, "end": 369, "text": "10]", "ref_id": null}, {"start": 477, "end": 481, "text": "[12]", "ref_id": null}, {"start": 701, "end": 704, "text": "[4]", "ref_id": null}], "ref_spans": [], "section": "Introduction"}, {"text": "Recently, artificial intelligence (AI) and, specifically, deep learning based approaches have demonstrated high levels of performance in the medical imaging domain due to their ability to automatically extract latent features and bypass so called \"handcrafting\" [13] . In addition, the technique called transfer learning [14] made possible to train a deep neural network on one set of images (e.g. ImageNet [15] ) but use effectively on another set of images. While manual reading CT and X-ray images takes 15 minutes and involves a highly skilled medical doctor/consultant which are now in high demand the use of AI and deep learning can take few seconds on a computer and be automated which provides opportunity for high throughput and remote way of operation. However, few stumbling blocks still hamper the wider use of deep neural networks. These include: i) their opaque, \"black-box\" nature and inability to explain any decision [16] ; ii) their inability to continue to learn once trained, to learn from a handful of examples and data and compute power appetite [17] .", "cite_spans": [{"start": 262, "end": 266, "text": "[13]", "ref_id": "BIBREF3"}, {"start": 321, "end": 325, "text": "[14]", "ref_id": "BIBREF4"}, {"start": 407, "end": 411, "text": "[15]", "ref_id": "BIBREF5"}, {"start": 934, "end": 938, "text": "[16]", "ref_id": "BIBREF6"}, {"start": 1068, "end": 1072, "text": "[17]", "ref_id": "BIBREF7"}], "ref_spans": [], "section": "Introduction"}, {"text": "In this paper we present a new deep learning method that is explainable by design. It is able to continue to learn and adapt for each new data sample which is immensely important for the case of COVID-19 (and other disease), because new cases are being accumulated every minute and traditional approaches require either iterative re-training or ignores the new data. The proposed approach is non-iterative and is entirely based on recursive calculations and use of prototypes. Therefore, it is computationally very efficient. The architecture of the proposed method combines reasoning and learning in a synergy while alternative approaches focus on either reasoning which favours the interpretability and explainability or on machine learning and statistical approaches which favour the accuracy and other statistical measures for the expence of the interpretability and explainability. In this paper we demosntrate that the proposed approach can be very efficient in detecting COVID-19 via CT scans and can be very useful to explain the decisions which itself may also be very important for medical doctors.", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "The main idea of the proposed approach is based on prototypes (images of CT scans -both, with and without COVID- 19) and is using the density in the data/feature space to build empirical estimations of the distributions [18] . The proposed approach is non-iterative and non-parametric, which explains its efficiency in terms of time and computational resources. From the user perspective, the proposed approach is clearly understandable/explainable which for the specific case of COVID-19 infections means to aid explanations and decisions made ultimately by human doctors (instead of percentages and likelihoods they can see and understand an image and compare similarities). In this sense, this is an approach of anthropomorphic machine learning [18] . We tested the proposed method on the very recent COVID-CT-Dataset [19] which contains a set of real cases. Results have demonstrated that proposed approach provides superior performance's measured by F1 score and other metrics, but also, critically, it offers epxlainability and is able to continue to learn from new data.", "cite_spans": [{"start": 113, "end": 116, "text": "19)", "ref_id": null}, {"start": 220, "end": 224, "text": "[18]", "ref_id": "BIBREF8"}, {"start": 748, "end": 752, "text": "[18]", "ref_id": "BIBREF8"}, {"start": 821, "end": 825, "text": "[19]", "ref_id": null}], "ref_spans": [], "section": "Introduction"}, {"text": "Same as most machine learning methods, the proposed in this paper method starts with pre-processing which involves scaling, augmentation, and rotation. In order to extract features of the CT images we use transfer learning over the GoogleNet Deep Learning structure [14] . It is important to stress that GoogleNet is used just to define the feature space and it was not trained on the CT images, but on ImageNet [15] . Other approaches could also be used for this purpose.", "cite_spans": [{"start": 266, "end": 270, "text": "[14]", "ref_id": "BIBREF4"}, {"start": 412, "end": 416, "text": "[15]", "ref_id": "BIBREF5"}], "ref_spans": [], "section": "Concept and Basic Algorithm"}, {"text": "The prototype-based learning is the core of the proposed method ( Fig. (1) ). The prototypes are actual training data samples (in this case, images) which are highly representative (local peaks of the density and empirically derived probability distributions [18] ). They are focal points of locally valid generative models described by multi-modal Cauchy distribution [18] .", "cite_spans": [{"start": 259, "end": 263, "text": "[18]", "ref_id": "BIBREF8"}, {"start": 369, "end": 373, "text": "[18]", "ref_id": "BIBREF8"}], "ref_spans": [{"start": 66, "end": 74, "text": "Fig. (1)", "ref_id": "FIGREF2"}], "section": "Concept and Basic Algorithm"}, {"text": "The algorithm of the proposed approach is described below. With the first observed image (data sample) it is being converted to a vector of features using transfer learning. In this paper, we use a vector with size 1000 formed from the last fully connected layer of the GoogleNet [14] . More information about the pre-processing step for the proposed method can be found in the Supplementary Material available for this paper.", "cite_spans": [{"start": 280, "end": 284, "text": "[14]", "ref_id": "BIBREF4"}], "ref_spans": [], "section": "Concept and Basic Algorithm"}, {"text": "be training data set with x i \u2208 R n denoting the feature vector and c i \u2208 {1, 2} denoting the class (COVID-19 or No COVID-19) for each i \u2208 {1, ..., N }. N is the number of training data/images used.", "cite_spans": [], "ref_spans": [], "section": "Concept and Basic Algorithm"}, {"text": "The proposed algorithm works per class; therefore, all the calculations are done for each class separately.", "cite_spans": [], "ref_spans": [], "section": "Concept and Basic Algorithm"}, {"text": "2 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.", "cite_spans": [], "ref_spans": [], "section": "Concept and Basic Algorithm"}, {"text": "The copyright holder for this preprint this version posted April 29, 2020. . https://doi.org/10.1101/2020.04.24.20078584 doi: medRxiv preprint", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "The meta-parameters are initialized with the first observed data sample.", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "where \u00b5 denotes the mean; V 1 denotes the first cluster; p 1 is the first prototype of the first cluster, V 1 ; S 1 is the corresponding support (number of members); P is the total number of the identified prototypes; r 1 is the corresponding radius of the area of influence of V 1 ( in this paper, we use r * = 2 \u2212 2cos(30 o ) same as [18] ; the rationale is that two vectors for which the angle between them is less than \u03c0/6 or 30 o are pointing in close/similar directions. That is, we consider that two feature vectors can be considered to be similar if the angle between them is smaller than 30 degrees. Note that r * is data derived, not a problem-or user-specific parameter. In fact, it can be defined without prior knowledge of the specific problem or data).", "cite_spans": [{"start": 336, "end": 340, "text": "[18]", "ref_id": "BIBREF8"}], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "The next step is to calculate the data density at the current data point,", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "Starting from the mutual distances (Euclidean or Mahalanobis type) between the data points (samples) in the feature space it can be demonstrated theoretically [18] that the data density takes the form of a Cauchy type function as in Eq.", "cite_spans": [{"start": 159, "end": 163, "text": "[18]", "ref_id": "BIBREF8"}], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "(2).", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "Then the algorithm absorbs the new data samples/images,x i one by one by assigning then to the nearest (in the feature space) prototype, p j * :", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "Because of this form of assignment, the shape of the data partitioning is of the so-called Voronoi tessellation type [20] . We call all data points associated with a prototype data clouds, because their shape is not regular (e.g., hyper-spherical, hyper-ellipsoidal, etc.) and the prototype is not necessarily the statistical and geometric mean [18] .", "cite_spans": [{"start": 117, "end": 121, "text": "[20]", "ref_id": "BIBREF10"}, {"start": 345, "end": 349, "text": "[18]", "ref_id": "BIBREF8"}], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "Then, using the density and the distance to the nearest prototype we check the following conditions [18] based on which we determine if the current data sample/image is going to be added to the set of prototypes as a new prototype or not: ", "cite_spans": [{"start": 100, "end": 104, "text": "[18]", "ref_id": "BIBREF8"}], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "When adding a new data cloud the following updates are being made:", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "Alternatively, the meta parameters of the nearest data cloud are being updated as follows [18] :", "cite_spans": [{"start": 90, "end": 94, "text": "[18]", "ref_id": "BIBREF8"}], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "One of the strongest aspects of the proposed approach is its high level of interpretability which comes from its prototype-based nature. Linguistic IF...THEN expressions that represent human reasoning can be formed around the local generative models:", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "3 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "The copyright holder for this preprint this version posted April 29, 2020. ", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "In this section we report the results obtained by the proposed eXplainable Deep Learning classification approach when applied to the COVID-CT-Dataset [19] . Results presented in Table 1 compare the proposed algorithm with other state-of-the-art approaches, including traditional (black-box) deep neural network, Support vector Machines, etc. In summary, the advantages of the proposed method include:", "cite_spans": [{"start": 150, "end": 154, "text": "[19]", "ref_id": null}], "ref_spans": [{"start": 178, "end": 185, "text": "Table 1", "ref_id": null}], "section": "Results"}, {"text": "-high precision as compared with the top state-of-the-art algorithms.", "cite_spans": [], "ref_spans": [], "section": "Results"}, {"text": "-high level of explainabilit. -no user-or problem-specific algorithmic meta parameters -non-iterative algorithm able to learn continuously.", "cite_spans": [], "ref_spans": [], "section": "Results"}, {"text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.", "cite_spans": [], "ref_spans": [], "section": "4"}, {"text": "The copyright holder for this preprint this version posted April 29, 2020. . https://doi.org/10.1101/2020.04.24.20078584 doi: medRxiv preprint Figure 2 : The figure illustrates the decision-making process of the proposed approach. As a new unlabeled data/image arrives it is compared to the identified prototypes. The local (per class) decision-making process is dedicated to calculate the winning prototype per class (the most similar to the new image prototypes of a given class). The global decision-making layer is in charge of forming the overall decision by comparing the degrees of similarity to all classes (in this case, to . Table 1 : The proposed eXplainable Deep Learning classifier provided better results in terms of Accuracy, Recall, F 1 Score, and AUC. Besides the best results, the proposed approach also provided highly interpretable results that may be helpful for specialists. The proposed classifier identified 30 prototypes for non-COVID and 33 prototypes for COVID partients. Rules generated by the identified prototypes for COVID and Non-COVID patients are illustrated by Figs. (3) and (4) respectively. The baseline approach [19] is a Neural Network Deep Leaning-based approach which is 'black box' and the interpretability is very cost.", "cite_spans": [{"start": 1150, "end": 1154, "text": "[19]", "ref_id": null}], "ref_spans": [{"start": 143, "end": 151, "text": "Figure 2", "ref_id": null}, {"start": 635, "end": 642, "text": "Table 1", "ref_id": null}], "section": "(which was not certified by peer review)"}, {"text": "Using the proposed method we generated (extracted form the data) linguistic IF...THEN rules which involve actual images of both cases (COVID-19 and NO COVID-19) as illustrated in Figs. (3) and (4). Such transparent rules can be used in the decision-making process for early diagnostics for COVID-19 infection. Rapid detection with high sensitivity of viral infection may allow better control of the viral spread. Early diagnosis of COVID-19 is crucial for the disease treatment and control. Fig. (5) illustrates the evolving nature of the proposed approach. The proposed approach is able to continuously learn as new data is presented to the system. Therefore, no full retraining is required due to its life-long learning architecture.", "cite_spans": [], "ref_spans": [{"start": 179, "end": 184, "text": "Figs.", "ref_id": null}, {"start": 491, "end": 499, "text": "Fig. (5)", "ref_id": null}], "section": "(which was not certified by peer review)"}, {"text": "In the opposite way, the Baseline approach [19] is based on Neural Network Deep Learning and requires full retraining for new data samples, what can be really cost in terms of time and computational complexity.", "cite_spans": [{"start": 43, "end": 47, "text": "[19]", "ref_id": null}], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "Computing tomography is a quick non-invasive imaging modality with high accuracy. According to [8, 9] almost all patients with COVID-19 had characteristic CT features during the disease, effects such as different degrees of groundglass opacities with or without crazy-paving sign, multifocal organizing pneumonia, and architectural distortion in a peripheral distribution. The proposed approach has demonstrated high efficiency on the identification and classification of such characteristics, and then provide high accurate and interpretable results.", "cite_spans": [{"start": 95, "end": 98, "text": "[8,", "ref_id": null}, {"start": 99, "end": 101, "text": "9]", "ref_id": null}], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.", "cite_spans": [], "ref_spans": [], "section": "5"}, {"text": "The copyright holder for this preprint this version posted April 29, 2020. ", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "In this paper we present a new explainable deep learning approach for COVID-19 detection via CT Scan. The proposed approach demonstrates better results in terms of performance than other state-of-the-art approaches, surpassing the baseline Deep Neural Network approach in terms of performance. Moreover, it also provides epxlanations in the form of IF...THEN rules using actual images of CT scans with and without COVID-19. This is of great importance for medical specialists to understand and diagnose COVID-19 at early stages via computed tomography. In addition, this method is fast and can continue to learn from new images which is very important in a real life application. CT can accurately reflect the disease evolution and monitor the treatment effects [21] . Rapid detection and diagnostics of the disease is of supreme importance to ensure timely treatment, and rapid patient isolation in order to slow the spread of the disease [22] .", "cite_spans": [{"start": 762, "end": 766, "text": "[21]", "ref_id": "BIBREF11"}, {"start": 940, "end": 944, "text": "[22]", "ref_id": "BIBREF12"}], "ref_spans": [], "section": "Conclusion"}, {"text": "In conclusion, chest CT imaging has high sensitivity for diagnosis of COVID-19. We offer a highly transparent deep learning approach which outperforms state-of-the-art approaches in order to detect COVID-19 via CT.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "The copyright holder for this preprint this version posted April 29, 2020. 7 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "The copyright holder for this preprint this version posted April 29, 2020. . https://doi.org/10.1101/2020.04.24.20078584 doi: medRxiv preprint Figure 5 : The figure illustrates the evolving nature of the proposed approach. It continuously learn as new training data arrives to the system. It can be observed that with 478 training data samples the proposed approach could obtain better results in terms of accuracy (84.56%) than the Baseline approach (84.0%) with 537 training data samples [19] . The Baseline approach is a Deep Neural Network which needs large number of training data to obtain high performance in terms of classification and once trained can not be further improved unless fully retrained. In contrast, the proposed approach can obtain higher performance using less training data due to its prototype-based nature.", "cite_spans": [{"start": 490, "end": 494, "text": "[19]", "ref_id": null}], "ref_spans": [{"start": 143, "end": 151, "text": "Figure 5", "ref_id": null}], "section": "(which was not certified by peer review)"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Clinical features of patients infected with 2019 novel coronavirus in wuhan, china. The Lancet", "authors": [{"first": "Chaolin", "middle": [], "last": "Huang", "suffix": ""}, {"first": "Yeming", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Xingwang", "middle": [], "last": "Li", "suffix": ""}, {"first": "Lili", "middle": [], "last": "Ren", "suffix": ""}, {"first": "Jianping", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "Yi", "middle": [], "last": "Hu", "suffix": ""}, {"first": "Li", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Guohui", "middle": [], "last": "Fan", "suffix": ""}, {"first": "Jiuyang", "middle": [], "last": "Xu", "suffix": ""}, {"first": "Xiaoying", "middle": [], "last": "Gu", "suffix": ""}], "year": 2020, "venue": "", "volume": "395", "issn": "", "pages": "497--506", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "A novel coronavirus from patients with pneumonia in china", "authors": [{"first": "Na", "middle": [], "last": "Zhu", "suffix": ""}, {"first": "Dingyu", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Wenling", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Xingwang", "middle": [], "last": "Li", "suffix": ""}, {"first": "Bo", "middle": [], "last": "Yang", "suffix": ""}, {"first": "Jingdong", "middle": [], "last": "Song", "suffix": ""}, {"first": "Xiang", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "Baoying", "middle": [], "last": "Huang", "suffix": ""}, {"first": "Weifeng", "middle": [], "last": "Shi", "suffix": ""}, {"first": "Roujian", "middle": [], "last": "Lu", "suffix": ""}], "year": 2019, "venue": "New England Journal of Medicine", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Clinical course and risk factors for mortality of adult inpatients with covid-19 in wuhan", "authors": [{"first": "Fei", "middle": [], "last": "Zhou", "suffix": ""}, {"first": "Ting", "middle": [], "last": "Yu", "suffix": ""}, {"first": "Ronghui", "middle": [], "last": "Du", "suffix": ""}, {"first": "Guohui", "middle": [], "last": "Fan", "suffix": ""}, {"first": "Ying", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Zhibo", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Jie", "middle": [], "last": "Xiang", "suffix": ""}, {"first": "Yeming", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Bin", "middle": [], "last": "Song", "suffix": ""}, {"first": "Xiaoying", "middle": [], "last": "Gu", "suffix": ""}], "year": null, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Deep learning for health informatics", "authors": [{"first": "Daniele", "middle": [], "last": "Rav\u00ec", "suffix": ""}, {"first": "Charence", "middle": [], "last": "Wong", "suffix": ""}, {"first": "Fani", "middle": [], "last": "Deligianni", "suffix": ""}, {"first": "Melissa", "middle": [], "last": "Berthelot", "suffix": ""}, {"first": "Javier", "middle": [], "last": "Andreu-Perez", "suffix": ""}, {"first": "Benny", "middle": [], "last": "Lo", "suffix": ""}, {"first": "Guang-Zhong", "middle": [], "last": "Yang", "suffix": ""}], "year": 2016, "venue": "IEEE journal of biomedical and health informatics", "volume": "21", "issn": "1", "pages": "4--21", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "Going deeper with convolutions", "authors": [{"first": "Christian", "middle": [], "last": "Szegedy", "suffix": ""}, {"first": "Wei", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Yangqing", "middle": [], "last": "Jia", "suffix": ""}, {"first": "Pierre", "middle": [], "last": "Sermanet", "suffix": ""}, {"first": "Scott", "middle": [], "last": "Reed", "suffix": ""}, {"first": "Dragomir", "middle": [], "last": "Anguelov", "suffix": ""}, {"first": "Dumitru", "middle": [], "last": "Erhan", "suffix": ""}, {"first": "Vincent", "middle": [], "last": "Vanhoucke", "suffix": ""}, {"first": "Andrew", "middle": [], "last": "Rabinovich", "suffix": ""}], "year": 2015, "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition", "volume": "", "issn": "", "pages": "1--9", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Imagenet: A large-scale hierarchical image database", "authors": [{"first": "Jia", "middle": [], "last": "Deng", "suffix": ""}, {"first": "Wei", "middle": [], "last": "Dong", "suffix": ""}, {"first": "Richard", "middle": [], "last": "Socher", "suffix": ""}, {"first": "Li-Jia", "middle": [], "last": "Li", "suffix": ""}, {"first": "Kai", "middle": [], "last": "Li", "suffix": ""}, {"first": "Li", "middle": [], "last": "Fei-Fei", "suffix": ""}], "year": 2009, "venue": "2009 IEEE conference on computer vision and pattern recognition", "volume": "", "issn": "", "pages": "248--255", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead", "authors": [{"first": "Cynthia", "middle": [], "last": "Rudin", "suffix": ""}], "year": 2019, "venue": "Nature Machine Intelligence", "volume": "1", "issn": "5", "pages": "206--215", "other_ids": {}}, "BIBREF7": {"ref_id": "b7", "title": "Deep learning: A critical appraisal", "authors": [{"first": "Gary", "middle": [], "last": "Marcus", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1801.00631"]}}, "BIBREF8": {"ref_id": "b8", "title": "Empirical approach to machine learning", "authors": [{"first": "P", "middle": [], "last": "Plamen", "suffix": ""}, {"first": "Xiaowei", "middle": [], "last": "Angelov", "suffix": ""}, {"first": "", "middle": [], "last": "Gu", "suffix": ""}], "year": 2019, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "Centroidal voronoi tessellations: Applications and algorithms", "authors": [{"first": "Qiang", "middle": [], "last": "Du", "suffix": ""}, {"first": "Vance", "middle": [], "last": "Faber", "suffix": ""}, {"first": "Max", "middle": [], "last": "Gunzburger", "suffix": ""}], "year": 1999, "venue": "SIAM review", "volume": "41", "issn": "4", "pages": "637--676", "other_ids": {}}, "BIBREF11": {"ref_id": "b11", "title": "Time course of lung changes on chest ct during recovery from 2019 novel coronavirus (covid-19) pneumonia", "authors": [{"first": "Feng", "middle": [], "last": "Pan", "suffix": ""}, {"first": "Tianhe", "middle": [], "last": "Ye", "suffix": ""}, {"first": "Peng", "middle": [], "last": "Sun", "suffix": ""}, {"first": "Shan", "middle": [], "last": "Gui", "suffix": ""}, {"first": "Bo", "middle": [], "last": "Liang", "suffix": ""}, {"first": "Lingli", "middle": [], "last": "Li", "suffix": ""}, {"first": "Dandan", "middle": [], "last": "Zheng", "suffix": ""}, {"first": "Jiazheng", "middle": [], "last": "Wang", "suffix": ""}, {"first": "L", "middle": [], "last": "Richard", "suffix": ""}, {"first": "Lian", "middle": [], "last": "Hesketh", "suffix": ""}, {"first": "", "middle": [], "last": "Yang", "suffix": ""}], "year": 2020, "venue": "Radiology", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "Coronavirus disease 2019 (covid-19): Role of chest ct in diagnosis and management", "authors": [{"first": "Yan", "middle": [], "last": "Li", "suffix": ""}, {"first": "Liming", "middle": [], "last": "Xia", "suffix": ""}], "year": 2020, "venue": "American Journal of Roentgenology", "volume": "", "issn": "", "pages": "1--7", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "j\u2208{1,...,P } (D(p j ))) OR (D(x i ) \u2264 min j\u2208{1,...,P } (D(p j ))) OR (||p j * \u2212x i || > r j * )THEN (add a new data cloud)", "latex": null, "type": "figure"}, "FIGREF2": {"text": "This figure illustrates the layered architecture of the proposed method. It has the form of a deep neural network but is using clear to understand prototypes (actual images). The density layer identifies the local peaks of the density and empirically derived probability distributions. The prototypes are actual training data samples (in this case, images) which are highly representative (local peaks of the density and empirically derived probability distributions.The learning procedure of the proposed approach is summarized by the following algorithm.Learning Procedure 1: Read the first feature vector sample x i representing the image I i of the class c; 2: Set \u00b5 \u2190x 1 ; ; V 1 \u2190 {x 1 }; p 1 \u2190x 1 ; S 1 \u2190 1; P \u2190 1; r 1 \u2190 r o ; 3: FOR i = 2, ... 4: Readx i ; 5: Calculate D(x i ) and D(p j ) (j = 1, 2, ..., P ) according to equation (2); 6: IF Eq.", "latex": null, "type": "figure"}, "FIGREF3": {"text": "Final rule given by the proposed eXplainable Deep Learning classifier for the COVID-19 identification. Differently from 'black box' approaches as deep neural networks, the proposed approach provides highly interpretable rules which can be used by human experts for the early evaluation of patients suspected of COVID-19 infection.", "latex": null, "type": "figure"}, "TABREF1": {"text": ". https://doi.org/10.1101/2020.04.... OR (Image \u223c ) THEN 'Non-COVID' Figure 4: Non-Covid final rule given by the proposed eXplainable Deep Learning classifier.retrospective cohort study. The Lancet, 2020. [4] Catrin Sohrabi, Zaid Alsafi, Niamh O'Neill, Mehdi Khan, Ahmed Kerwan, Ahmed Al-Jabir, Christos Iosifidis, and Riaz Agha. World health organization declares global emergency: A review of the 2019 novel coronavirus (covid-19). International Journal of Surgery, 2020. [5] Ensheng Dong, Hongru Du, and Lauren Gardner. An interactive web-based dashboard to track covid-19 in real time. The Lancet infectious diseases, 2020. [6] Tao Ai, Zhenlu Yang, Hongyan Hou, Chenao Zhan, Chong Chen, Wenzhi Lv, Qian Tao, Ziyong Sun, and Liming Xia. Correlation of chest ct and rt-pcr testing in coronavirus disease 2019 (covid-19) in china: a report of 1014 cases. Radiology, page 200642, 2020. [7] Yicheng Fang, Huangqi Zhang, Jicheng Xie, Minjie Lin, Lingjun Ying, Peipei Pang, and Wenbin Ji. Sensitivity of chest ct for covid-19: comparison to rt-pcr. Radiology, page 200432, 2020. [8] Adam Bernheim, Xueyan Mei, Mingqian Huang, Yang Yang, Zahi A Fayad, Ning Zhang, Kaiyue Diao, Bin Lin, Xiqi Zhu, Kunwei Li, et al. Chest ct findings in coronavirus disease-19 (covid-19): relationship to duration of infection. Radiology, page 200463, 2020. [9] Wei Zhao, Zheng Zhong, Xingzhi Xie, Qizhi Yu, and Jun Liu. Relation between chest ct findings and clinical conditions of coronavirus disease (covid-19) pneumonia: a multicenter study. American Journal of Roentgenology, pages 1-6, 2020. [10] Weifang Kong and Prachi P Agarwal. Chest imaging appearance of covid-19 infection. Radiology: Cardiothoracic Imaging, 2(1):e200028, 2020. [11] Ming-Yen Ng, Elaine YP Lee, Jin Yang, Fangfang Yang, Xia Li, Hongxia Wang, Macy Mei-sze Lui, Christine Shing-Yen Lo, Barry Leung, Pek-Lan Khong, et al. Imaging profile of the covid-19 infection: radiologic findings and literature review. Radiology: Cardiothoracic Imaging, 2(1):e200034, 2020. [12] Heshui Shi, Xiaoyu Han, Nanchuan Jiang, Yukun Cao, Osamah Alwalid, Jin Gu, Yanqing Fan, and Chuansheng Zheng. Radiological findings from 81 patients with covid-19 pneumonia in wuhan, china: a descriptive study. The Lancet Infectious Diseases, 2020.", "latex": null, "type": "table"}}, "back_matter": []}