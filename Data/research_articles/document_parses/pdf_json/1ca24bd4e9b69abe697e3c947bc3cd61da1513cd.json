{"paper_id": "1ca24bd4e9b69abe697e3c947bc3cd61da1513cd", "metadata": {"title": "Time-sync Video Tag Extraction Using Semantic Association Graph", "authors": [{"first": "Wenmain", "middle": [], "last": "Yang", "suffix": "", "affiliation": {}, "email": ""}, {"first": "Kun", "middle": [], "last": "Wang", "suffix": "", "affiliation": {}, "email": "wangk@ucla.edu"}, {"first": "N", "middle": ["A"], "last": "Ruan", "suffix": "", "affiliation": {}, "email": ""}, {"first": "Wenyuan", "middle": [], "last": "Gao", "suffix": "", "affiliation": {}, "email": ""}, {"first": "Wei", "middle": [], "last": "Zhao", "suffix": "", "affiliation": {}, "email": ""}, {"first": "Nan", "middle": [], "last": "Liu", "suffix": "", "affiliation": {}, "email": ""}, {"first": "Yunyong", "middle": [], "last": "Zhang", "suffix": "", "affiliation": {}, "email": ""}, {"first": "Na", "middle": [], "last": "Ruan", "suffix": "", "affiliation": {}, "email": ""}, {"first": "Weijia", "middle": [], "last": "Jia", "suffix": "", "affiliation": {}, "email": ""}, {"first": "Shanghai", "middle": [], "last": "", "suffix": "", "affiliation": {}, "email": ""}]}, "abstract": [{"text": "Time-sync comments reveal a new way of extracting the online video tags. However, such time-sync comments have lots of noises due to users' diverse comments, introducing great challenges for accurate and fast video tag extractions. In this paper, we propose an unsupervised video tag extraction algorithm named Semantic Weight-Inverse Document Frequency (SW-IDF). Specifically, we first generate corresponding semantic association graph (SAG) using semantic similarities and timestamps of the time-sync comments. Second, we propose two graph cluster algorithms, i.e., dialogue-based algorithm and topic center-based algorithm, to deal with the videos with different density of comments. Third, we design a graph iteration algorithm to assign the weight to each comment based on the degrees of the clustered subgraphs, which can differentiate the meaningful comments from the noises. Finally, we gain the weight of each word by combining Semantic Weight (SW) and Inverse Document Frequency (IDF). In this way, the video tags are extracted automatically in an unsupervised way. Extensive experiments have shown that SW-IDF (dialogue-based algorithm) achieves 0.4210 F1-score and 0.4932 MAP (Mean Average Precision) in high-density comments, 0.4267 F1-score and 0.3623 MAP in low-density comments; while SW-IDF (topic center-based algorithm) achieves 0.4444 F1-score and 0.5122 MAP in high-density comments, 0.4207 F1-score and 0.3522 MAP in low-density comments. It has a better performance than the state-of-the-art unsupervised algorithms in both F1-score and MAP.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "Recently, watching online videos of news and amusement have become mainstream entertainment during people's leisure time. The booming of online video-sharing websites raises significant challenges in effective management and retrieval of videos. To address that, many text retrieval based automatic video tagging techniques have been proposed [44, 45, 47] . However, these techniques can only provide video-level tags [55] . The problem is that even if these generated tags can perfectly summarize the video content, users have no idea how these tags are associated with the video playback time. If videos are associated with time-sync tags, users can preview the content with both thumbnails and text along the timeline, and this textual information can further enhance users' search experience. Although there are many video content analysis algorithms that can generate video tags with timestamps [9, 19] , their time complexities are too high for large-scale video retrieval. Fortunately, a new type of review data, i.e., time-sync comments (TSCs) appear on video websites like Youku (www.youku.com), AcFun (www.acfun.tv) and BiliBili (www.bilibili.com) in China, and NicoNico (www.nicovideo.jp) in Japan.", "cite_spans": [{"start": 343, "end": 347, "text": "[44,", "ref_id": "BIBREF43"}, {"start": 348, "end": 351, "text": "45,", "ref_id": "BIBREF44"}, {"start": 352, "end": 355, "text": "47]", "ref_id": "BIBREF46"}, {"start": 418, "end": 422, "text": "[55]", "ref_id": "BIBREF54"}, {"start": 900, "end": 903, "text": "[9,", "ref_id": "BIBREF8"}, {"start": 904, "end": 907, "text": "19]", "ref_id": "BIBREF18"}], "ref_spans": [], "section": "INTRODUCTION"}, {"text": "In this paper, we focus on extracting time-sync video tags from TSCs efficiently, which can enhance users' search experience. When watching a video, many people are willing to share their feelings and exchange ideas with others. TSC is such a new form of real-time and interactive crowdsourced comments [14, 20, 52, 53] . TSCs are displayed as streams of moving subtitles overlaid on the video screen, and convey information involving the content of current video frame, feelings of users or replies to other TSCs. In TSC-enabled online video platforms, users can make their comments synchronized to a video's playback time. That is, once a user posts a TSC, it will be synchronized to the associated video time and immediately displayed onto the video. All viewers (including the writer) of the video can see the TSCs when they watch around the associated video time. Moreover, each TSC has a timestamp to record the corresponding video time when posted. Therefore, compared with traditional video reviews, TSCs are much easier to obtain the local tags with timestamp rather than video-level tags. Moreover, the TSCs are more personalized than traditional reviews, therefore the tags generated by TSCs can better reflect the user's perspective. The users can thereby get high-quality retrieval results when they search for videos with these tags [55] .", "cite_spans": [{"start": 303, "end": 307, "text": "[14,", "ref_id": "BIBREF13"}, {"start": 308, "end": 311, "text": "20,", "ref_id": "BIBREF19"}, {"start": 312, "end": 315, "text": "52,", "ref_id": "BIBREF51"}, {"start": 316, "end": 319, "text": "53]", "ref_id": "BIBREF52"}, {"start": 1347, "end": 1351, "text": "[55]", "ref_id": "BIBREF54"}], "ref_spans": [], "section": "INTRODUCTION"}, {"text": "Recently, some methods have been proposed to generate temporal tags or labels based on TSCs. Wu et al. [55] use statistics and topic model to build Temporal and Personalized Topic Modeling (TPTM) to generate temporal tags. However, their approach is based on the Latent Dirichlet Allocation (LDA) model [6] , which has poor performance when dealing with short and noisy text like TSC [57] . Lv et al. [33] propose a Temporal Deep Structured Semantic Model (T-DSSM) to generate video labels in a supervised way. However, their approach does not consider the semantic association between TSCs, so that some of the video content-independent noises cannot be processed. In summary, TSCs have some features distinguished from the common comments [32, 58] , which make the above methods not very effective in the TSCs: (1) Semantic relevance. Abundant video semantic information is contained that describes both local and global video contents by selecting the time interval of the timestamp. (2) Real-time. TSC is synchronous to the real-time content of the videos. Users may produce different topics when it comes to the same video contents. (3) Herding effects. Herding effects are common in TSCs [17, 61] . That means, latter TSCs may depend on the former ones and have a semantic association with the preceding ones. (4) Noise. Some video content-independent comments and internet slang are included in TSCs, which makes trouble for tag extraction. Due to the above features of TSCs, how to deal with the herding effects, distinguishing the importance of each TSC and consequently identify high-impact TSCs and noises are the major challenges for extracting video tags from TSCs.", "cite_spans": [{"start": 103, "end": 107, "text": "[55]", "ref_id": "BIBREF54"}, {"start": 303, "end": 306, "text": "[6]", "ref_id": "BIBREF5"}, {"start": 384, "end": 388, "text": "[57]", "ref_id": "BIBREF56"}, {"start": 401, "end": 405, "text": "[33]", "ref_id": "BIBREF32"}, {"start": 741, "end": 745, "text": "[32,", "ref_id": "BIBREF31"}, {"start": 746, "end": 749, "text": "58]", "ref_id": "BIBREF57"}, {"start": 1194, "end": 1198, "text": "[17,", "ref_id": "BIBREF16"}, {"start": 1199, "end": 1202, "text": "61]", "ref_id": "BIBREF60"}, {"start": 1316, "end": 1319, "text": "(4)", "ref_id": "BIBREF3"}], "ref_spans": [], "section": "INTRODUCTION"}, {"text": "To make full use of the features of TSC and tackle the above challenges, we propose a graph-based algorithm named Semantic Weight-Inverse Document Frequency (SW-IDF) to generate time-sync video tags automatically. More precisely, we design to reduce the impact of noises by clustering the semantic similar and time-related TSCs and identify high-impact TSCs by their semantic relationships. Intuitively, TSCs including video tags are usually within hot topics and impact on the trend of their follow-up TSCs. On the contrary, the noises usually neither have similar semantic relationships with other TSCs over a period nor influence other TSCs [58] . Moreover, we find that the density of TSCs (number of TSCs per unit time) affects how users communicate. When the density is low (the TSC in a period is sparse), the user can more clearly distinguish the content of each nearby TSC, and therefore is more likely for the user to reply to a specific TSC when posting the new one. Conversely, when the density is high (the TSC in a period is dense), the user cannot clearly distinguish the content of each TSC, but only roughly distinguish the topic of these TSCs. Therefore, the user is more likely to reply to the entire topic instead of a specific TSC. Specifically, in the SW-IDF algorithm, we first treat the TSCs as vertices, generating the semantic association graph (SAG) based on semantic similarities and timestamps of TSCs. Then, we intend to cluster TSCs into different topics. For the videos with low-density TSCs, we propose a dialogue-based clustering algorithm, which is inspired by community detection theory [12, 18, 24] . For the videos with high-density TSCs, we propose a topic center-based cluster algorithm, which is a novel hierarchical agglomerative clustering [37, 39, 41] . These two cluster algorithms can identify the topic of each TSC and distinguish the popularity of each topic in any case. In the clustered subgraph, the in-degrees of each TSC express its affecting TSCs, while the out-degrees express its affected TSCs. Therefore, we design a graph iteration algorithm to assign the weight of each TSC by its degrees so that we can differentiate the meaningful TSCs from noises. Moreover, similar to TF-IDF algorithm, we gain the weight of each word by combining Semantic Weight (SW) and Inverse Document Frequency (IDF) and the video tags are extracted automatically.", "cite_spans": [{"start": 644, "end": 648, "text": "[58]", "ref_id": "BIBREF57"}, {"start": 1623, "end": 1627, "text": "[12,", "ref_id": "BIBREF11"}, {"start": 1628, "end": 1631, "text": "18,", "ref_id": "BIBREF17"}, {"start": 1632, "end": 1635, "text": "24]", "ref_id": "BIBREF23"}, {"start": 1783, "end": 1787, "text": "[37,", "ref_id": "BIBREF36"}, {"start": 1788, "end": 1791, "text": "39,", "ref_id": "BIBREF38"}, {"start": 1792, "end": 1795, "text": "41]", "ref_id": "BIBREF40"}], "ref_spans": [], "section": "INTRODUCTION"}, {"text": "Particularly, this paper is an extended version of [58] . In this extended version, we propose a novel topic center-based cluster algorithm at first, which is more suitable for high-density TSCs. Then, we provide a greedy optimization for the topic center-based algorithm and prove this optimization will not delete any valid case. Finally, we add more experiments to verify the effectiveness of the algorithms. The main contributions of our paper are as follows: 1) We propose a novel graph-based Semantic Weight-Inverse Document Frequency (SW-IDF) algorithm, which can extract video tags in an unsupervised way by mining TSCs. 2) We design two graph clustering algorithms based on the density of the TSCs, i.e., dialoguebased clustering algorithm and topic center-based cluster algorithm, to cluster in the semantic association graph (SAG). These algorithms take the features of TSCs into account and effectively reduce the impact of noises. 3) We evaluate our proposed algorithms with real-world datasets on mainstream video-sharing websites and compare results with classical keyword extraction methods. The results show that SW-IDF outperforms baselines in both precision and recall of video tag extraction.", "cite_spans": [{"start": 51, "end": 55, "text": "[58]", "ref_id": "BIBREF57"}], "ref_spans": [{"start": 541, "end": 549, "text": "(SW-IDF)", "ref_id": null}], "section": "INTRODUCTION"}, {"text": "In the rest of the paper, we introduce the related work in Section 2, and then formally propose our algorithm in Section 3. In Section 4, we verify the effectiveness of our algorithm with experimental results. Conclusions of this work are presented in Section 5.", "cite_spans": [], "ref_spans": [], "section": "INTRODUCTION"}, {"text": "In this section, we introduce the related work from four aspects.", "cite_spans": [], "ref_spans": [], "section": "RELATED WORK"}, {"text": "Time-Sync Comments (TSCs) provide a new source of information regarding the video and have received growing research interests. Wu et al. [55] first introduce TSCs and propose a Temporal and Personalized Topic Modeling (TPTM) to generate temporal tags. However, their approach is based on the Latent Dirichlet Allocation (LDA) model [6] , which has poor performance when dealing with short text like TSC [57] . To describe the video more specifically, Xu and Zhang [56] extract representative TSCs based on a temporal summarization model. Their methods need the pre-extracted keywords in the TSCs, so our algorithm can improve the effectiveness of them. There are also some other applications based on TSCs. Lv et al. [33] propose a Temporal Deep Structured Semantic Model (T-DSSM) to represent comments as semantic vectors and recognize video highlights by semantic vectors in a supervised way. They are the first to analyze the TSC using the neural network. Then, Chen et al. [10] propose the neural network based collaborative filtering to recommend the personalized keyframe from TSCs. However, both the models of [33] and [10] rely on a large amount of human-labeled video segments or predefined emotional tags to train, which limits its applicability to more general scenarios. In this paper, we design a novel graphbased algorithm according to the features of TSC to efficiently and accurately extract keywords automatically in an unsupervised way.", "cite_spans": [{"start": 138, "end": 142, "text": "[55]", "ref_id": "BIBREF54"}, {"start": 333, "end": 336, "text": "[6]", "ref_id": "BIBREF5"}, {"start": 404, "end": 408, "text": "[57]", "ref_id": "BIBREF56"}, {"start": 465, "end": 469, "text": "[56]", "ref_id": "BIBREF55"}, {"start": 718, "end": 722, "text": "[33]", "ref_id": "BIBREF32"}, {"start": 978, "end": 982, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 1118, "end": 1122, "text": "[33]", "ref_id": "BIBREF32"}, {"start": 1127, "end": 1131, "text": "[10]", "ref_id": "BIBREF9"}], "ref_spans": [], "section": "Analysis of time-sync video comments"}, {"text": "Keyword extraction is a classical problem in the field of information retrieval. At present, mainly three categories unsupervised keyword extraction methods are available. The first one is based on word frequency statistics, where TF-IDF is the most commonly used and well-known method. However, this kind of methods only consider the frequency of words and ignore the semantics, which may generate keywords that are not related to video content. The second kind of methods depends on the co-occurrence of words, such as textrank [34] , which is a graph-based ranking model. Similar to the first one, this kind of methods does not consider semantics either, so it cannot solve the noise well. And the last one is according to the topic model. It brings document-topic and topic-word distribution together by simulating document generation process. Blei et al. [6] propose the Latent Dirichlet Allocation(LDA) model, the most representative model. To better deal with short text situation, Yan et al. [57] propose the Bi-term Topic Model (BTM), which models the generation of word co-occurrence patterns (i.e., bi-terms) in the whole corpus directly. Yin and Wang [59, 60] propose the Gibbs Sampling algorithm for the Dirichlet multinomial mixture model for short text clustering and keyword extraction. Although the topic model-based approaches consider the semantics, their basic hypothesis is that the generation of each word is independent and identically distributed. However, some TSCs are generated by herding effects, which does not satisfy the assumptions. Compared with the methods above, our algorithms are well-designed to identify noises by analyzing the semantic relationship between TSCs.", "cite_spans": [{"start": 530, "end": 534, "text": "[34]", "ref_id": "BIBREF33"}, {"start": 860, "end": 863, "text": "[6]", "ref_id": "BIBREF5"}, {"start": 1000, "end": 1004, "text": "[57]", "ref_id": "BIBREF56"}, {"start": 1163, "end": 1167, "text": "[59,", "ref_id": "BIBREF58"}, {"start": 1168, "end": 1171, "text": "60]", "ref_id": "BIBREF59"}], "ref_spans": [], "section": "Tag/keyword extraction"}, {"text": "Semantic similarity calculation is an essential issue of natural language processing, which is widely used in text classification [51] , fuzzy retrieval [1] , and so on. Generally, there are mainly two kinds of approaches to measuring the similarity of documents. One is based on the similarity of the words in sentences. The representations of this approach are proposed by [22] on unsupervised learning and [23, 48] on supervised learning. Considering that time-sync comments contain a mass of newborn internet slangs, it is difficult to obtain accurate results in this way. The other one is based on the sentence vector. The topic model such as LDA, and embedding model such as word2vec [29, 35] are the representations of this kind of methods. Since the embedding model offers much denser feature representation, embedding based similarity computation is better TSCs than the topic model-based methods. Kenter and De Rijke [22] propose a supervised learning method based on external sources of semantic knowledge with word embedding, which considers the weight of the semantic feature. In this paper, we only consider the topics discussed by TSCs while the word order will not change the topics discussed in the TSCs. Therefore, the word order is not important and the sentence2vec [21, 28] and deep learning [16, 36] based methods are not used in this paper.", "cite_spans": [{"start": 130, "end": 134, "text": "[51]", "ref_id": "BIBREF50"}, {"start": 153, "end": 156, "text": "[1]", "ref_id": "BIBREF0"}, {"start": 375, "end": 379, "text": "[22]", "ref_id": "BIBREF21"}, {"start": 409, "end": 413, "text": "[23,", "ref_id": "BIBREF22"}, {"start": 414, "end": 417, "text": "48]", "ref_id": "BIBREF47"}, {"start": 690, "end": 694, "text": "[29,", "ref_id": "BIBREF28"}, {"start": 695, "end": 698, "text": "35]", "ref_id": "BIBREF34"}, {"start": 927, "end": 931, "text": "[22]", "ref_id": "BIBREF21"}, {"start": 1286, "end": 1290, "text": "[21,", "ref_id": "BIBREF20"}, {"start": 1291, "end": 1294, "text": "28]", "ref_id": "BIBREF27"}, {"start": 1313, "end": 1317, "text": "[16,", "ref_id": "BIBREF15"}, {"start": 1318, "end": 1321, "text": "36]", "ref_id": "BIBREF35"}], "ref_spans": [], "section": "Semantic similarity"}, {"text": "Graph clustering algorithms have attracted much research interest in the past. There are two main theories, i.e., community detection theory and hierarchical agglomerative clustering inspired our work. Community detection theory is first proposed by [40] to make natural divisions of network nodes into densely connected subgroups, which brings great inspiration to the graph clustering field. Recently, Ramezani et al. [46] exploit the diffusion information and utilize the conditional random fields to discover the community structures. Li et al. [31] propose a novel local expansion via minimum one norm approach for finding overlapping communities, and provide the theoretical analysis of the local spectral properties. Chakraborty et al. [8] find that the belongingness of nodes in a community is not uniform and design a new vertex-based metric to quantify the degree of belongingness within a community. To reduce the time complexity, Bae et al. [3] propose an algorithm to optimize the map equation, which makes the iterations take less time, and the algorithm converges faster. These above-mentioned community detection theory based graph clustering algorithms provide us with good inspiration for designing dialogue-based clustering algorithms. Besides, hierarchical agglomerative clustering is also a method of graph clustering [37, 39, 41] . Recently, Pang et al. [42] propose a topic-restricted similarity diffusion process to efficiently identify real topics from a large number of candidates. Although their method has a good clustering effect, it has a high time complexity and is not suitable for large-scale data. Compared with the aforementioned hierarchical agglomerative clustering algorithms, we proposed a novel topic center-based clustering algorithm have lower time complexity under the condition of ensuring accuracy.", "cite_spans": [{"start": 250, "end": 254, "text": "[40]", "ref_id": "BIBREF39"}, {"start": 420, "end": 424, "text": "[46]", "ref_id": "BIBREF45"}, {"start": 549, "end": 553, "text": "[31]", "ref_id": "BIBREF30"}, {"start": 743, "end": 746, "text": "[8]", "ref_id": "BIBREF7"}, {"start": 953, "end": 956, "text": "[3]", "ref_id": "BIBREF2"}, {"start": 1339, "end": 1343, "text": "[37,", "ref_id": "BIBREF36"}, {"start": 1344, "end": 1347, "text": "39,", "ref_id": "BIBREF38"}, {"start": 1348, "end": 1351, "text": "41]", "ref_id": "BIBREF40"}, {"start": 1376, "end": 1380, "text": "[42]", "ref_id": "BIBREF41"}], "ref_spans": [], "section": "Graph clustering algorithm"}, {"text": "In this section, we first introduce the construction of Semantic Association Graph (SAG) for TSCs with their semantic similarity in Section 3.1. Then, we propose two graph cluster algorithms, i.e., dialogue-based algorithm and topic center-based algorithm, to cluster the TSCs into subgraphs of different topics in Section 3.2. Moreover, we propose an out-in degree iterative algorithm to get the weight of each TSC and extract keywords as video tags automatically by combining Semantic Weight (SW) and inverse document frequency (IDF) in Section 3.3. Finally, we give the complexity analysis in Section 3.4.", "cite_spans": [], "ref_spans": [], "section": "ALGORITHMS"}, {"text": "The Notation list is shown in Table 1 .", "cite_spans": [], "ref_spans": [{"start": 30, "end": 37, "text": "Table 1", "ref_id": "TABREF0"}], "section": "ALGORITHMS"}, {"text": "In this section, we construct the semantic association graph and define the attributes in the graph. Since TSCs appear in chronological order, they can only affect the upcoming TSCs rather than prior TSCs. We use a directed graph to describe the relationships between TSCs and construct the semantic association graph (SAG).", "cite_spans": [], "ref_spans": [], "section": "Preliminaries and Graph Construction"}, {"text": "In SAG, the vertices (nodes) are TSCs and the edges reflect their semantic association in a topic. Let G denote the directed graph, represented by G = (V , E), where V and E are the sets of nodes and edges. Specifically,", "cite_spans": [], "ref_spans": [], "section": "Preliminaries and Graph Construction"}, {"text": "where N is the number of nodes in V , and M is the number of edges in E. For each TSC i, it has a timestamp t i , denoting the post time in ", "cite_spans": [], "ref_spans": [], "section": "Preliminaries and Graph Construction"}, {"text": "The first node of edge i e i .y", "cite_spans": [], "ref_spans": [], "section": "Preliminaries and Graph Construction"}, {"text": "The second node of edge i e i .w", "cite_spans": [], "ref_spans": [], "section": "Preliminaries and Graph Construction"}, {"text": "The weight of edge e i \u03b3 t Attenuation coefficient \u03c1 d Threshold of dialogue bsed intra-cluster density \u03c1 c Threshold of topic based intra-cluster density vec i", "cite_spans": [], "ref_spans": [], "section": "Preliminaries and Graph Construction"}, {"text": "The embedding vector of TSC i S.center Topic center vector of the set S S.st Start time of the set S S.ct", "cite_spans": [], "ref_spans": [], "section": "Preliminaries and Graph Construction"}, {"text": "Center time of the set S ST Universal set of topic sets match i A set that matches S i maxval i Max Affinity value of set S i", "cite_spans": [], "ref_spans": [], "section": "Preliminaries and Graph Construction"}, {"text": "A priority queue with set pairs U list A queue with sets to be updated", "cite_spans": [], "ref_spans": [], "section": "AffQ"}, {"text": "Since the TSCs are the short texts [55] , in our algorithm, we assume that each TSC has one exact topic. For vertex v i , v i .S is used to describe the set that contain the vertices which have the same topic as v i and |S | is used to express the number of vertices in set S. We use the domain to describe the attributes of edges. For edge e k , e k .x and e k .y are two vertices that are linked by edge e k where t e k .x < t e k .y . The weight of edge i is described as e i .w.", "cite_spans": [{"start": 35, "end": 39, "text": "[55]", "ref_id": "BIBREF54"}], "ref_spans": [], "section": "AffQ"}, {"text": "Besides, e u,v also describes the edge with vertices u and v where t u < t v . Next we will provide the definition of edge weights. As we mentioned in Section 2, an embedding based method word2vec (more details see Section 4.1) is selected to calculate the semantic similarity between each pair of TSCs. Since we only care about the topic of the TSC, the word order is not important. In this paper, we calculate the mean vector of each word in a TSC as the sentence vector. We set the dimension of each vector as d. Therefore, the semantic similarity between TSC a and b is calculated by the cosine angle between ", "cite_spans": [], "ref_spans": [], "section": "AffQ"}, {"text": "Besides, the greater the timestamp interval between two TSCs, the less likely they are in the same topic. So we use the exponential function to express the decay of TSC associations:", "cite_spans": [], "ref_spans": [], "section": "AffQ"}, {"text": "where \u03b3 t is a hyperparameter that control the decay speed.", "cite_spans": [], "ref_spans": [], "section": "AffQ"}, {"text": "Combining the semantic similarity and the time decay, the weight of edge i that link vertices u and v is defined by", "cite_spans": [], "ref_spans": [], "section": "AffQ"}, {"text": "Empirically derived threshold, two TSCs with a negative weight edge are less semantically related (because their angle in the semantic embedding space is greater than \u03c0 /2), and negative edge weights are inconvenient to calculate in graph algorithms. Therefore, when e u,v .w < 0, we set e u,v .w = 0 and delete this edge.", "cite_spans": [], "ref_spans": [], "section": "AffQ"}, {"text": "For a more intuitive description, an example of SAG construction is shown in Fig. 1 (a) , which is a UEFA Champions League video. We select 10 TSCs as nodes and construct the SAG. User A made the TSC 1 \u25cb as \"Great player Messi!\" when he saw the goal. Then user B responded with \"Messi deserves MVP!\" as the TSC 3", "cite_spans": [], "ref_spans": [{"start": 77, "end": 87, "text": "Fig. 1 (a)", "ref_id": null}], "section": "AffQ"}, {"text": "\u25cb. User C makes a TSC \"What is the BGM ?\" as TSC 2 \u25cb to ask the background music, which deviates the video content. So the TSC 2 \u25cb has the less semantic association with other TSCs, while TSC 1 \u25cb and TSC 3 \u25cb have a semantic edge.", "cite_spans": [], "ref_spans": [], "section": "AffQ"}, {"text": "In this section, we will partition the topic of each TSC according to the semantic relationships in SAG. In our algorithm, the TSC that has the similar semantics and similar timestamps should belong to the same topic. However, the density of TSCs (number of TSCs per unit time) affects how users communicate. Therefore, we propose a dialogue-based cluster algorithm in Section 3.2.1 for the videos with sparse TSCs and a topic center-based cluster algorithm in Section 3.2.2 for the videos with dense TSCs.", "cite_spans": [], "ref_spans": [], "section": "Topic Partitioning"}, {"text": "First, we provide a dialogue-based algorithm. When the density of TSCs is low, the user can more clearly distinguish the content of each nearby TSC, and therefore is more likely for the user to reply to a specific TSC when posting the new one. Therefore, we cluster the TSCs according to the semantic relationship between each pair. The main idea is that the mean weight of edges in intra-topic is large while the mean weight of edges that link different topics is small, which satisfies community detection theory [25] .", "cite_spans": [{"start": 515, "end": 519, "text": "[25]", "ref_id": "BIBREF24"}], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "Specifically, in the beginning, each TSC belongs to a unique topic. We use a unique set that only contains itself to achieve the objective. That is, ", "cite_spans": [], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "and", "cite_spans": [], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "where \u03c1 d is the threshold of intra-cluster density. That is, we merge S1 and S2 only if the average edge weight of the their union is greater than the threshold. In this paper, disjoint-set (union-find set) algorithm [49] is used to merge the sets efficiently. When all the edges are solved, TSCs with high semantic similarity are merged into a topic, and the intra-cluster density of each subgraph is higher than the threshold. An example of dialogue-based topic partitioning is shown in Fig. 1 (b1) . The SAG constructed in Fig. 1 (a) is finally partitioned into two topics marked as red and blue, and several noises marked as purple in Fig. 1 (c) . The TSC \"Great player Messi!\" and \"Messi deserves MVP!\" belong to the red topic, while the TSC \"What is the BGM ?\" is identified as a noise.", "cite_spans": [{"start": 218, "end": 222, "text": "[49]", "ref_id": "BIBREF48"}], "ref_spans": [{"start": 490, "end": 501, "text": "Fig. 1 (b1)", "ref_id": null}, {"start": 527, "end": 537, "text": "Fig. 1 (a)", "ref_id": null}, {"start": 640, "end": 650, "text": "Fig. 1 (c)", "ref_id": null}], "section": "Dialogue-based Algorithm."}, {"text": "The full algorithm is shown in Algorithm 1. ", "cite_spans": [], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "merge S 1 and S 2 6: end if 7: end for 3.2.2 Topic Center-based Algorithm. In the dialogue-based algorithm, we assume that TSCs are in the form of dialogues. However, when the density of TSCs is high, the user cannot clearly distinguish the content of each TSC, but only roughly distinguish the topic of these TSCs. Therefore, the user is more likely to reply to the entire topic instead of a specific TSC. The results of dialoguebased model will be disturbed by these situations. Therefore, we provide a Topic Center-based algorithm, which is inspired by Hierarchical Agglomerative Clustering [37] [38] [39] 42] .", "cite_spans": [{"start": 594, "end": 598, "text": "[37]", "ref_id": "BIBREF36"}, {"start": 599, "end": 603, "text": "[38]", "ref_id": "BIBREF37"}, {"start": 604, "end": 608, "text": "[39]", "ref_id": "BIBREF38"}, {"start": 609, "end": 612, "text": "42]", "ref_id": "BIBREF41"}], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "Before proposing this algorithm, the definition of topic center is given at first. As we defined in Section 3.1, the set is used to describe the topic and each TSC can be express as an embedding vector by word2vec. The topic center is the average vectors of all TSCs within the topic. We use S.center to express the topic center vector, and S.st and S.ct to express the start time and center time of topic set S, respectively. Initially, each TSC belongs to a unique topic, so v i .S.center = vec i , v i .S.st = v i .S.ct = t i , where vec i is the sentence embedding vector of TSC i. All these sets belong to ST , which is the universal set of topic sets.", "cite_spans": [], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "Generally, this algorithm can be divided into two parts. (1) Find the nearest two topic centers. (2) Merge the two topic centers. It is actually a Nearest Neighbor Search (NNS) problem [2, 4] , where the k-d tree [4, 5, 13] is one of the most effective methods. However, the analyses of binary search trees have found that the worst case time for range search in a k-dimensional k-d tree containing N nodes is given by the following equation [26] : t wor st = O(k \u00b7 N 1\u2212 1 k ). Besides, the k-d tree has a larger constant.", "cite_spans": [{"start": 185, "end": 188, "text": "[2,", "ref_id": "BIBREF1"}, {"start": 189, "end": 191, "text": "4]", "ref_id": "BIBREF3"}, {"start": 213, "end": 216, "text": "[4,", "ref_id": "BIBREF3"}, {"start": 217, "end": 219, "text": "5,", "ref_id": "BIBREF4"}, {"start": 220, "end": 223, "text": "13]", "ref_id": "BIBREF12"}, {"start": 442, "end": 446, "text": "[26]", "ref_id": "BIBREF25"}], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "In this paper, we propose a greedy algorithm to solve this problem efficiently. In the beginning, for each S i \u2208 ST , we find S j \u2208 ST that", "cite_spans": [], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "where", "cite_spans": [], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "The decay function is still added to avoid that the topics with large time interval are merged. We use match i to express the set that matches S i with maximum Affinity(S i , match i ) value maxval i . And the pair (S i , match i ) is added to a queue AffQ, which is a priority queue where the pair (S k , match k ) with the maximum maxval k is the front.", "cite_spans": [], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "Each time, we take out the front pair (S i , S j ), merging S i and S j , and pop it, until Affinity(S i , S j ) < \u03c1 c . When merging sets, the following updates will be done: First, since S i and S j are merged, all pairs that contain S i or S j , for instance (S i , S u ), should be deleted from AffQ. Then, these sets that matched S i or S j previously like S u are added into the update list U list. Next, the sets S i and S j are removed from ST , and a new set S v is added into ST and U list, where", "cite_spans": [], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "and", "cite_spans": [], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "That is, the center time and the center vector of S v are the weighted average of S i and S j , and the start time of S v is the minimum of S i and S j . Finally, for each set S u \u2208 U list, we find a new match u according to Eq.(6) in ST to match it. What is more, there exists a greedy optimization in the algorithm. Before giving the greedy optimization, we propose a lemma at first: Lemma 3.1. For the set S i , let match i = S j . Then the pair (S i , S j ) will never be solved in AffQ if Affinity(S i , S j ) < maxval j .", "cite_spans": [], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "Proof. Since Affinity(S i , S j ) < maxval j , we have match j = S k S i , and Affinity(S i , S j ) < Affinity(S j , S k ). There exist two cases:", "cite_spans": [], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "Case i: match k = S j Then, in the priority queue AffQ, the pair (S j , S k ) will be solved before (S i , S j ) because Affinity(S i , S j ) < Affinity(S j , S k ). Therefore, the pair (S i , S j ) will be removed from AffQ when solving (S j , S k ).", "cite_spans": [], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "Case ii: match k = S p S j Then we have Affinity(S k , S p ) > Affinity(S j , S k ) (otherwise match k = S j ). So the pair (S k , S p ) will be solved before (S j , S k ) in the priority queue AffQ. When solving (S k , S p ), (S j , S k ) will be removed, and set S j will find a new match j \u2032 in ST . If match j \u2032 = S i , then (S i , S j ) is re-added into AffQ (at that time, Affinity(S i , S j ) = maxval j ). Otherwise, match j \u2032 = S q S i . In that case, the pair (S j , S q ) will be solved before (S i , S j ), and (S i , S j ) will be removed when solving (S j , S q ). Therefore, (S i , S j ) will always be removed and never be solved in any case. \u25a1 According to Lemma 3.1, we propose the greedy optimization: for the set S i , if match i = S j and Affinity(S i , S j ) < maxval j , then the pair (S i , S j ) is rejected and not added into AffQ.", "cite_spans": [], "ref_spans": [], "section": "Dialogue-based Algorithm."}, {"text": "The process of Topic Center-based Algorithm is described in Fig. 1 (b2) and the clustering results are the same with the dialogue-based algorithm in this example showing in Fig. 1 (c) . The full algorithm is shown in Algorithm 2.", "cite_spans": [], "ref_spans": [{"start": 60, "end": 66, "text": "Fig. 1", "ref_id": null}, {"start": 173, "end": 183, "text": "Fig. 1 (c)", "ref_id": null}], "section": "Dialogue-based Algorithm."}, {"text": "We partition the topic in Section 3.2 and get the topic of each TSC. In this section, we will attribute weight to each TSC according to the influence of its topic and the relationship in the semantic graph.", "cite_spans": [], "ref_spans": [], "section": "Weight Distribution and Tag Extraction"}, {"text": "The weight of a TSC is affected by its topic popularity, so we define the popularity of the TSC i as:", "cite_spans": [], "ref_spans": [], "section": "Weight Distribution and Tag Extraction"}, {"text": "where S j (j = 1, 2, ..., K) is the j \u2212 th topic in SAG, and K is the total number of topics in SAG.", "cite_spans": [], "ref_spans": [], "section": "Weight Distribution and Tag Extraction"}, {"text": "Obviously those topics with fewer TSCs are more likely to be noises and have less weight. According to Eq.(11), noises will have small values of popularity. Within the topic, a TSC which affects more TSCs and is affected by fewer TSCs should have a higher weight. In order to quantitatively measure the weight of the TSC in a topic, we design a graph iterative algorithm below.", "cite_spans": [], "ref_spans": [], "section": "Weight Distribution and Tag Extraction"}, {"text": "An influence matrix M N \u00d7N is established at first to express semantic relations within each topic. For the elements in the matrix,", "cite_spans": [], "ref_spans": [], "section": "Weight Distribution and Tag Extraction"}, {"text": "we use I i,k to denote the influence value of i \u2212 th TSC after k iterations. For each TSC i, I i,0 = 1 initially. Then in the k \u2212 th turn of iteration, there are two steps as follows:", "cite_spans": [], "ref_spans": [], "section": "Weight Distribution and Tag Extraction"}, {"text": "and", "cite_spans": [], "ref_spans": [], "section": "Weight Distribution and Tag Extraction"}, {"text": "In the (2k \u2212 1) \u2212 th iteration, we increase the influence value of TSC i based on the values of TSCs that affected by TSC i. We know that a TSC only affects the TSCs lagging behind it, so the find S j = match i using Eq. (6) 8:", "cite_spans": [], "ref_spans": [], "section": "Weight Distribution and Tag Extraction"}, {"text": "calculate maxval i using Eq. (7) 9:", "cite_spans": [], "ref_spans": [], "section": "Weight Distribution and Tag Extraction"}, {"text": "if (maxval j \u2264 maxval i ) and (maxval i > \u03c1 c ) then (S x , S y ) = AffQ.f ront() 15: Remove all the pairs (S x , S u ) and (S u , S x ) in AffQ 16: if S u \u2208 ST and S u S y then 17: add S u into U list S tmp = U list .f ront() 28: find S t j = match tmp using Eq.(6) 29: calculate maxval tmp using Eq.(7) 30: if (maxval S t j \u2264 maxvak tmp ) and (maxval tmp > \u03c1 c ) then 31: push the pair (S tmp , match tmp ) into AffQ 32: end if 33: end while 34: end while TSCs are processed from v N down to v 1 . That is, before we process TSC i, all the TSCs j that t j > t i have been processed. In the (2k) \u2212 th iteration, we reduce the influence value of TSC i based on the values of the TSCs that affect TSC i. Contrary to the (2k \u2212 1) \u2212 th iteration, we process the TSCs from v 1 to v N in the (2k) \u2212 th iteration.", "cite_spans": [{"start": 82, "end": 85, "text": "15:", "ref_id": null}, {"start": 145, "end": 148, "text": "16:", "ref_id": null}, {"start": 178, "end": 181, "text": "17:", "ref_id": null}, {"start": 227, "end": 230, "text": "28:", "ref_id": null}, {"start": 267, "end": 270, "text": "29:", "ref_id": null}, {"start": 305, "end": 308, "text": "30:", "ref_id": null}, {"start": 370, "end": 373, "text": "31:", "ref_id": null}, {"start": 419, "end": 422, "text": "32:", "ref_id": null}, {"start": 430, "end": 433, "text": "33:", "ref_id": null}], "ref_spans": [], "section": "Weight Distribution and Tag Extraction"}, {"text": "The iteration process of SAG in Fig. 1 (c) is shown in Fig. 2. Fig. 2 (a) shows the calculation of the last two nodes (marked as red) that need to be processed in the (2k \u2212 1) \u2212 th iteration (ignore the noise node I 2 ), where the orange edges express their out-degree edges. While Fig. 2 (b) shows the calculation of the last two nodes (marked as red) that need to be processed in the (2k) \u2212 th iteration (ignore the noise node I 10 ), where the green edges express their in-degree edges.", "cite_spans": [], "ref_spans": [{"start": 32, "end": 42, "text": "Fig. 1 (c)", "ref_id": null}, {"start": 55, "end": 73, "text": "Fig. 2. Fig. 2 (a)", "ref_id": "FIGREF3"}, {"start": 282, "end": 292, "text": "Fig. 2 (b)", "ref_id": "FIGREF3"}], "section": "Weight Distribution and Tag Extraction"}, {"text": "The converged influence values of the 10 TSCs in Fig. 1 (c) is shown in Fig. 3 . After 20 iterations, all TSCs converge to the interval [0, 1]. To combine the popularity and the influence value, the weight of TSC i is obtained by", "cite_spans": [], "ref_spans": [{"start": 49, "end": 59, "text": "Fig. 1 (c)", "ref_id": null}, {"start": 72, "end": 78, "text": "Fig. 3", "ref_id": "FIGREF8"}], "section": "Weight Distribution and Tag Extraction"}, {"text": "where T is the number of turns of iterations and depends on the number of nonzero elements in the matrix M N \u00d7N . Therefore, the weight of each word is formulated as below:", "cite_spans": [], "ref_spans": [], "section": "Time Stamp"}, {"text": "where j denotes the TSC that word i appears and I DF i is the inverse document frequency as defined in TF-IDF method. We extract words with the highest SW-IDF value as video tags. After the above steps, those words which appear in the TSCs that are popular and have high impact will be extracted as tags. The complete algorithm is shown in Algorithm 3. ", "cite_spans": [], "ref_spans": [], "section": "Time Stamp"}, {"text": "In this section, we analyze the time complexity and the space complexity of each algorithm.", "cite_spans": [], "ref_spans": [], "section": "Complexity Analysis"}, {"text": "In Algorithm 1, the time complexity of the edge sorting algorithm in line 1 is O(Mlo\u0434M) by using quicksort, and the space complexity is O(M). The amortized time complexity of merging sets by disjoint-set is O(\u03b1(n)) [50] and the space complexity is O(N ), where \u03b1(n) is the inverse Ackermann function that \u03b1(n) < 5. So the total time complexity of Algorithm 1 is O(Mlo\u0434M + M\u03b1(N )), and the space complexity is O(M + N ).", "cite_spans": [{"start": 215, "end": 219, "text": "[50]", "ref_id": "BIBREF49"}], "ref_spans": [], "section": "Complexity Analysis"}, {"text": "In Algorithm 2, the time complexity of initialization from line 1 to line 12 is O(N 2 ), and the space complexity is O(N ). In AffQ, the number of times of merge-operation is limited to N \u2212 1 (because there are at most N sets), and the amortized removal operation is limited to 1 each merge-operation. For each merge operation, the lookup operation and remove operation can be dealt in O(N ) by naive algorithm, or O(lo\u0434N ) by binary balance tree [4] . The worst complexity of total Algorithm 2 is O(N 2 ). The total space complexity is just O(N ).", "cite_spans": [{"start": 447, "end": 450, "text": "[4]", "ref_id": "BIBREF3"}], "ref_spans": [], "section": "Complexity Analysis"}, {"text": "In Algorithm 3, the time complexity is O(T \u00b7N 2 ) and the space complexity is O(M +N 2 ) apparently. In our SAG, M < N 2 because two TSCs with a negative semantic similarity do not have an edge. Therefore, O(Mlo\u0434M + M\u03b1(N )) < N 2 ) in the true TSC data, and the dialogue-base algorithm has a more efficient time complexity than the topic center-based algorithm.", "cite_spans": [], "ref_spans": [], "section": "Complexity Analysis"}, {"text": "In this section, we verify the effectiveness of our proposed method by comparing with four unsupervised methods of keyword extraction. The datasets are crawled from AcFun (www.acfun.cn) and Bilibili. We provide the necessary parameters in our algorithms in Section 4.1 and then analyze the performance of our algorithms on video tag extraction in Section 4.2.", "cite_spans": [], "ref_spans": [], "section": "EXPERIMENTAL STUDY"}, {"text": "We crawl TSCs from two famous Chinese time-sync comments video websites AcFun and Bilibili. The raw TSC texts are full of noises, so we manually remove non-textual TSCs (such as emojis) and establish a set of mapping rules for network slang, which will be substituted by their real meaning in the text. For instance, 233... (2 followed by several 3) means laughter, 666... (several 6) means playing games very well. After that, we segment the words and remove the anomaly symbol (the symbolic expression, such as a smiley face (\u02c6_\u02c6) ) in TSCs by an open-source Chinese-language processing toolbox Jieba 1 . To analyze the algorithms from different aspects, we collected two datasets. To be specific, in the first dataset (called it D1), totally 287 videos with 227,780 comments are collected randomly from music, sports, and movie. To set the hyper-parameters in this paper, we select 167 videos with 126,146 TSCs for the validation set and 120 videos with 101,634 comments for the test set. In the second dataset (called it D2), totally 180 videos with 569,996 comments are collected from Japanese anime. We use D1 to compare our algorithms with baselines, and use D2 to accurately analyze the effects of the two algorithms we proposed at different densities.", "cite_spans": [], "ref_spans": [], "section": "Experimental Setup and Datasets"}, {"text": "We define the density of TSCs as the average number of TSCs per minute. In D2, we divide the density into 5 levels: 0-30, 30-60, 60-90, 90-120 and more than 120 (the intervals are left-closed and right-open). More details include the length of the video, total number of TSCs, density and the number of videos about test set are shown in Table 2 for D1 and Table 3 for D2. We select two undergraduate students and one Ph.D. student as volunteers. For each video, each volunteer chooses 15 words from TSCs and votes them as video tags. The words with two or more votes are selected as the standard tags. Therefore, the number of standard tags per video is different. Moreover, the order of these tags is determined by the number of votes at first. TSCs with more votes rank in front. When the number of votes is the same, the order is determined by the Ph.D. student. 2 In Section 3.1, we use the word2vec method get the embedding vectors of TSCs. In this paper, we choose the skip-gram model of word2vec to pre-train the word embedding vectors and the training algorithm is hierarchical softmax, because both skip-gram model and hierarchical softmax algorithm are better for infrequent words [35] , which is more relevant to the features of the TSCs. We use gensim 3 to train the model, and the training data is crawled from Bilibili with the TSCs of 6,743,912 words. Since we have sufficient training corpus, the dimension d of word2vec is set to 300 as [30] .", "cite_spans": [{"start": 867, "end": 868, "text": "2", "ref_id": "BIBREF1"}, {"start": 1192, "end": 1196, "text": "[35]", "ref_id": "BIBREF34"}, {"start": 1455, "end": 1459, "text": "[30]", "ref_id": "BIBREF29"}], "ref_spans": [{"start": 338, "end": 364, "text": "Table 2 for D1 and Table 3", "ref_id": "TABREF0"}], "section": "Experimental Setup and Datasets"}, {"text": "To further prove the rationality of using the word2vec to calculate the similarities of the TSCs, we use several traditional unsupervised learning and other word embedding methods to calculate the semantic similarities, i.e.", "cite_spans": [], "ref_spans": [], "section": "Experimental Setup and Datasets"}, {"text": "(1) LDA, a famous topic model based method, Latent Dirichlet Allocation [6] .", "cite_spans": [{"start": 72, "end": 75, "text": "[6]", "ref_id": "BIBREF5"}], "ref_spans": [], "section": "Experimental Setup and Datasets"}, {"text": "(2) PPMI, a co-occurrence probability based distributional model, Positive Pointwise Mutual Information [27] (3) HowNet, a HowNet hierarchical sememe tree based approach [54] , where HowNet [11] is a common-sense knowledge base unveiling inter-conceptual relations and inter-attribute relations of concepts. (4) GLoVe, a famous word embedding method, Global Vectors for Word Representation [43] .", "cite_spans": [{"start": 104, "end": 108, "text": "[27]", "ref_id": "BIBREF26"}, {"start": 170, "end": 174, "text": "[54]", "ref_id": "BIBREF53"}, {"start": 190, "end": 194, "text": "[11]", "ref_id": "BIBREF10"}, {"start": 390, "end": 394, "text": "[43]", "ref_id": "BIBREF42"}], "ref_spans": [], "section": "Experimental Setup and Datasets"}, {"text": "We test the top 10 tag extraction results using the above methods to calculate the similarity and build the graph on the verification set (the hyper-parameters used in the experiment are discussed later). In this paper, we use F1-score and MAP (Mean Average Precision, which is the mean of the average precision scores for each query [62] ) to measure the performance of tag extraction. The results are shown in Table 4 . The experimental results show that, in the verification set, Hownet performs the worst among the baselines because of the limited number of word lists. LDA also performs poorly because it is not good at handling short texts. Among the word embedding based methods PPMI, GLoVe, and word2vec, word2vec performs best, which indicates that the fully trained word2vec method has better robustness and is more suitable for calculating the similarity of the TSCs.", "cite_spans": [{"start": 334, "end": 338, "text": "[62]", "ref_id": "BIBREF61"}], "ref_spans": [{"start": 412, "end": 419, "text": "Table 4", "ref_id": "TABREF4"}], "section": "Experimental Setup and Datasets"}, {"text": "What is more, in our algorithm, three parameters need to be determined, i.e., the threshold of intra-cluster density \u03c1 d and \u03c1 c , and the attenuation coefficient \u03b3 t . The \u03c1 d and \u03c1 c control the accuracy of topic clustering. The \u03b3 t is the attenuation coefficient of the interval between time-sync comments, which controls the value of the edge weights in the graph.", "cite_spans": [], "ref_spans": [], "section": "Experimental Setup and Datasets"}, {"text": "We first fix \u03b3 t and adjust the values of \u03c1 d and \u03c1 c so that the F1-score and MAP in the verification set are optimal. Then, we select the optimal \u03c1 d and \u03c1 c and re-adjust \u03b3 t so that the F1-score and MAP in the verification set is optimal. In Bilibili video site, the default time for each TSC to appear on the screen is 10 seconds. Therefore, we assume that the semantic half-life of each TSC is 5 seconds, and calculate the initial \u03b3 t = \u2212ln0.5/5 \u2248 0.14 according to Eq. (2).", "cite_spans": [], "ref_spans": [], "section": "Experimental Setup and Datasets"}, {"text": "To determine \u03c1 d , we fix \u03b3 t = 0.14, adjusting \u03c1 d from 0 to 0.5 in 0.02 steps and observe the F-score and MAP of Top 10 tagging results generated by the dialogue-based algorithm. The results of F1-score and MAP in the validation set are shown in Fig.4 and Fig.5 , respectively. Both in F1-score To determine \u03c1 c , we also fix \u03b3 t = 0.14, adjusting \u03c1 c from 0 to 0.5 in 0.02 steps and observe the F-score and MAP of Top 10 tagging results generated by the topic center-based algorithm. The results of F1-score and MAP in the validation set are shown in Fig.6 and Fig.7 , respectively. For F1-score, \u03c1 c gains better results in the range of 0.34 to 0.42 and get optimal performance at 0.40. For MAP, \u03c1 c gains better results in the range of 0.34 to 0.40 and get the optimal performance at 0.38. Considering both F1-score and MAP, we choose \u03c1 c = 0.38 for the following experiments. With the optimal \u03c1 d and \u03c1 c obtained before, we re-adjust \u03b3 t from 0 to 0.2 in steps 0.01, and observe the F-score and MAP of video tags generated by our algorithms. The results of F1-score and MAP in the validation set are shown in the Fig. 8 and Fig. 9 . For the dialogue-based algorithm, \u03b3 t gains better performance in the range of 0.10 to 0.13 and gets optimal performance at 0.12 for F1-score and 0.11 for MAP. For topic the center-based algorithm, \u03b3 t gains better performance in the range of 0.10 tp 0.14 and gets optimal performance at 0.13 for both F1-score and MAP. To take comprehensive consideration of both F1-score and MAP, we choose \u03b3 t = 0.12 for the dialogue-based algorithm, and \u03b3 t = 0.13 for the topic center-based algorithm in the following experiments. In fact, when \u03b3 t = 0, the semantic association graph is independent of time; when \u03b3 t = +\u221e, all weights of edge equal to 0, and our model is equivalent to TF-IDF.", "cite_spans": [], "ref_spans": [{"start": 248, "end": 263, "text": "Fig.4 and Fig.5", "ref_id": null}, {"start": 554, "end": 559, "text": "Fig.6", "ref_id": null}, {"start": 564, "end": 569, "text": "Fig.7", "ref_id": null}, {"start": 1120, "end": 1126, "text": "Fig. 8", "ref_id": null}, {"start": 1131, "end": 1137, "text": "Fig. 9", "ref_id": null}], "section": "Experimental Setup and Datasets"}, {"text": "Besides, the number of iterations T also needs to be determined. We count the number of iterations when algorithms converge at different densities (we consider the algorithm converges when the average of", "cite_spans": [], "ref_spans": [], "section": "Experimental Setup and Datasets"}, {"text": ", the results are shown in Table 5 . As shown in Table 5 , when the density of TSCs is low, the SAG generated by two algorithms is sparse, and therefore the number of iterations is few. As the density increases, the SAG becomes dense and the number of iterations increases. To simplify, we choose T = 50 in the experiment.", "cite_spans": [], "ref_spans": [{"start": 27, "end": 34, "text": "Table 5", "ref_id": "TABREF5"}, {"start": 49, "end": 56, "text": "Table 5", "ref_id": "TABREF5"}], "section": "Experimental Setup and Datasets"}, {"text": "In this section, we first use D2 to analyze the clustering effect of the two algorithms we proposed at different densities. Then, we use the test set of D1 to verify the effectiveness of the greedy optimization we proposed, and compare our algorithms with the existing methods TF-IDF, TextRank [34] , BTM [57] GSDPMM [59, 60] , and TPTM [55] .", "cite_spans": [{"start": 294, "end": 298, "text": "[34]", "ref_id": "BIBREF33"}, {"start": 305, "end": 309, "text": "[57]", "ref_id": "BIBREF56"}, {"start": 317, "end": 321, "text": "[59,", "ref_id": "BIBREF58"}, {"start": 322, "end": 325, "text": "60]", "ref_id": "BIBREF59"}, {"start": 337, "end": 341, "text": "[55]", "ref_id": "BIBREF54"}], "ref_spans": [], "section": "Results"}, {"text": "In the beginning, an experiment was designed to compare the clustering effect of the two algorithms. Given a set of topics ST = {S 1 , S 2 , ..., S K }, two distance scores are introduced [57] .", "cite_spans": [{"start": 188, "end": 192, "text": "[57]", "ref_id": "BIBREF56"}], "ref_spans": [], "section": "Results"}, {"text": "Average Intra-Cluster Distance:", "cite_spans": [], "ref_spans": [], "section": "Results"}, {"text": "Average Inter-Cluster Distance:", "cite_spans": [], "ref_spans": [], "section": "Results"}, {"text": "Since we use Affinity function to calculate the semantic similarity between two topics, where the higher the similarity is, the greater the function value is. Intuitively, if the Average Intra-Cluster Distance is high and the Average Inter-Cluster Distance is low, then the algorithm has a great clustering effect. Therefore, we calculate", "cite_spans": [], "ref_spans": [], "section": "Results"}, {"text": "to evaluate the quality of clustering algorithms as [7, 15] .", "cite_spans": [{"start": 52, "end": 55, "text": "[7,", "ref_id": "BIBREF6"}, {"start": 56, "end": 59, "text": "15]", "ref_id": "BIBREF14"}], "ref_spans": [], "section": "Results"}, {"text": "Due to the time decay function in the semantic association graph, the H value, the IntraDis and the topic number (cluster number) of the videos vary greatly with the video duration. Therefore, we do not calculate the average value of all the videos directly but define an H \u2212 hit score instead. That is, for each video, we compare the H score obtained by the two cluster algorithms, and the algorithm with the larger H score obtains a hit. The H-hit that the dialogue-based algorithm gets is called D-Hit, and the H-hit that the topic center-based algorithm obtains is called T-Hit. 19 13 17 17 The results are shown in Fig. 10 . The dialogue-based algorithm performs better when the density is lower than 60. As the density increases and exceeds 60, the topic center-based algorithm performs better than the dialogue-based model. Moreover, we directly compare the top 10 tag extraction results of two clustering algorithms at different densities. The results are shown in Table 6 . The tag extraction results are similar to Fig. 10 . From Fig. 10 and Table 6 , we can conclude that the dialogue-based algorithm is better for videos with a density lower than 60, while topic center-based algorithm has significant advantages for videos with the density higher than 60, which fits our assumptions in Section 3.2. Based on the conclusions above, in the test set of D1, we consider the videos with the density of TSCs greater than 60 as high-density videos, and others are low-density videos. Then, the test set in D1 is divided into two parts: videos with high-density TSCs and with low-density TSCs. The details are shown in Table 7 .", "cite_spans": [{"start": 583, "end": 585, "text": "19", "ref_id": "BIBREF18"}], "ref_spans": [{"start": 620, "end": 627, "text": "Fig. 10", "ref_id": "FIGREF12"}, {"start": 973, "end": 980, "text": "Table 6", "ref_id": "TABREF7"}, {"start": 1025, "end": 1032, "text": "Fig. 10", "ref_id": "FIGREF12"}, {"start": 1040, "end": 1047, "text": "Fig. 10", "ref_id": "FIGREF12"}, {"start": 1052, "end": 1059, "text": "Table 6", "ref_id": "TABREF7"}, {"start": 1624, "end": 1631, "text": "Table 7", "ref_id": "TABREF8"}], "section": "Results"}, {"text": "We use the data in Table 7 to verify the effectiveness of greedy optimization we proposed in Section 3.2.2. Specifically, we run the code of Algorithm 2 for 10 times, counting the running time from line 6 to line 34, with and without the greedy optimization (in line 9), respectively. The experiment platform we used is one MacBook Pro 13-inch, 2.9 Ghz Inter Core i5, 8GB 2133MHz Table 8 .", "cite_spans": [], "ref_spans": [{"start": 19, "end": 26, "text": "Table 7", "ref_id": "TABREF8"}, {"start": 380, "end": 387, "text": "Table 8", "ref_id": null}], "section": "Results"}, {"text": "The results show that the greedy optimization reduces 9.99% running time of high-density data and 6.20% of low-density data, respectively, which verifies the effectiveness of our greedy algorithm.", "cite_spans": [], "ref_spans": [], "section": "Results"}, {"text": "Then, we compare our algorithm with different existing methods using the test set of D1. To evaluate the performance of the proposed video tag extraction algorithm, we compare our method with 5 unsupervised keyword extraction methods, i.e., (1) TF-IDF, a classical keyword extraction algorithm.", "cite_spans": [], "ref_spans": [], "section": "Results"}, {"text": "(2) TX, a graph-based text ranking model, textrank [34] , which is inspired by PageRank.", "cite_spans": [{"start": 51, "end": 55, "text": "[34]", "ref_id": "BIBREF33"}], "ref_spans": [], "section": "Results"}, {"text": "(3) BTM, a topic model based algorithm, Biterm Topic Model [57] , which is the improvement of LDA [6] for short texts. The number of topics is 20 in this experiment. (4) GSDPMM, a collapsed Gibbs Sampling algorithm for the Dirichlet Process Multinomial Mixture model [59, 60] , which has good performance when dealing with short texts. We set \u03b1 = 0.1 * D (D is the number of documents in the dataset), K = 1, and \u03b2 = 0.02 in this experiment. (5) TPTM, a Temporal and Personalized Topic Model [55] , which is the first work on automatic TSC tagging. All parameters are set in accordance with [55] . For each method, we calculate the precision, recall, MAP (Mean Average Precision) and F1-score of top 10 tagging results at first. Results of high-density and low-density of TSCs are shown in Table 9 and Table 10 , respectively. In high-density condition, our topic center-based SW-IDF algorithm achieves optimal results in both F1-score and MAP. It increases the F1-score by 21.82% and the MAP by 21.26% compared with the state-of-the-art method TF-IDF in the baselines. In low-density condition, our dialogue-based SW-IDF algorithm achieves optimal results in both F1-score and MAP. It increases the F1-score by 7.24% and the MAP by 7.86% compared with the state-of-the-art method TPTM in the baselines. Compare the two algorithms, we find that the dialogue-based algorithm performs better in lowdensity condition, while topic center-based algorithm performs better in high-density condition, which further proves our assumption in Section 3.2.", "cite_spans": [{"start": 59, "end": 63, "text": "[57]", "ref_id": "BIBREF56"}, {"start": 98, "end": 101, "text": "[6]", "ref_id": "BIBREF5"}, {"start": 267, "end": 271, "text": "[59,", "ref_id": "BIBREF58"}, {"start": 272, "end": 275, "text": "60]", "ref_id": "BIBREF59"}, {"start": 492, "end": 496, "text": "[55]", "ref_id": "BIBREF54"}, {"start": 591, "end": 595, "text": "[55]", "ref_id": "BIBREF54"}], "ref_spans": [{"start": 790, "end": 797, "text": "Table 9", "ref_id": "TABREF9"}, {"start": 802, "end": 810, "text": "Table 10", "ref_id": "TABREF0"}], "section": "Results"}, {"text": "What is more, when the density of TSCs becomes high, the noises increase. Therefore the result of topic model based methods, BTM, GSDPMM, and TPTM are poor and even worse than classical method TF-IDF. However, TF-IDF only counts the number of words and does not consider the semantic relationship of TSCs, so the result is not as good as our algorithms. Relatively, in lowdensity comments, the graph is sparse and noises reduce. That is why our algorithms achieve greater improvement in high-density than in low-density. To further validate our algorithm, we show the precision and recall of top 5 and top 15 candidate tags in Table 11 . The results of each algorithm are similar to the performance of Top 10, which prove that our two algorithms have better performance when extracting video tags from time-sync comments in any situation.", "cite_spans": [], "ref_spans": [{"start": 627, "end": 635, "text": "Table 11", "ref_id": "TABREF0"}], "section": "Results"}, {"text": "Finally, we show the Top 5 of video tags generated by the algorithms above in Table 12 . The Bold italic words indicate the good tags (the tags that all three volunteers voted), while the underline words indicate the bad tags ((the tags that less than two volunteers voted)). The results show that the SW-IDF (Topic Center) and SW-IDF(dialogue) have more good tags and less bad tags than other algorithms, which intuitively demonstrates the superiority of our algorithms. ", "cite_spans": [], "ref_spans": [{"start": 78, "end": 86, "text": "Table 12", "ref_id": "TABREF0"}], "section": "Results"}, {"text": "In this paper, we proposed a novel video tag extraction algorithm to acquire video tags for timesync videos. To deal with the features of time-sync comments, SW-IDF was designed to cluster comments into semantic association graph by taking advantage of their semantic similarities and timestamps. In this way, the noises could be differentiated from the meaningful comments, and thus be effectively eliminated. Finally, video tags were well recognized and extracted in an unsupervised way. Extensive experiments on real-world dataset proved that our algorithm could effectively extract video tags with a significant improvement of precision and recall compared with several baselines, which obviously validates the potential of our algorithm on tag extraction, as well as tackling with the features of time-sync comments.", "cite_spans": [], "ref_spans": [], "section": "CONCLUSION"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Fuzzy rule based profiling approach for enterprise information seeking and retrieval", "authors": [{"first": "Obada", "middle": [], "last": "Alhabashneh", "suffix": ""}, {"first": "Rahat", "middle": [], "last": "Iqbal", "suffix": ""}, {"first": "Faiyaz", "middle": [], "last": "Doctor", "suffix": ""}, {"first": "Anne", "middle": [], "last": "James", "suffix": ""}], "year": 2017, "venue": "Information Sciences", "volume": "394", "issn": "", "pages": "18--37", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "New data structures for orthogonal range searching", "authors": [{"first": "Stephen", "middle": [], "last": "Alstrup", "suffix": ""}, {"first": "Theis", "middle": [], "last": "Stolting Brodal", "suffix": ""}, {"first": "", "middle": [], "last": "Rauhe", "suffix": ""}], "year": 2000, "venue": "Foundations of Computer Science, 2000. Proceedings. 41st Annual Symposium on", "volume": "", "issn": "", "pages": "198--207", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Scalable and efficient flow-based community detection for large-scale graph analysis", "authors": [{"first": "Seung-Hee", "middle": [], "last": "Bae", "suffix": ""}, {"first": "Daniel", "middle": [], "last": "Halperin", "suffix": ""}, {"first": "D", "middle": [], "last": "Jevin", "suffix": ""}, {"first": "Martin", "middle": [], "last": "West", "suffix": ""}, {"first": "Bill", "middle": [], "last": "Rosvall", "suffix": ""}, {"first": "", "middle": [], "last": "Howe", "suffix": ""}], "year": 2017, "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD)", "volume": "11", "issn": "", "pages": "", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Multidimensional binary search trees used for associative searching", "authors": [{"first": "Jon", "middle": ["Louis"], "last": "Bentley", "suffix": ""}], "year": 1975, "venue": "Commun. ACM", "volume": "18", "issn": "", "pages": "509--517", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "K-d trees for semidynamic point sets", "authors": [{"first": "Jon", "middle": ["Louis"], "last": "Bentley", "suffix": ""}], "year": 1990, "venue": "Proceedings of the sixth annual symposium on Computational geometry", "volume": "", "issn": "", "pages": "187--197", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Latent dirichlet allocation", "authors": [{"first": "M", "middle": [], "last": "David", "suffix": ""}, {"first": "", "middle": [], "last": "Blei", "suffix": ""}, {"first": "Y", "middle": [], "last": "Andrew", "suffix": ""}, {"first": "Michael I Jordan", "middle": [], "last": "Ng", "suffix": ""}], "year": 2003, "venue": "Journal of Machine Learning Research", "volume": "3", "issn": "", "pages": "993--1022", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "Query similarity by projecting the queryflow graph", "authors": [{"first": "Ilaria", "middle": [], "last": "Bordino", "suffix": ""}, {"first": "Carlos", "middle": [], "last": "Castillo", "suffix": ""}, {"first": "Debora", "middle": [], "last": "Donato", "suffix": ""}, {"first": "Aristides", "middle": [], "last": "Gionis", "suffix": ""}], "year": 2010, "venue": "Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval", "volume": "", "issn": "", "pages": "515--522", "other_ids": {}}, "BIBREF7": {"ref_id": "b7", "title": "Permanence and community structure in complex networks", "authors": [{"first": "Tanmoy", "middle": [], "last": "Chakraborty", "suffix": ""}, {"first": "Sriram", "middle": [], "last": "Srinivasan", "suffix": ""}, {"first": "Niloy", "middle": [], "last": "Ganguly", "suffix": ""}, {"first": "Animesh", "middle": [], "last": "Mukherjee", "suffix": ""}, {"first": "Sanjukta", "middle": [], "last": "Bhowmick", "suffix": ""}], "year": 2016, "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD)", "volume": "11", "issn": "", "pages": "", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Video captioning with guidance of multimodal latent topics", "authors": [{"first": "Shizhe", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Jia", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Qin", "middle": [], "last": "Jin", "suffix": ""}, {"first": "Alexander", "middle": [], "last": "Hauptmann", "suffix": ""}], "year": 2017, "venue": "Proceedings of the 2017 ACM on Multimedia Conference", "volume": "", "issn": "", "pages": "1838--1846", "other_ids": {}}, "BIBREF9": {"ref_id": "b9", "title": "Personalized key frame recommendation", "authors": [{"first": "Xu", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Yongfeng", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Qingyao", "middle": [], "last": "Ai", "suffix": ""}, {"first": "Hongteng", "middle": [], "last": "Xu", "suffix": ""}, {"first": "Junchi", "middle": [], "last": "Yan", "suffix": ""}, {"first": "Zheng", "middle": [], "last": "Qin", "suffix": ""}], "year": 2017, "venue": "Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval", "volume": "", "issn": "", "pages": "315--324", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "HowNet-a hybrid language and knowledge resource", "authors": [{"first": "Zhendong", "middle": [], "last": "Dong", "suffix": ""}, {"first": "Qiang", "middle": [], "last": "Dong", "suffix": ""}], "year": 2003, "venue": "Natural Language Processing and Knowledge Engineering", "volume": "", "issn": "", "pages": "820--824", "other_ids": {}}, "BIBREF11": {"ref_id": "b11", "title": "Community detection in graphs", "authors": [{"first": "Santo", "middle": [], "last": "Fortunato", "suffix": ""}], "year": 2010, "venue": "Physics reports", "volume": "486", "issn": "", "pages": "75--174", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "An algorithm for finding best matches in logarithmic expected time", "authors": [{"first": "Jon", "middle": ["Louis"], "last": "Jerome H Friedman", "suffix": ""}, {"first": "Raphael", "middle": ["Ari"], "last": "Bentley", "suffix": ""}, {"first": "", "middle": [], "last": "Finkel", "suffix": ""}], "year": 1977, "venue": "ACM Transactions on Mathematical Software (TOMS)", "volume": "3", "issn": "", "pages": "209--226", "other_ids": {}}, "BIBREF13": {"ref_id": "b13", "title": "A reliable task assignment strategy for spatial crowdsourcing in big data environment", "authors": [{"first": "Liqiu", "middle": [], "last": "Gu", "suffix": ""}, {"first": "Kun", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Xiulong", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Song", "middle": [], "last": "Guo", "suffix": ""}, {"first": "Bo", "middle": [], "last": "Liu", "suffix": ""}], "year": 2017, "venue": "2017 IEEE International Conference on Communications (ICC)", "volume": "", "issn": "", "pages": "1--6", "other_ids": {}}, "BIBREF14": {"ref_id": "b14", "title": "Intent-aware query similarity", "authors": [{"first": "Jiafeng", "middle": [], "last": "Guo", "suffix": ""}, {"first": "Xueqi", "middle": [], "last": "Cheng", "suffix": ""}, {"first": "Gu", "middle": [], "last": "Xu", "suffix": ""}, {"first": "Xiaofei", "middle": [], "last": "Zhu", "suffix": ""}], "year": 2011, "venue": "Proceedings of the 20th ACM international conference on Information and knowledge management", "volume": "", "issn": "", "pages": "259--268", "other_ids": {}}, "BIBREF15": {"ref_id": "b15", "title": "Multi-Perspective Sentence Similarity Modeling with Convolutional Neural Networks", "authors": [{"first": "Hua", "middle": [], "last": "He", "suffix": ""}, {"first": "Kevin", "middle": [], "last": "Gimpel", "suffix": ""}, {"first": "Jimmy", "middle": ["J"], "last": "Lin", "suffix": ""}], "year": 2015, "venue": "EMNLP", "volume": "", "issn": "", "pages": "1576--1586", "other_ids": {}}, "BIBREF16": {"ref_id": "b16", "title": "Predicting the Popularity of DanMu-enabled Videos: A Multi-factor View", "authors": [{"first": "Ming", "middle": [], "last": "He", "suffix": ""}, {"first": "Yong", "middle": [], "last": "Ge", "suffix": ""}, {"first": "Le", "middle": [], "last": "Wu", "suffix": ""}, {"first": "Enhong", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Chang", "middle": [], "last": "Tan", "suffix": ""}], "year": 2016, "venue": "Proceedings of International Conference on Database Systems for Advanced Applications", "volume": "", "issn": "", "pages": "351--366", "other_ids": {}}, "BIBREF17": {"ref_id": "b17", "title": "Overlapping community detection for multimedia social networks", "authors": [{"first": "Faliang", "middle": [], "last": "Huang", "suffix": ""}, {"first": "Xuelong", "middle": [], "last": "Li", "suffix": ""}, {"first": "Shichao", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Jilian", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Jinhui", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Zhinian", "middle": [], "last": "Zhai", "suffix": ""}], "year": 2017, "venue": "IEEE Transactions on Multimedia", "volume": "19", "issn": "", "pages": "1881--1893", "other_ids": {}}, "BIBREF18": {"ref_id": "b18", "title": "V-JAUNE: A Framework for Joint Action Recognition and Video Summarization", "authors": [{"first": "Fairouz", "middle": [], "last": "Hussein", "suffix": ""}, {"first": "Massimo", "middle": [], "last": "Piccardi", "suffix": ""}], "year": 2017, "venue": "ACM Transactions on Multimedia Computing", "volume": "13", "issn": "", "pages": "", "other_ids": {}}, "BIBREF19": {"ref_id": "b19", "title": "Utilizing context-relevant keywords extracted from a large collection of user-generated documents for music discovery", "authors": [{"first": "Ziwon", "middle": [], "last": "Hyung", "suffix": ""}, {"first": "Joon-Sang", "middle": [], "last": "Park", "suffix": ""}, {"first": "Kyogu", "middle": [], "last": "Lee", "suffix": ""}], "year": 2017, "venue": "Information Processing & Management", "volume": "53", "issn": "", "pages": "1185--1200", "other_ids": {}}, "BIBREF20": {"ref_id": "b20", "title": "Sensembed: Learning sense embeddings for word and relational similarity", "authors": [{"first": "Ignacio", "middle": [], "last": "Iacobacci", "suffix": ""}, {"first": "Mohammad", "middle": ["Taher"], "last": "Pilehvar", "suffix": ""}, {"first": "Roberto", "middle": [], "last": "Navigli", "suffix": ""}], "year": 2015, "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing", "volume": "1", "issn": "", "pages": "95--105", "other_ids": {}}, "BIBREF21": {"ref_id": "b21", "title": "Short text similarity with word embeddings", "authors": [{"first": "Tom", "middle": [], "last": "Kenter", "suffix": ""}, {"first": "Maarten", "middle": [], "last": "De Rijke", "suffix": ""}], "year": 2015, "venue": "Proceedings of the 24th ACM international on conference on information and knowledge management", "volume": "", "issn": "", "pages": "1411--1420", "other_ids": {}}, "BIBREF22": {"ref_id": "b22", "title": "From word embeddings to document distances", "authors": [{"first": "J", "middle": [], "last": "Matt", "suffix": ""}, {"first": "Yu", "middle": [], "last": "Kusner", "suffix": ""}, {"first": "", "middle": [], "last": "Sun", "suffix": ""}, {"first": "Kilian Q", "middle": [], "last": "Nicholas I Kolkin", "suffix": ""}, {"first": "", "middle": [], "last": "Weinberger", "suffix": ""}], "year": 2015, "venue": "Proceedings of the 32nd International Conference on Machine Learning", "volume": "", "issn": "", "pages": "957--966", "other_ids": {}}, "BIBREF23": {"ref_id": "b23", "title": "Community detection algorithms: a comparative analysis", "authors": [{"first": "Andrea", "middle": [], "last": "Lancichinetti", "suffix": ""}, {"first": "Santo", "middle": [], "last": "Fortunato", "suffix": ""}], "year": 2009, "venue": "Physical review E", "volume": "80", "issn": "", "pages": "", "other_ids": {}}, "BIBREF24": {"ref_id": "b24", "title": "Benchmark graphs for testing community detection algorithms", "authors": [{"first": "Andrea", "middle": [], "last": "Lancichinetti", "suffix": ""}, {"first": "Santo", "middle": [], "last": "Fortunato", "suffix": ""}, {"first": "Filippo", "middle": [], "last": "Radicchi", "suffix": ""}], "year": 2008, "venue": "Physical review E", "volume": "78", "issn": "", "pages": "", "other_ids": {}}, "BIBREF25": {"ref_id": "b25", "title": "Worst-case analysis for region and partial region searches in multidimensional binary search trees and balanced quad trees", "authors": [{"first": "C", "middle": ["K"], "last": "Der-Tsai Lee", "suffix": ""}, {"first": "", "middle": [], "last": "Wong", "suffix": ""}], "year": 1977, "venue": "Acta Informatica", "volume": "9", "issn": "", "pages": "23--29", "other_ids": {}}, "BIBREF26": {"ref_id": "b26", "title": "Linguistic regularities in sparse and explicit word representations", "authors": [{"first": "Omer", "middle": [], "last": "Levy", "suffix": ""}, {"first": "Yoav", "middle": [], "last": "Goldberg", "suffix": ""}], "year": 2014, "venue": "Proceedings of the eighteenth conference on computational natural language learning", "volume": "", "issn": "", "pages": "171--180", "other_ids": {}}, "BIBREF27": {"ref_id": "b27", "title": "Neural word embedding as implicit matrix factorization", "authors": [{"first": "Omer", "middle": [], "last": "Levy", "suffix": ""}, {"first": "Yoav", "middle": [], "last": "Goldberg", "suffix": ""}], "year": 2014, "venue": "Advances in neural information processing systems", "volume": "", "issn": "", "pages": "2177--2185", "other_ids": {}}, "BIBREF28": {"ref_id": "b28", "title": "Improving distributional similarity with lessons learned from word embeddings", "authors": [{"first": "Omer", "middle": [], "last": "Levy", "suffix": ""}, {"first": "Yoav", "middle": [], "last": "Goldberg", "suffix": ""}, {"first": "Ido", "middle": [], "last": "Dagan", "suffix": ""}], "year": 2015, "venue": "Transactions of the Association for Computational Linguistics", "volume": "3", "issn": "", "pages": "211--225", "other_ids": {}}, "BIBREF29": {"ref_id": "b29", "title": "Analogical Reasoning on Chinese Morphological and Semantic Relations", "authors": [{"first": "Shen", "middle": [], "last": "Li", "suffix": ""}, {"first": "Zhe", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "Renfen", "middle": [], "last": "Hu", "suffix": ""}, {"first": "Wensi", "middle": [], "last": "Li", "suffix": ""}, {"first": "Tao", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Xiaoyong", "middle": [], "last": "Du", "suffix": ""}], "year": 2018, "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics", "volume": "2", "issn": "", "pages": "138--143", "other_ids": {}}, "BIBREF30": {"ref_id": "b30", "title": "Local Spectral Clustering for Overlapping Community Detection", "authors": [{"first": "Yixuan", "middle": [], "last": "Li", "suffix": ""}, {"first": "Kun", "middle": [], "last": "He", "suffix": ""}, {"first": "Kyle", "middle": [], "last": "Kloster", "suffix": ""}, {"first": "David", "middle": [], "last": "Bindel", "suffix": ""}, {"first": "John", "middle": [], "last": "Hopcroft", "suffix": ""}], "year": 2018, "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD)", "volume": "12", "issn": "", "pages": "", "other_ids": {}}, "BIBREF31": {"ref_id": "b31", "title": "TSCSet: A Crowdsourced Time-Sync Comment Dataset for Exploration of User Experience Improvement", "authors": [{"first": "Zhenyu", "middle": [], "last": "Liao", "suffix": ""}, {"first": "Yikun", "middle": [], "last": "Xian", "suffix": ""}, {"first": "Xiao", "middle": [], "last": "Yang", "suffix": ""}, {"first": "Qinpei", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "Chenxi", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Jiangfeng", "middle": [], "last": "Li", "suffix": ""}], "year": 2018, "venue": "23rd International Conference on Intelligent User Interfaces", "volume": "", "issn": "", "pages": "641--652", "other_ids": {}}, "BIBREF32": {"ref_id": "b32", "title": "Reading the Videos: Temporal Labeling for Crowdsourced Time-Sync Videos Based on Semantic Embedding", "authors": [{"first": "Guangyi", "middle": [], "last": "Lv", "suffix": ""}, {"first": "Tong", "middle": [], "last": "Xu", "suffix": ""}, {"first": "Enhong", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Qi", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Yi", "middle": [], "last": "Zheng", "suffix": ""}], "year": 2016, "venue": "Proceedings of the 30th AAAI Conference on Artificial Intelligence", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF33": {"ref_id": "b33", "title": "TextRank: Bringing order into texts", "authors": [{"first": "Rada", "middle": [], "last": "Mihalcea", "suffix": ""}, {"first": "Paul", "middle": [], "last": "Tarau", "suffix": ""}], "year": 2004, "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing", "volume": "", "issn": "", "pages": "8--15", "other_ids": {}}, "BIBREF34": {"ref_id": "b34", "title": "Distributed representations of words and phrases and their compositionality", "authors": [{"first": "Tomas", "middle": [], "last": "Mikolov", "suffix": ""}, {"first": "Ilya", "middle": [], "last": "Sutskever", "suffix": ""}, {"first": "Kai", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Greg", "middle": ["S"], "last": "Corrado", "suffix": ""}, {"first": "Jeff", "middle": [], "last": "Dean", "suffix": ""}], "year": 2013, "venue": "Advances in neural information processing systems", "volume": "", "issn": "", "pages": "3111--3119", "other_ids": {}}, "BIBREF35": {"ref_id": "b35", "title": "Siamese Recurrent Architectures for Learning Sentence Similarity", "authors": [{"first": "Jonas", "middle": [], "last": "Mueller", "suffix": ""}, {"first": "Aditya", "middle": [], "last": "Thyagarajan", "suffix": ""}], "year": 2016, "venue": "AAAI", "volume": "", "issn": "", "pages": "2786--2792", "other_ids": {}}, "BIBREF36": {"ref_id": "b36", "title": "Algorithms for hierarchical clustering: an overview", "authors": [{"first": "Fionn", "middle": [], "last": "Murtagh", "suffix": ""}, {"first": "Pedro", "middle": [], "last": "Contreras", "suffix": ""}], "year": 2012, "venue": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery", "volume": "2", "issn": "", "pages": "86--97", "other_ids": {}}, "BIBREF37": {"ref_id": "b37", "title": "Hierarchical clustering of massive, high dimensional data sets by exploiting ultrametric embedding", "authors": [{"first": "Fionn", "middle": [], "last": "Murtagh", "suffix": ""}, {"first": "Geoff", "middle": [], "last": "Downs", "suffix": ""}, {"first": "Pedro", "middle": [], "last": "Contreras", "suffix": ""}], "year": 2008, "venue": "SIAM Journal on Scientific Computing", "volume": "30", "issn": "", "pages": "707--730", "other_ids": {}}, "BIBREF38": {"ref_id": "b38", "title": "Ward's hierarchical agglomerative clustering method: which algorithms implement ward's criterion?", "authors": [{"first": "Fionn", "middle": [], "last": "Murtagh", "suffix": ""}, {"first": "Pierre", "middle": [], "last": "Legendre", "suffix": ""}], "year": 2014, "venue": "Journal of Classification", "volume": "31", "issn": "", "pages": "274--295", "other_ids": {}}, "BIBREF39": {"ref_id": "b39", "title": "Finding and evaluating community structure in networks", "authors": [{"first": "E", "middle": ["J"], "last": "Mark", "suffix": ""}, {"first": "Michelle", "middle": [], "last": "Newman", "suffix": ""}, {"first": "", "middle": [], "last": "Girvan", "suffix": ""}], "year": 2004, "venue": "Physical review E", "volume": "69", "issn": "", "pages": "", "other_ids": {}}, "BIBREF40": {"ref_id": "b40", "title": "Systematic review of clustering high-dimensional and large datasets", "authors": [{"first": "Divya", "middle": [], "last": "Pandove", "suffix": ""}, {"first": "Shivan", "middle": [], "last": "Goel", "suffix": ""}, {"first": "Rinkl", "middle": [], "last": "Rani", "suffix": ""}], "year": 2018, "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD)", "volume": "12", "issn": "", "pages": "", "other_ids": {}}, "BIBREF41": {"ref_id": "b41", "title": "Unsupervised web topic detection using a ranked clustering-like pattern across similarity cascades", "authors": [{"first": "Junbiao", "middle": [], "last": "Pang", "suffix": ""}, {"first": "Fei", "middle": [], "last": "Jia", "suffix": ""}, {"first": "Chunjie", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Weigang", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Qingming", "middle": [], "last": "Huang", "suffix": ""}, {"first": "Baocai", "middle": [], "last": "Yin", "suffix": ""}], "year": 2015, "venue": "IEEE Transactions on Multimedia", "volume": "17", "issn": "", "pages": "843--853", "other_ids": {}}, "BIBREF42": {"ref_id": "b42", "title": "Glove: Global Vectors for Word Representation", "authors": [{"first": "Jeffrey", "middle": [], "last": "Pennington", "suffix": ""}, {"first": "Richard", "middle": [], "last": "Socher", "suffix": ""}, {"first": "Christopher D", "middle": [], "last": "Manning", "suffix": ""}], "year": 2014, "venue": "Proceedings of the 2014 Conference on Empirical Methods on Natural Language Processing", "volume": "14", "issn": "", "pages": "1532--1575", "other_ids": {}}, "BIBREF43": {"ref_id": "b43", "title": "Using author-specified keywords in building an initial reading list of research papers in scientific paper retrieval and recommender systems", "authors": [{"first": "Aravind", "middle": [], "last": "Sesagiri Raamkumar", "suffix": ""}, {"first": "Schubert", "middle": [], "last": "Foo", "suffix": ""}, {"first": "Natalie", "middle": [], "last": "Pang", "suffix": ""}], "year": 2017, "venue": "Information Processing & Management", "volume": "53", "issn": "", "pages": "577--594", "other_ids": {}}, "BIBREF44": {"ref_id": "b44", "title": "Keyword length and matching options as indicators of search intent in sponsored search", "authors": [{"first": "Kkm", "middle": [], "last": "Kutlwano", "suffix": ""}, {"first": "Peter", "middle": [], "last": "Ramaboa", "suffix": ""}, {"first": "", "middle": [], "last": "Fish", "suffix": ""}], "year": 2018, "venue": "Information Processing & Management", "volume": "54", "issn": "", "pages": "175--183", "other_ids": {}}, "BIBREF45": {"ref_id": "b45", "title": "Community Detection Using Diffusion Information", "authors": [{"first": "Maryam", "middle": [], "last": "Ramezani", "suffix": ""}, {"first": "Ali", "middle": [], "last": "Khodadadi", "suffix": ""}, {"first": "", "middle": [], "last": "Hamid R Rabiee", "suffix": ""}], "year": 2018, "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD)", "volume": "12", "issn": "", "pages": "", "other_ids": {}}, "BIBREF46": {"ref_id": "b46", "title": "Automatic video tagging using content redundancy", "authors": [{"first": "Stefan", "middle": [], "last": "Siersdorfer", "suffix": ""}, {"first": "Jose", "middle": [], "last": "San", "suffix": ""}, {"first": "Pedro", "middle": [], "last": "", "suffix": ""}, {"first": "Mark", "middle": [], "last": "Sanderson", "suffix": ""}], "year": 2009, "venue": "Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval", "volume": "", "issn": "", "pages": "395--402", "other_ids": {}}, "BIBREF47": {"ref_id": "b47", "title": "Parsing natural scenes and natural language with recursive neural networks", "authors": [{"first": "Richard", "middle": [], "last": "Socher", "suffix": ""}, {"first": "C", "middle": [], "last": "Cliff", "suffix": ""}, {"first": "Chris", "middle": [], "last": "Lin", "suffix": ""}, {"first": "Andrew Y", "middle": [], "last": "Manning", "suffix": ""}, {"first": "", "middle": [], "last": "Ng", "suffix": ""}], "year": 2011, "venue": "Proceedings of the 28th International Conference on Machine Learning", "volume": "", "issn": "", "pages": "129--136", "other_ids": {}}, "BIBREF48": {"ref_id": "b48", "title": "Efficiency of a good but not linear set union algorithm", "authors": [{"first": "", "middle": [], "last": "Robert Endre Tarjan", "suffix": ""}], "year": 1975, "venue": "Journal of the ACM (JACM)", "volume": "22", "issn": "", "pages": "215--225", "other_ids": {}}, "BIBREF49": {"ref_id": "b49", "title": "A class of algorithms which require nonlinear time to maintain disjoint sets", "authors": [{"first": "", "middle": [], "last": "Robert Endre Tarjan", "suffix": ""}], "year": 1979, "venue": "Journal of computer and system sciences", "volume": "18", "issn": "", "pages": "110--127", "other_ids": {}}, "BIBREF50": {"ref_id": "b50", "title": "World knowledge as indirect supervision for document clustering", "authors": [{"first": "Chenguang", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Yangqiu", "middle": [], "last": "Song", "suffix": ""}, {"first": "Dan", "middle": [], "last": "Roth", "suffix": ""}, {"first": "Ming", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Jiawei", "middle": [], "last": "Han", "suffix": ""}], "year": 2016, "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD)", "volume": "11", "issn": "", "pages": "", "other_ids": {}}, "BIBREF51": {"ref_id": "b51", "title": "Crowdsourcing-based content-centric network: a social perspective", "authors": [{"first": "Kun", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Liqiu", "middle": [], "last": "Gu", "suffix": ""}, {"first": "Song", "middle": [], "last": "Guo", "suffix": ""}, {"first": "Hongbin", "middle": [], "last": "Chen", "suffix": ""}, {"first": "C", "middle": ["M"], "last": "Victor", "suffix": ""}, {"first": "Yanfei", "middle": [], "last": "Leung", "suffix": ""}, {"first": "", "middle": [], "last": "Sun", "suffix": ""}], "year": 2017, "venue": "IEEE Network", "volume": "31", "issn": "", "pages": "28--34", "other_ids": {}}, "BIBREF52": {"ref_id": "b52", "title": "Toward trustworthy crowdsourcing in the social internet of things", "authors": [{"first": "Kun", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Xin", "middle": [], "last": "Qi", "suffix": ""}, {"first": "Lei", "middle": [], "last": "Shu", "suffix": ""}, {"first": "", "middle": [], "last": "Der-Jiunn Deng", "suffix": ""}, {"first": "", "middle": [], "last": "Rodrigues", "suffix": ""}], "year": 2016, "venue": "IEEE Wireless Communications", "volume": "23", "issn": "", "pages": "30--36", "other_ids": {}}, "BIBREF53": {"ref_id": "b53", "title": "Chinese hownet-based multi-factor word similarity algorithm integrated of result modification", "authors": [{"first": "Benbin", "middle": [], "last": "Wu", "suffix": ""}, {"first": "Jing", "middle": [], "last": "Yang", "suffix": ""}, {"first": "Liang", "middle": [], "last": "He", "suffix": ""}], "year": 2012, "venue": "International Conference on Neural Information Processing", "volume": "", "issn": "", "pages": "256--266", "other_ids": {}}, "BIBREF54": {"ref_id": "b54", "title": "Crowdsourced time-sync video tagging using temporal and personalized topic modeling", "authors": [{"first": "Bin", "middle": [], "last": "Wu", "suffix": ""}, {"first": "Erheng", "middle": [], "last": "Zhong", "suffix": ""}, {"first": "Ben", "middle": [], "last": "Tan", "suffix": ""}, {"first": "Andrew", "middle": [], "last": "Horner", "suffix": ""}, {"first": "Qiang", "middle": [], "last": "Yang", "suffix": ""}], "year": 2014, "venue": "Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "volume": "", "issn": "", "pages": "721--730", "other_ids": {}}, "BIBREF55": {"ref_id": "b55", "title": "Bridging Video Content and Comments: Synchronized Video Description with Temporal Summarization of Crowdsourced Time-Sync Comments", "authors": [{"first": "Linli", "middle": [], "last": "Xu", "suffix": ""}, {"first": "Chao", "middle": [], "last": "Zhang", "suffix": ""}], "year": 2017, "venue": "AAAI", "volume": "", "issn": "", "pages": "1611--1617", "other_ids": {}}, "BIBREF56": {"ref_id": "b56", "title": "A biterm topic model for short texts", "authors": [{"first": "Xiaohui", "middle": [], "last": "Yan", "suffix": ""}, {"first": "Jiafeng", "middle": [], "last": "Guo", "suffix": ""}, {"first": "Yanyan", "middle": [], "last": "Lan", "suffix": ""}, {"first": "Xueqi", "middle": [], "last": "Cheng", "suffix": ""}], "year": 2013, "venue": "Proceedings of the 22nd international conference on World Wide Web", "volume": "", "issn": "", "pages": "1445--1456", "other_ids": {}}, "BIBREF57": {"ref_id": "b57", "title": "Crowdsourced time-sync video tagging using semantic association graph", "authors": [{"first": "Wenmian", "middle": [], "last": "Yang", "suffix": ""}, {"first": "Na", "middle": [], "last": "Ruan", "suffix": ""}, {"first": "Wenyuan", "middle": [], "last": "Gao", "suffix": ""}, {"first": "Kun", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Wensheng", "middle": [], "last": "Ran", "suffix": ""}, {"first": "Weijia", "middle": [], "last": "Jia", "suffix": ""}], "year": 2017, "venue": "2017 IEEE International Conference on. IEEE", "volume": "", "issn": "", "pages": "547--552", "other_ids": {}}, "BIBREF58": {"ref_id": "b58", "title": "A dirichlet multinomial mixture model-based approach for short text clustering", "authors": [{"first": "Jianhua", "middle": [], "last": "Yin", "suffix": ""}, {"first": "Jianyong", "middle": [], "last": "Wang", "suffix": ""}], "year": 2014, "venue": "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining", "volume": "", "issn": "", "pages": "233--242", "other_ids": {}}, "BIBREF59": {"ref_id": "b59", "title": "A model-based approach for text clustering with outlier detection", "authors": [{"first": "Jianhua", "middle": [], "last": "Yin", "suffix": ""}, {"first": "Jianyong", "middle": [], "last": "Wang", "suffix": ""}], "year": 2016, "venue": "IEEE 32nd International Conference on. IEEE", "volume": "", "issn": "", "pages": "625--636", "other_ids": {}}, "BIBREF60": {"ref_id": "b60", "title": "Discovering information propagation patterns in microblogging services", "authors": [{"first": "Zhiwen", "middle": [], "last": "Yu", "suffix": ""}, {"first": "Zhu", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Huilei", "middle": [], "last": "He", "suffix": ""}, {"first": "Jilei", "middle": [], "last": "Tian", "suffix": ""}, {"first": "Xinjiang", "middle": [], "last": "Lu", "suffix": ""}, {"first": "Bin", "middle": [], "last": "Guo", "suffix": ""}], "year": 2015, "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD)", "volume": "10", "issn": "", "pages": "", "other_ids": {}}, "BIBREF61": {"ref_id": "b61", "title": "Recall, precision and average precision", "authors": [{"first": "Mu", "middle": [], "last": "Zhu", "suffix": ""}], "year": 2004, "venue": "", "volume": "2", "issn": "", "pages": "", "other_ids": {}}}, "ref_entries": {"FIGREF1": {"text": "Fig. 1. An example of SAG Construction", "latex": null, "type": "figure"}, "FIGREF2": {"text": "{i}. Then edges in set E are sorted by descending order of weight. The new edge set E .y.S. The set S 1 and S 2 should be merged if and only if TSCs in two sets discuss the similar topics. Therefore, we merge S 1 and S 2 if", "latex": null, "type": "figure"}, "FIGREF3": {"text": "Topic center-based algorithmInput the vectors and timestamp of time-sync comments Output the topic set of each time-sync comment1:  for i = 1 to N do", "latex": null, "type": "figure"}, "FIGREF4": {"text": "pair (S i , match i ) into AffQ 11: end if 12: end for 13: while AffQ not empty do 14:", "latex": null, "type": "figure"}, "FIGREF5": {"text": "the pairs (S v , S y ) and (S y , S v ) in AffQ20:    if S v \u2208 ST and S v S x then z .center , S z .st, and S z .ct and using Eq.(8), Eq.(9), Eq.(10)24:    remove S x and S y from ST25:    add S z into ST and U list26:    while U list not empty do27:", "latex": null, "type": "figure"}, "FIGREF6": {"text": "The Iteration process of SAG inFig. 1 (c).", "latex": null, "type": "figure"}, "FIGREF8": {"text": "The influence value of TSCs inFig. 1", "latex": null, "type": "figure"}, "FIGREF9": {"text": "EXTRACTING TAGS BY SW-IDF Input Semantic Association Graph Output Tags of video 1: Assign time-sync comments to a set by Algorithm 1 or Algorithm 2 2: Calculate the influence matrix M N \u00d7N using Eq.14: end for 15: Calculate the SW-IDF of each word using Eq.(16) 16: Select words with max SW-IDF as video tags", "latex": null, "type": "figure"}, "FIGREF10": {"text": "The effect of threshold \u03c1 d in F1The effect of threshold \u03c1 d in MAP The effect of threshold \u03c1 c in F1-score The effect of threshold \u03c1 c in MAP and MAP, \u03c1 d gains better results in the range of 0.32 to 0.38 and get optimal performance at 0.34. Therefore, we choose \u03c1 d = 0.34 for the following experiments.", "latex": null, "type": "figure"}, "FIGREF11": {"text": "The effect of attenuation coefficient \u03b3 t on F1score The effect of attenuation coefficient \u03b3 t on MAP", "latex": null, "type": "figure"}, "FIGREF12": {"text": "The comparison of two clustering algorithms", "latex": null, "type": "figure"}, "TABREF0": {"text": "Notations", "latex": null, "type": "table", "html": "<html><body><table><tr><td>G </td><td>Directed graph\n</td></tr><tr><td>V </td><td>Set of nodes\n</td></tr><tr><td>E </td><td>Set of Edges\n</td></tr><tr><td>N </td><td>Number of nodes in V\n</td></tr><tr><td>M </td><td>Number of edges in E i \u2212 th node in V i \u2212 th edge in E\n</td></tr><tr><td>vi </td></tr><tr><td>ei </td><td>\u00a0</td></tr><tr><td>ti </td><td>Timestamp of node i\n</td></tr><tr><td>vi .S </td><td>Topic set of node vi\n</td></tr><tr><td>|S | </td><td>Number of nodes in set S\n</td></tr><tr><td>ei .x </td><td>The first node of edge i\n</td></tr><tr><td>ei .y </td><td>The second node of edge i\n</td></tr><tr><td>ei .w </td><td>The weight of edge ei\n</td></tr><tr><td>\u03b3t </td><td>Attenuation coefficient\n</td></tr><tr><td>\u03c1d </td><td>Threshold of dialogue bsed intra-cluster density\n</td></tr><tr><td>\u03c1c </td><td>Threshold of topic based intra-cluster density\n</td></tr><tr><td>veci </td><td>The embedding vector of TSC i\n</td></tr><tr><td>S .center </td><td>Topic center vector of the set S\n</td></tr><tr><td>S .st </td><td>Start time of the set S\n</td></tr><tr><td>S .ct </td><td>Center time of the set S\n</td></tr><tr><td>ST </td><td>Universal set of topic sets\n</td></tr><tr><td>matchi maxvali </td><td>A set that matches Si\n</td></tr><tr><td>Max Affinity value of set Si\n</td></tr><tr><td>AffQ </td><td>A priority queue with set pairs\n</td></tr><tr><td>Ulist </td><td>A queue with sets to be updated\n</td></tr><tr><td>Pi </td><td>Popularity of comment i\n</td></tr><tr><td>K </td><td>Total number of topics in SAG\n</td></tr><tr><td>MN\u00d7N </td><td>Influence matrix\n</td></tr><tr><td>Ii,k </td><td>Influence value of comment i after k iterations\n</td></tr><tr><td>Wi </td><td>Weight of comment i\n</td></tr></table></body></html>"}, "TABREF1": {"text": "ALGORITHM 1: Dialogue-based algorithmInput the edge set E Output the topic set of each time-sync comment 1: sort E by descending order of e i .w, obtain E", "latex": null, "type": "table"}, "TABREF2": {"text": "Data Description Table for D1", "latex": null, "type": "table", "html": "<html><body><table><tr><td>\u00a0</td><td>Validation set </td><td>Test set\n</td></tr><tr><td>Total length (minute) </td><td>1,573.29 </td><td>1,441.38\n</td></tr><tr><td>Total TSCs number </td><td>126,146 </td><td>101,634\n</td></tr><tr><td>Density </td><td>80.18 </td><td>70.51\n</td></tr><tr><td>Total video number </td><td>167 </td><td>120\n</td></tr></table></body></html>"}, "TABREF3": {"text": "Data Description Table for D2", "latex": null, "type": "table", "html": "<html><body><table><tr><td>\u00a0</td><td>0-30 </td><td>30-60 </td><td>60-90 </td><td>90-120 </td><td>&gt;120\n</td></tr><tr><td>Total length (minute) </td><td>644.37 </td><td>433.01 </td><td>855.40 </td><td>883.61 </td><td>1,221.55\n</td></tr><tr><td>Total TSCs number </td><td>11,489 </td><td>19,368 </td><td>60,152 </td><td>99,671 </td><td>379,316\n</td></tr><tr><td>Density </td><td>17.83 </td><td>43.72 </td><td>70.32 </td><td>112.80 </td><td>310.52\n</td></tr><tr><td>Total video number </td><td>29 </td><td>21 </td><td>37 </td><td>42 </td><td>51\n</td></tr></table></body></html>"}, "TABREF4": {"text": "The effect of semantic similarity calculation method on the results", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Method </td><td>F1 (dialogue) </td><td>MAP (dialogue) </td><td>F1 (topic center) </td><td>MAP (topic center)\n</td></tr><tr><td>LDA </td><td>0.3625 </td><td>0.3372 </td><td>0.3641 </td><td>0.3224\n</td></tr><tr><td>PPMI </td><td>0.3919 </td><td>0.3705 </td><td>0.4101 </td><td>0.3806\n</td></tr><tr><td>HowNet </td><td>0.3537 </td><td>0.3423 </td><td>0.3468 </td><td>0.3194\n</td></tr><tr><td>GLoVe </td><td>0.4045 </td><td>0.4012 </td><td>0.4202 </td><td>0.4079\n</td></tr><tr><td>Word2Vec </td><td>0.4183 </td><td>0.4041 </td><td>0.4342 </td><td>0.4160\n</td></tr></table></body></html>"}, "TABREF5": {"text": "The number of iterations when algorithms converged at different densities", "latex": null, "type": "table", "html": "<html><body><table><tr><td>\u00a0</td><td>0-30 </td><td>31-60 </td><td>60-90 </td><td>90-120 </td><td>&gt;120\n</td></tr><tr><td>Dialogue </td><td>7.32 </td><td>13.59 </td><td>27.59 </td><td>35.15 </td><td>43.82\n</td></tr><tr><td>Topic center </td><td>6.89 </td><td>14.92 </td><td>23.15 </td><td>31.42 </td><td>45.62\n</td></tr></table></body></html>"}, "TABREF7": {"text": "The tag extraction results at different densities.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>\u00a0</td><td>0-30 </td><td>31-60 </td><td>60-90 </td><td>90-120 </td><td>&gt;120\n</td></tr><tr><td>Dialogue F1-score </td><td>0.4357 </td><td>0.4412 </td><td>0.4219 </td><td>0.4108 </td><td>0.4383\n</td></tr><tr><td>Dialogue MAP </td><td>0.3742 </td><td>0.4027 </td><td>0.4615 </td><td>0.4013 </td><td>0.4872\n</td></tr><tr><td>Topic center F1-score </td><td>0.4139 </td><td>0.4276 </td><td>0.4275 </td><td>0.4216 </td><td>0.4433\n</td></tr><tr><td>Topic center MAP </td><td>0.3615 </td><td>0.3988 </td><td>0.4747 </td><td>0.4077 </td><td>0.5093\n</td></tr></table></body></html>"}, "TABREF8": {"text": "Data Description Table for the test set of D1LPDDR3 with single thread. We add up the total time of all the samples (since the single sample only runs for a short time). The average time of 10 runs is shown in", "latex": null, "type": "table"}, "TABREF9": {"text": "Comparison of different methods on video tag extraction of the top 10 candidate tags with highdensity TSCs.", "latex": null, "type": "table"}, "TABREF10": {"text": "Comparison of different methods on video tag extraction of the top 10 candidate tags with lowdensity TSCs.", "latex": null, "type": "table"}, "TABREF11": {"text": "Comparison of different methods on video tag extraction of the top 5 and top 15 candidate tags", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Method </td><td>H-Top 5 Prec Recall </td><td>H-Top 15 Prec Recall </td><td>L-Top 5 Prec Recall </td><td>L-top 15 Prec Recall\n</td></tr><tr><td>TF-IDF </td><td>0.4182 0.4483 </td><td>0.1871 0.5997 </td><td>0.4140 0.2434 </td><td>0.2993 0.5255\n</td></tr><tr><td>TX </td><td>0.3012 0.3234 </td><td>0.1810 0.5831 </td><td>0.3838 0.2250 </td><td>0.2814 0.5071\n</td></tr><tr><td>BTM </td><td>0.2715 0.2924 </td><td>0.1771 0.5692 </td><td>0.3678 0.2158 </td><td>0.2609 0.4602\n</td></tr><tr><td>GSDPMM </td><td>0.2812 0.3013 </td><td>0.1832 0.5930 </td><td>0.4181 0.2486 </td><td>0.3067 0.5390\n</td></tr><tr><td>TPTM </td><td>0.3627 0.3945 </td><td>0.1805 0.5927 </td><td>0.4365 0.2662 </td><td>0.3183 0.5624\n</td></tr><tr><td>SW-IDF(d) </td><td>0.4935 0.5362 </td><td>0.2273 0.7241 </td><td>0.4654 0.2893 </td><td>0.3556 0.6327\n</td></tr><tr><td>SW-IDF(c) </td><td>0.5300 0.5692 </td><td>0.2345 0.7571 </td><td>0.4518 0.2783 </td><td>0.3410 0.6269\n</td></tr></table></body></html>"}, "TABREF12": {"text": "The top5 results of video tags generated by different algorithms SW-IDF(d)", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Video number </td><td>AcFun ac2643295_1 </td><td>AcFun ac2656362_6 </td><td>AcFun ac2474006_1 </td><td>AcFun ac2669229_1\n</td></tr><tr><td>Screenshot\n</td><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>Timeline </td><td>0:00:00\u223c0:01:10 </td><td>0:07:28\u223c 0:09:49 </td><td>0:00:00\u223c1:04:07 </td><td>0:00:00\u223c0:15:41\n</td></tr><tr><td>Amount </td><td>785 </td><td>764 </td><td>2933 </td><td>2460\n</td></tr><tr><td>Density </td><td>672.84 </td><td>325.08 the Twin Swords\n</td><td>45.78 </td><td>156.84\n</td></tr><tr><td>Brief Encounter\n</td><td>\u00a0</td><td>killer\n</td><td>Cheung Ka Fai\n</td></tr><tr><td>TF-IDF\n</td><td>Peng Julia\n</td><td>Cheung Wai Kin\n</td><td>Ryoko\n</td><td>alert\n</td></tr><tr><td>miss\n</td><td>Jen Hsien-chi\n</td><td>ID card\ncell phone\nacting skill\nkiller\n</td><td>\u00a0</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>Jimmy Lin\n</td><td>shock\n</td></tr><tr><td>\u00a0</td><td>euphonious\nWind and Cloud\n</td><td>idol\n</td><td>ghost\nLouis Cheung\n</td></tr><tr><td>\u00a0</td><td>Brief Encounter\neuphonious\n</td><td>Jen Hsien-chi\n</td><td>\u00a0</td><td>Cheung Ka Fai\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>Cheung Wai Kin\n</td><td>ID card\n</td><td>alert\n</td></tr><tr><td>TextRank\n</td><td>our\n</td><td>hair\n</td><td>actor\n</td><td>movie\n</td></tr><tr><td>Peng Julia\n</td><td>wonderful\nmemory\n</td><td>Japan\n</td><td>terror\n</td></tr><tr><td>\u00a0</td><td>know\n</td><td>\u00a0</td><td>corpse\nfierce\nperform\n</td><td>feel\n</td></tr><tr><td>\u00a0</td><td>Brief Encounter\neuphonious\n</td><td>Jen Hsien-chi\n</td><td>update\nhobbies\nmovie\nCheung Ka Fai\nforget\npowerful\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>hair\n</td><td>\u00a0</td></tr><tr><td>BTM\n</td><td>know\n</td><td>wonderful\nmemery\nCantonese\n</td><td>model\n</td></tr><tr><td>brave\nchildhood\neuphonious\nfollow\nmyself\n</td><td>\u00a0</td><td>employer\ncorpse\n</td></tr><tr><td>\u00a0</td><td>Jen Hsien-chi\n</td><td>New Year\nkiller\n</td><td>\u00a0</td></tr><tr><td>GSDPMM\n</td><td>hair\n</td><td>\u00a0</td><td>alerf\n</td></tr><tr><td>\u00a0</td><td>Cantonese\n</td><td>ID card\nchimney\nbathhouse\ncorpse\ncell phone\nkiller\n</td><td>movie\n</td></tr><tr><td>brave\n</td><td>Jimmy Lin\n</td><td>ghost\n</td></tr><tr><td>\u00a0</td><td>Wind and Cloud\n</td><td>love\n</td><td>fear\n</td></tr><tr><td>\u00a0</td><td>Brief Encounter\n</td><td>Cheung Wai Kin\nmemory\nthe Twin Swords\n</td><td>Cheung Ka Fai\n</td></tr><tr><td>TPTM\n</td><td>stuck\n</td><td>movie\n</td></tr><tr><td>Peng Julia\neuphonious\nchildhood\n</td><td>\u00a0</td><td>\u00a0</td><td>forget\nghost\ndracula movie\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>Jimmy Lin\nhair\nthe Twin Swords Cheung Wai Kin\n</td><td>Japan\nactor\nkiller\nID card\n</td><td>\u00a0</td></tr><tr><td>SW-IDF(d)\n</td><td>Brief Encounter Peng Julia\neuphonious\nexpress\n</td><td>\u00a0</td><td>\u00a0</td><td>Lawrence Cheung Ka Fai\n</td></tr><tr><td>Jen Hsien-chi\n</td><td>Kreisler\n</td><td>Louis Cheung\nalert\nshock\n</td></tr><tr><td>Wind and Cloud\n</td><td>Jimmy Lin\nidol\n</td><td>Japan\ncell phone\nkiller\n</td><td>\u00a0</td></tr><tr><td>SW-IDF(c)\n</td><td>Brief Encounter\n</td><td>Cheung Wai Kin the Twin Swords Jimmy Lin\nmemory\n</td><td>\u00a0</td><td>Cheung Ka Fai\nshock\n</td></tr><tr><td>Peng Julia Wind and Cloud\neuphonious\ntheme song\n</td><td>ID card\nJapan\n</td><td>ghost\n</td></tr><tr><td>\u00a0</td><td>Ryoko\n</td><td>dracula movie\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>Jen Hsien-chi\n</td><td>cell phone\n</td><td>Kuo Tsai-chieh\n</td></tr></table></body></html>"}}, "back_matter": []}