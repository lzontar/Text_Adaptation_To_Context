{"paper_id": "1c588fca3c13303f444f545a5ad5318bdf5ff460", "metadata": {"title": "COMBINING VISIBLE LIGHT AND INFRARED IMAGING FOR EFFICIENT DETECTION OF RESPIRATORY INFECTIONS SUCH AS COVID-19 ON PORTABLE DEVICE", "authors": [{"first": "Zheng", "middle": [], "last": "Jiang", "suffix": "", "affiliation": {"laboratory": "", "institution": "Shanghai Jiao Tong University", "location": {"country": "China"}}, "email": ""}, {"first": "Menghan", "middle": [], "last": "Hu", "suffix": "", "affiliation": {"laboratory": "", "institution": "East China Normal University", "location": {"country": "China"}}, "email": ""}, {"first": "Lei", "middle": [], "last": "Fan", "suffix": "", "affiliation": {"laboratory": "", "institution": "Shanghai Jiao Tong University", "location": {"country": "China"}}, "email": ""}, {"first": "Yaling", "middle": [], "last": "Pan", "suffix": "", "affiliation": {"laboratory": "", "institution": "Shanghai Jiao Tong University", "location": {}}, "email": ""}, {"first": "Wei", "middle": [], "last": "Tang", "suffix": "", "affiliation": {"laboratory": "", "institution": "Shanghai Jiao Tong University", "location": {}}, "email": ""}, {"first": "Guangtao", "middle": [], "last": "Zhai", "suffix": "", "affiliation": {"laboratory": "", "institution": "Shanghai Jiao Tong University", "location": {"country": "China"}}, "email": "zhaiguangtao@sjtu.edu.cn"}, {"first": "Yong", "middle": [], "last": "Lu", "suffix": "", "affiliation": {"laboratory": "", "institution": "Shanghai Jiao Tong University", "location": {}}, "email": ""}, {"first": "Z", "middle": [], "last": "Jiang", "suffix": "", "affiliation": {}, "email": ""}, {"first": "M", "middle": [], "last": "Hu", "suffix": "", "affiliation": {}, "email": ""}]}, "abstract": [{"text": "Coronavirus Disease 2019 caused by severe acute respiratory syndrome coronaviruses 2 (SARS-CoV-2) has become a serious global epidemic in the past few months and caused huge loss to human society worldwide. For such a large-scale epidemic, early detection and isolation of potential virus carriers is essential to curb the spread of the epidemic. Recent studies have shown that one important feature of COVID-19 is the abnormal respiratory status caused by viral infections. During the epidemic, many people tend to wear masks to reduce the risk of getting sick. Therefore, in this paper, we propose a portable non-contact method to screen the health condition of people wearing masks through analysis of the respiratory characteristics. The device mainly consists of a FLIR one thermal camera and an Android phone. This may help identify those potential patients of COVID-19 under practical scenarios such as pre-inspection in schools and hospitals. In this work, we perform the health screening through the combination of the RGB and thermal videos obtained from the dual-mode camera and deep learning architecture. We first accomplish a respiratory data capture technique for people wearing masks by using face recognition. Then, a bidirectional GRU neural network with attention mechanism is applied to the respiratory data to obtain the health screening result. The results of validation experiments show that our model can identify the health status on respiratory with the accuracy of 83.7% on the real-world dataset. The abnormal respiratory data and part of normal respiratory data are collected from Ruijin Hospital Affiliated to The Shanghai Jiao Tong University Medical School. Other normal respiratory data are obtained from healthy people around our researchers.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "During the outbreak of COVID-19 epidemic, early control is essential. Among all the control measures, efficient and safe identification of potential patients is the most important part. Existing researches show that human physiological state can be perceived through breathing [1] , which means respiratory signals are vital signs that can reflect human health condition to a certain extent [2] . Many clinical literature suggests that abnormal respiratory symptoms may be important factors for diagnosis of some specific diseases [3] . Recent studies have found that COVID-19 patients will have obvious respiratory symptoms such as shortness of breath fever, tiredness, and dry cough [4, 5] . Among those symptoms, atypical or irregular breathing is considered as one of the early signs. For many people, early mild respiratory symptoms are difficult to be recognized. Therefore, through the measurement of respiration condition, potential COVID-19 patients can be screened to some extent. This may play an auxiliary diagnostic role, thus helping to find potential patients as early as possible.", "cite_spans": [{"start": 277, "end": 280, "text": "[1]", "ref_id": "BIBREF0"}, {"start": 391, "end": 394, "text": "[2]", "ref_id": "BIBREF1"}, {"start": 531, "end": 534, "text": "[3]", "ref_id": "BIBREF2"}, {"start": 685, "end": 688, "text": "[4,", "ref_id": "BIBREF3"}, {"start": 689, "end": 691, "text": "5]", "ref_id": "BIBREF4"}], "ref_spans": [], "section": "INTRODUCTION"}, {"text": "Traditional respiration measurement requires attachments of sensors to the patient's body [6] . The monitor of respiration is measured through the movement of the chest or abdomen. Contact measurement equipment is bulky, expensive, and time-consuming. The most important thing is that the contact during measurement may increase the risk of spreading infectious diseases such as COVID-19. Therefore, the non-contact measurement is more suitable for the current situation. In recent years, many non-contact respiration measurement methods have been developed based on imaging sensors, doppler radar [7] , depth camera [8] and thermal cam-era [9] . Considering factors such as safety, stability and price, the measurement technology of thermal imaging is the most suitable for extensive promotion. So far, thermal imaging has been used as a monitoring technology in a wide range of medical fields such as estimations of heart rate [10] and breathing rate [11] [12] [13] . Another important thing is that many existing respiration measurement devices are large and immovable. Given the worldwide epdemic, the partable and intelligent screening equipment is required to meet the needs of largescale screening and other application scenarios in a real-time manner. For thermal imaging based respiration measurement, nostril regions and mouth regions are the only focused regions since only these two parts have periodic heat exchange between the body and the outside environment. However, until now, researchers seldom considered measuring thermal respiration data for people wearing masks. During the epidemic of infectious diseases, masks may effectively suppress the spread of the virus according to recent studies [14, 15] . Therefore, developing the respiration measurement method for people wearing masks becomes quite practical. In this study, we develop a portable and intelligent health screening device that uses thermal imaging to extract respiration data from masked people which is then used to do the health screening classification via deep learning architecture.", "cite_spans": [{"start": 90, "end": 93, "text": "[6]", "ref_id": "BIBREF5"}, {"start": 598, "end": 601, "text": "[7]", "ref_id": "BIBREF6"}, {"start": 617, "end": 620, "text": "[8]", "ref_id": "BIBREF7"}, {"start": 641, "end": 644, "text": "[9]", "ref_id": "BIBREF8"}, {"start": 929, "end": 933, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 953, "end": 957, "text": "[11]", "ref_id": "BIBREF10"}, {"start": 958, "end": 962, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 963, "end": 967, "text": "[13]", "ref_id": "BIBREF12"}, {"start": 1713, "end": 1717, "text": "[14,", "ref_id": "BIBREF13"}, {"start": 1718, "end": 1721, "text": "15]", "ref_id": "BIBREF14"}], "ref_spans": [], "section": "INTRODUCTION"}, {"text": "In classification tasks, deep learning has achieved the state-of-the-art performance in most research areas. Compared with traditional classifiers, classifiers based on deep learning can automatically identify the corresponding features and their correlations rather than extracting features manually. For breathing tasks, algorithms based deep learning can also better extract the corresponding features such as breathing rate and breath-to-exhale ratio, and make more accurate predictions [16] [17] [18] [19] . Recently, Many researchers made use of deep learning to analyze the respiratory process. Cho et al. used a convolutional neural network (CNN) to analyze human breathing parameters to determine the degree of nervousness through thermal imaging [20] . Romero et al. applied a language model to detect acoustic events in sleepdisordered breathing through related sounds [21] . Wang et al. utilized deep learning and depth camera to classify abnormal respiratory patterns in real time and achieved excellent results [8] . The disadvantage of this research may be that the equipment is not portable.", "cite_spans": [{"start": 491, "end": 495, "text": "[16]", "ref_id": "BIBREF15"}, {"start": 496, "end": 500, "text": "[17]", "ref_id": "BIBREF16"}, {"start": 501, "end": 505, "text": "[18]", "ref_id": "BIBREF17"}, {"start": 506, "end": 510, "text": "[19]", "ref_id": "BIBREF18"}, {"start": 756, "end": 760, "text": "[20]", "ref_id": "BIBREF19"}, {"start": 880, "end": 884, "text": "[21]", "ref_id": "BIBREF21"}, {"start": 1025, "end": 1028, "text": "[8]", "ref_id": "BIBREF7"}], "ref_spans": [], "section": "INTRODUCTION"}, {"text": "In this paper, we propose a remote, potable and intelligent health screening system based on respiratory data for pre-screening and auxiliary diagnosis of respiratory diseases like COVID-19. In order to be more practical in a situation where people often choose to wear masks, the breathing data capture method for people wearing masks is introduced. After extracting breathing data from the video obtained from the thermal camera, a deep learning neural network is performed to work on the classification between healthy and abnormal respiration conditions. To verify the robustness of our algorithm and the effectiveness of the proposed equipment, we an-alyze the influence of mask type, measurement distance and measurement angle on breathing data.", "cite_spans": [], "ref_spans": [], "section": "INTRODUCTION"}, {"text": "The main contributions of this paper are threefold. First, we combine the face recognition technology with dual-mode imaging to accomplish a respiratory data extraction method for people wearing masks, which is quite essential for current situation. Based on our dual-camera algorithm, the respiration data is successfully obtained from masked facial thermal videos. Subsequently, we propose a classification method to judge abnormal respiratory state with deep learning framework. Finally, based on the two contributions mentioned above, we have implemented a non-contact and efficient health screening system for respiratory infections using the actual measured data from hospital, which may contribute to finding the possible cases of COVID-19 and keeping the control of the secondary spread of SARSCoV-2.", "cite_spans": [], "ref_spans": [], "section": "INTRODUCTION"}, {"text": "A brief introduction to the proposed respiration condition screening method is shown below. We first use the portable and intelligent screening device to get the thermal and the corresponding RGB videos. During the data collection, we also perform a simple real-time screening result. After getting the thermal videos, the first step is to extract respiration data from faces in thermal videos. During the extraction process, we use the face detection method to capture people's masked areas. Then a region of interest (ROI) selection algorithm is proposed to get the region from the mask that stands for the characteristic of breath most. Finally, we use a bidirectional GRU neural network with attention mechanism (BiGRU-AT) model to work on the classification task with the input respiration data.", "cite_spans": [], "ref_spans": [], "section": "METHOD"}, {"text": "Our data collection is achieved by the system shown in Fig.  1 . The whole screening system includes a FLIR one thermal camera, an Android smartphone and the corresponding application we have written, which is used for data acquisition and simple instant analysis. Our screening equipment, whose main advantage is portable, can be easily applied to measure abnormal breathing in many occasions of instant detection.", "cite_spans": [], "ref_spans": [{"start": 55, "end": 62, "text": "Fig.  1", "ref_id": null}], "section": "Overview of Portable and Intelligent Health Screening System for Respiratory Infections"}, {"text": "As shown in Fig. 1 , the FLIR one thermal camera consists of two canmeras, an RGB camera and a thermal camera. We collect the face videos from both cameras and use face recogition method to get the nostril area and forehead area. The temperatures of the two regions are calculated in time series and is shown in the screening result page in Fig. 1(b) . The red line stands for the body temprature and the blue line stands for breathing data. From the breathing data, we can predict the respiratory pattern of the testcase. Then, a simple real-time screening result is given directly in the application Fig. 1 : Overview of portable and intelligent health screening system for respiratory infections: a) device appearance; b) analysis result of the application. (Notice that the system can simultaneously collect body temperature signals. In the current work, this body temperature signal is not considered in the model and is only used as a reference for the users. ) according to the extracted features shown in Fig. 1 . We use the the raw face videos collected from both RGB camera and thermal camera as the data for further study to ensure accuracy and higher performance.", "cite_spans": [], "ref_spans": [{"start": 12, "end": 18, "text": "Fig. 1", "ref_id": null}, {"start": 341, "end": 350, "text": "Fig. 1(b)", "ref_id": null}, {"start": 602, "end": 608, "text": "Fig. 1", "ref_id": null}, {"start": 1013, "end": 1019, "text": "Fig. 1", "ref_id": null}], "section": "Overview of Portable and Intelligent Health Screening System for Respiratory Infections"}, {"text": "When continuous breathing activities performs, there is a fact that periodic temperature fluctuations occur around the nostril due to the inspiration and expiration cycles. Therefore, respiration data can be obtained by analyzing the temperature data around the nostril based on thermal image sequence. However, when people wear masks, many facial features are blocked because of this. Merely recognizing the face through thermal image will lose a lot of geometric and textural facial details, resulting in recognition errors of the face and mask parts. In order to solve this problem, we adopt the method based on two parallel located RGB and infrared cameras for face and mask region recognition. The masked region of face is first captured in the RGB camera, then such region is mapped to the thermal image with a related mapping function.", "cite_spans": [], "ref_spans": [], "section": "Detection of Masked Region from Dual Mode Image"}, {"text": "The algorithm for masked face detection is based on pyramidbox model created by Tang et al. [22] . The main idea is to apply tricks like Gaussian pyramidbox in deep learning to get the context correlations as further characteristics. The face image is first used to extract features of different scales using Gaussian pyramid algorithm. For those high-level contextual features, a feature pyramid network is proposed to further excavate high-level contextual features. Then, the output together with those low-level features are combined in lowlevel feature pyramid layers. Finally, the result is obtained after another two layers of deep neural network. For faces that a lot of features are lost due to the cover of mask, such a context-sensitive structure can obtain more feature correlations and thus improve the accuracy of face detection. In our experiment, we use the open source model from paddlehub to detect the face area on RGB videos. The next step is to extract the masked area and map the area from RGB video to thermal video. Since the position of the mask on the human face is fixed, after obtaining the position coordinates of the human face, we obtain the mask area of the face by scaling down in equal proportions. For a detected face with width w, and height h, the loaction of left-up corner is defined as (0, 0), the loaction of right-bottom corner is then (w, h). The corresponding coordinate of the two corners of mask region is decalred as (w/4, h/2) and (3w/4, 4h/5). Considering that the background to the boundary of the mask will produce a large contrast with the movement, which is easy to cause errors, we choose the center area of the mask through this division. Then the selected area is mapped from the RGB image to thermal image to obtain the masked region in thermal videos.", "cite_spans": [{"start": 92, "end": 96, "text": "[22]", "ref_id": "BIBREF22"}], "ref_spans": [], "section": "Detection of Masked Region from Dual Mode Image"}, {"text": "After getting the masked region in thermal videos, we need to get the region of interest (ROI) that represents breathing features. Recent studies often characterize breathing data through temperature changes around the nostril [10, 23] . However when people wear masks, there exists another problem that the nostrils are also blocked by the masks, and when people wearing different masks, the ROI may be different. Therefore, we perform a ROI tracking method based on maximizing the variance of thermal image sequence to extract a certain area on the masked region of the thermal video which stands for the breath signals most.", "cite_spans": [{"start": 227, "end": 231, "text": "[10,", "ref_id": "BIBREF9"}, {"start": 232, "end": 235, "text": "23]", "ref_id": "BIBREF23"}], "ref_spans": [], "section": "Extract Respiration Data from ROI"}, {"text": "Due to the lack of texture features in masked regions compared to human faces, we judge the ROI by the temperature change of thermal image sequence. The main idea is to traverse the masked region in the thermal images and find a small block with the largest temperature change as the selected ROI. The position of a certain block is fixed in the masked region among all the frames since the nostril area is fixed on the face region. We do not need to consider the movement of the block since our face recognition algorithm can detect the mask position in each frame's thermal image. For a certain block with height m, and width n, we define the average pixel intensity at frame t as:", "cite_spans": [], "ref_spans": [], "section": "Extract Respiration Data from ROI"}, {"text": "For thermal images,s(t) represents the temperature value at frame t. For every block we obtained, we calculate their s(t) on time line. Then, for each block n, the total variance of the list of average pixel intensity with T frames \u03c3 2 s (n) is calculated as shown in Eq. 2, where \u00b5 stands for the mean value ofs(t).", "cite_spans": [], "ref_spans": [], "section": "Extract Respiration Data from ROI"}, {"text": "Since respiration is a periodic data spread out from the nostril area, we can consider that the block with the largest variance is the position where the heat changes most in both frequency and value within the mask, which stands for the breath data most in the masked region. We adjust the corresponding block size according to the size of the masked region. For a masked region with N blocks, the final ROI is selected by:", "cite_spans": [], "ref_spans": [], "section": "Extract Respiration Data from ROI"}, {"text": "For each thermal video, we traverse all possible blocks in the mask regions of each frame and find the ROIs for each frame by the method above. The respiration data is then defined ass(t)(0 < t < T ), which is the pixel intensities of ROIs in all the frames.", "cite_spans": [], "ref_spans": [], "section": "Extract Respiration Data from ROI"}, {"text": "We apply a BiGRU-AT neural network to do the classification task on judging whether the respiration condition is healthy or not as shown in Fig. 3 . The input of the network is the respiration data obtained by our extraction method. Since the respiratory data is time series, it can be regarded as a time series classification problem. Therefore, we choose the Gate Recurrent Unit (GRU) network with bidirection and attention layer to work on the sequence prediction task.", "cite_spans": [], "ref_spans": [{"start": 140, "end": 146, "text": "Fig. 3", "ref_id": "FIGREF1"}], "section": "BiGRU-AT Neural Network"}, {"text": "Among all the deep learning structures, recurrent neural network (RNN) is a type of neural network which is specially used to process time series data samples [24] . For a time step t, the RNN model can be represented by:", "cite_spans": [{"start": 159, "end": 163, "text": "[24]", "ref_id": "BIBREF24"}], "ref_spans": [], "section": "BiGRU-AT Neural Network"}, {"text": "where x (t) , h (t) and o (t) stands for the current input state, hidden state and output at time step t respectively. V, W, U are parameters obtained by training procedure. b is the bias and \u03c3 and \u03c6 are activation functions. The final prediction is y (t) . Long-short term memory network is developed on the basis of RNN [25] . Compared to RNN, which can only memorize and analyze short-term information, it can process relatively long-term information, and is suitable for problems with short-term delays or long time intervals. Based on LSTM, many related structures are proposed in recent years [26] . GRU is a simplified LSTM which merges three doors of LSTM (forget, input and output) into two doors (update and reset) [27] . For tasks with a few data, GRU may achieve a better result than LSTM since it includes less parameters. In our task, since the input of the neural network is only the respiration data in time sequence, the GRU network may perform a better result than LSTM network. The structure of GRU can be expressed by the following equations:", "cite_spans": [{"start": 322, "end": 326, "text": "[25]", "ref_id": "BIBREF25"}, {"start": 599, "end": 603, "text": "[26]", "ref_id": "BIBREF26"}, {"start": 725, "end": 729, "text": "[27]", "ref_id": "BIBREF27"}], "ref_spans": [], "section": "BiGRU-AT Neural Network"}, {"text": "where r t is the reset gate that controls the amount of information being passed to the new state from the previous states. z t stands for the update gate which determines the amount of information being forgotten and added. W r , W z and W h are trained parameters that vary in the training procedure.h t is the candidate hidden layer which can be regarded as a summary of the above information h t\u22121 and the input information x t at time step t. h t is the output layer at time step t which will be sent to the next unit. The bidirectional RNN has been widely used in natural language processing [28] . The advantage of such network structure is that it can strengthen the correlation between context of the sequence. As the respiratory data is a periodic sequence, we use bidirectional GRU to obtain more information from the periodic sequence. The difference between bidirectional GRU and normal GRU is that backfoward sequence of data is spliced to the original forward sequence of data. In this way, the hidden layer of the original h(t) is changed to:", "cite_spans": [{"start": 598, "end": 602, "text": "[28]", "ref_id": "BIBREF28"}], "ref_spans": [], "section": "BiGRU-AT Neural Network"}, {"text": "where \u2212 \u2192 h t is the original hidden layer and \u2190 \u2212 h t is the backfoward sequence of \u2212 \u2192 h t . During the analysis of respiratory data, the entire waveform in time sequence should be taken into consideration. For some specic breathing pattern such as sphyxia, several paticular features such as sudden acceleration may occur only at a certain point in the entire process. However, if we only use the BiGRU network, these features may be weakened as the time sequence data is input step by step which may cause a larger error in prediction. Therefore, we add an attention layer to the network, which can ensure that certain key point features in the breathing process can be maximized.", "cite_spans": [], "ref_spans": [], "section": "BiGRU-AT Neural Network"}, {"text": "Attention mechanism is a choice to focus only on those important points among the total data [29] . It is often combined with neural networks like RNN. Before the RNN model summarizes the hidden states for the output, an attention layer can make an estimation of all outputs and find the most important ones. This mechanism has been widely used in many research areas. The structure of attention layer is:", "cite_spans": [{"start": 93, "end": 97, "text": "[29]", "ref_id": "BIBREF29"}], "ref_spans": [], "section": "BiGRU-AT Neural Network"}, {"text": "where h t represents the BiGRU layer output at time step t, which is bidirectional. W u and b w are also parameters that vary in the training process. a t performs a softmax fucntion on u t to get the weight of each step t. Finally, the output of the attention layer s is a combination of all the steps from BiGRU with different weights. By applying another softmax function to the output s, we get the final prediction of the classification task. The structure of the whole network is shown in Fig. 3 .", "cite_spans": [], "ref_spans": [{"start": 495, "end": 501, "text": "Fig. 3", "ref_id": "FIGREF1"}], "section": "BiGRU-AT Neural Network"}, {"text": "Our goal is to distinguish whether there is an epidemic infectious disease such as COVID-19 according to the abnormal breathing in the respiratory system. Our dataset is not collected from patients with COVID-19. These data were obtained from the inpatients of the respiratory disease department and cardiology department in Ruijin Hospital. Most of the patients we collected data from only caught with basic or chronic respiratory disease. They did not have fever which is the typical respiratory symptoms of infectious diseases. Therefore, the body temperature is not taken into consideration in our current screening system. In Ruijin Hospital wards, we use a FLIR one thermal camera connected to an Android phone to work on the data collection. We collected data from 73 people. For each person, we collect two 20-second infrared and RGB camera data with a sampling frequency of 10 Hz. Through data cutting and oversampling, we finally obtained 1,925 healthy breathing data and 2,292 abnormal breathing data, a total of 4,217 data. Each piece of data consists of 100 frames of infrared and RGB videos in 10 seconds. In the BiGRU-AT network, the hidden cells in BiGRU layer and attention layers are 32 and 8 respectively. The breathing data is normalized before input into the neural network and we use cross-entropy as the loss function. During the training process, we separate the dataset into two parts. The training set includes 1,427 healthy breathing data and 1,780 abnormal breathing data. And the test set contains 498 healthy breathing data and 512 abnormal breathing data. Once this paper is accepted, we will release the dataset used in the current work for non-commercial users. Among the whole dataset, we choose 4 typical respiratory data examples as shown in Fig. 4. Fig. 4(a) and Fig. 4 (b) stand for the abnormal respiratory patterns extracted from patients. Fig. 4 (c) and Fig. 4(d) represent the normal respiratory pattern called Eupnea from healthy participants. By comparison, we can find that the respiratory of normal people is in strong periodic and evenly distributed while abnormal respiratory data tend to be more irregular. Generally speaking, most abnormal breathing data from respiratory infections have faster frequency and irregular amplitude.", "cite_spans": [], "ref_spans": [{"start": 1778, "end": 1795, "text": "Fig. 4. Fig. 4(a)", "ref_id": "FIGREF2"}, {"start": 1800, "end": 1806, "text": "Fig. 4", "ref_id": "FIGREF2"}, {"start": 1880, "end": 1886, "text": "Fig. 4", "ref_id": "FIGREF2"}, {"start": 1895, "end": 1904, "text": "Fig. 4(d)", "ref_id": "FIGREF2"}], "section": "Dataset Explanation and Experimental Settings"}, {"text": "The experimental results are shown in Table. 1. We consider four evaluation metrics viz. Accuracy, Precision, Recall and F1. To measure the performance of our model, we compare the result of our model with three other models which are GRU-AT, BiLSTM-AT and LSTM respectively. The result shows that our method performs better than any other networks in all evaluation metrics despite the precision value of GRU-AT. By comparison, the experimental result demonstrates that attention mechanism is well-performed in keeping important node features in the time series of breathing data since the networks with attention layer all perform a better result than LSTM. Another point is that GRU based networks achieve better result than LSTM based networks. This may beacuse our data set is relatively small which can't fill the demand of the LSTM based networks. GRU based networks require less data than LSTM and perform better result in our respiration condition classification task. To figure out the detailed information about the classification of respiratory state, we plotted the confusion matrixs of the four models as demonstrated in Fig. 5 . As can be seen from the results, the performance improvement of BiGRU-AT compared to LSTM is mainly in the accuracy rate of the negative class. This is because many scatter-like abnormalities in the time series of abnormal breathing are better recognized by the attention mechanism. Besides, the misclassification rate of the four networks are relatively high to some extent which may because many positive samples do not have typical respiratory infections characteristics since part of the patients caught other lung-related diseases.", "cite_spans": [], "ref_spans": [{"start": 38, "end": 44, "text": "Table.", "ref_id": null}, {"start": 1135, "end": 1141, "text": "Fig. 5", "ref_id": "FIGREF3"}], "section": "Experimental Result"}, {"text": "In the analysis section, we give 3 comparasions from different aspects to prove the robustness of our algorithm and device.", "cite_spans": [], "ref_spans": [], "section": "Analysis"}, {"text": "In order to measure the robustness of our breathing data acquisition algorithm and the effectiveness of the proposed portable device, we analyze the breathing data of the same person wearing different masks. We design 3 mask wearing scenarios that cover most situations: wearing one surgical mask (blue line); wearing one KN95 (N95) mask (red line) and wearing two surgical masks (green line). The results are shown in Fig. 6 . It can be seen from the experimental results that no matter what kind of mask is worn, or even two masks, the respiratory data can be well recognized. This proves the stability of our algorithm and device. However, since different masks have different thermal insulation capabilities, the average breathing temperature may vary as the mask changes. To minimize this error, respiratory data are normalized before input into the neural network. ", "cite_spans": [], "ref_spans": [{"start": 419, "end": 425, "text": "Fig. 6", "ref_id": "FIGREF4"}], "section": "Influence of Mask Types on Respiratory Data"}, {"text": "In order to verify the robustness of our algorithm and device in different scenarios, we design experiments to collect respiratory data at different distances. Considering the limitations of handheld devices, we test the collection of facial respiration data from a distance of 0 to 2 meters. The result is demonstrated in Fig. 7 . The signal tends to be periodic from the position of 10 centimeters, and it does not start to lose regularity until about 1.8 meters. At a distance of about 10 centimeters, the complete face begins to appear in the camera video. When the distance comes to 1.8 meters, our face detection algorithm begins to fail gradually due to the distance and pixel limitation. This experiment verifies that our algorithm and device can guarantee relatively accurate measurement results in the distance range of 0.1 meters to 1.8 meters.", "cite_spans": [], "ref_spans": [{"start": 323, "end": 329, "text": "Fig. 7", "ref_id": "FIGREF5"}], "section": "Limitation of Distance to the Camera during Measurement"}, {"text": "Considering that breath detection will be applied in different scenarios, we design this experiment to show the actual situation under different shooting angles. We define the camera directly towards the face to be 0 degree, and design an experiment in which the shooting angle gradually changed from 45 degrees to 0 degree. We consider the transformation of two angles: horizontal and vertical, which respectively represent left and right turning and nodding. The results in the two cases are quite different as shown in Fig. 8 . Our algorithm and device maintain good results in horizontal rotation, but it is difficult to obtain precise respiratory data in vertical rotation. This means participants can trun left or turn right during the measurement but can't nod or head up since this may impact the measurement result.", "cite_spans": [], "ref_spans": [{"start": 522, "end": 528, "text": "Fig. 8", "ref_id": "FIGREF6"}], "section": "Limitation of Angle to the Camera during Measurement"}, {"text": "In this paper, we propose a abnormal breathing detection method based on a portable dual-mode camera which can reocrd both RGB and thermal videos. In our detection method, we first accomplished an accurate and robust respiratory data detecion algorithm which can precisely extract breathing data from people wearing masks. Then, a BiGRU-AT network is applied to work on the screening of respiratory infections.", "cite_spans": [], "ref_spans": [], "section": "CONCLUSION"}, {"text": "In validation experiments, the obtained BiGRU-AT network achieves a realtively good result with the accuracy of 83.7% on the real-world dataset. It is foreseeable that in patients with COVID-19 who have more clinical respiratory symptoms, this classification method may yield better results. During the current outbreak of COVID-19, our research can work as prescan method for abnomral breathing in many scenarios such as community, campus and hospital which may contribute to distuigishing the possible cases , and then keep the control of the virus spread.", "cite_spans": [], "ref_spans": [], "section": "CONCLUSION"}, {"text": "In future research, on the basis of ensuring portability, we plan to use a more stable algorithm to minimize the effect of different masks on measurement of breathing condition. Besides, temperature may be taken into consideration to achieve a higher detection accuracy on respiratory infections.", "cite_spans": [], "ref_spans": [], "section": "CONCLUSION"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Respiratory rate: the neglected vital sign", "authors": [{"first": "Rinaldo", "middle": [], "last": "Michelle A Cretikos", "suffix": ""}, {"first": "Ken", "middle": [], "last": "Bellomo", "suffix": ""}, {"first": "Jack", "middle": [], "last": "Hillman", "suffix": ""}, {"first": "Simon", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Arthas", "middle": [], "last": "Finfer", "suffix": ""}, {"first": "", "middle": [], "last": "Flabouris", "suffix": ""}], "year": 2008, "venue": "Medical Journal of Australia", "volume": "188", "issn": "11", "pages": "657--659", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "Non-contact respiratory rate measurement validation for hospitalized patients", "authors": [{"first": "D", "middle": [], "last": "Amy", "suffix": ""}, {"first": "", "middle": [], "last": "Droitcour", "suffix": ""}, {"first": "B", "middle": [], "last": "Todd", "suffix": ""}, {"first": "Byung-Kwon", "middle": [], "last": "Seto", "suffix": ""}, {"first": "Shuhei", "middle": [], "last": "Park", "suffix": ""}, {"first": "Alex", "middle": [], "last": "Yamada", "suffix": ""}, {"first": "Charles", "middle": ["El"], "last": "Vergara", "suffix": ""}, {"first": "Tommy", "middle": [], "last": "Hourani", "suffix": ""}, {"first": "Andrea", "middle": [], "last": "Shing", "suffix": ""}, {"first": "", "middle": [], "last": "Yuen", "suffix": ""}, {"first": "M", "middle": [], "last": "Victor", "suffix": ""}, {"first": "Olga", "middle": [], "last": "Lubecke", "suffix": ""}, {"first": "", "middle": [], "last": "Boric-Lubecke", "suffix": ""}], "year": 2009, "venue": "2009 Annual International Conference of the IEEE Engineering in Medicine and Biology Society", "volume": "", "issn": "", "pages": "4812--4815", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Dysfunctional breathing: a review of the literature and proposal for classification", "authors": [{"first": "Richard", "middle": [], "last": "Boulding", "suffix": ""}, {"first": "Rebecca", "middle": [], "last": "Stacey", "suffix": ""}, {"first": "Rob", "middle": [], "last": "Niven", "suffix": ""}, {"first": "Stephen J", "middle": [], "last": "Fowler", "suffix": ""}], "year": 2016, "venue": "European Respiratory Review", "volume": "25", "issn": "141", "pages": "287--294", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Pathological findings of covid-19 associated with acute respiratory distress syndrome", "authors": [{"first": "Zhe", "middle": [], "last": "Xu", "suffix": ""}, {"first": "Lei", "middle": [], "last": "Shi", "suffix": ""}, {"first": "Yijin", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Jiyuan", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Lei", "middle": [], "last": "Huang", "suffix": ""}, {"first": "Chao", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Shuhong", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Peng", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "Hongxia", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Li", "middle": [], "last": "Zhu", "suffix": ""}], "year": 2020, "venue": "The Lancet respiratory medicine", "volume": "8", "issn": "4", "pages": "420--422", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "World health organization declares global emergency: A review of the 2019 novel coronavirus (covid-19)", "authors": [{"first": "Catrin", "middle": [], "last": "Sohrabi", "suffix": ""}, {"first": "Zaid", "middle": [], "last": "Alsafi", "suffix": ""}, {"first": "Niamh", "middle": [], "last": "Oneill", "suffix": ""}, {"first": "Mehdi", "middle": [], "last": "Khan", "suffix": ""}, {"first": "Ahmed", "middle": [], "last": "Kerwan", "suffix": ""}, {"first": "Ahmed", "middle": [], "last": "Al-Jabir", "suffix": ""}, {"first": "Christos", "middle": [], "last": "Iosifidis", "suffix": ""}, {"first": "Riaz", "middle": [], "last": "Agha", "suffix": ""}], "year": 2020, "venue": "International Journal of Surgery", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Respiration rate monitoring methods: A review", "authors": [{"first": "Q", "middle": [], "last": "Farah", "suffix": ""}, {"first": "Reza", "middle": [], "last": "Al-Khalidi", "suffix": ""}, {"first": "Derek", "middle": [], "last": "Saatchi", "suffix": ""}, {"first": "H", "middle": [], "last": "Burke", "suffix": ""}, {"first": "Stephen", "middle": [], "last": "Elphick", "suffix": ""}, {"first": "", "middle": [], "last": "Tan", "suffix": ""}], "year": 2011, "venue": "Pediatric pulmonology", "volume": "46", "issn": "6", "pages": "523--529", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "Novel methods for noncontact heart rate measurement: A feasibility study", "authors": [{"first": "Jure", "middle": [], "last": "Kranjec", "suffix": ""}, {"first": "Samo", "middle": [], "last": "Begu\u0161", "suffix": ""}, {"first": "Janko", "middle": [], "last": "Drnov\u0161ek", "suffix": ""}, {"first": "Gregor", "middle": [], "last": "Ger\u0161ak", "suffix": ""}], "year": 2013, "venue": "IEEE transactions on instrumentation and measurement", "volume": "63", "issn": "4", "pages": "838--847", "other_ids": {}}, "BIBREF7": {"ref_id": "b7", "title": "Abnormal respiratory patterns classifier may contribute to large-scale screening of people infected with covid-19 in an accurate and unobtrusive manner", "authors": [{"first": "Yunlu", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Menghan", "middle": [], "last": "Hu", "suffix": ""}, {"first": "Qingli", "middle": [], "last": "Li", "suffix": ""}, {"first": "Xiao-Ping", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Guangtao", "middle": [], "last": "Zhai", "suffix": ""}, {"first": "Nan", "middle": [], "last": "Yao", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2002.05534"]}}, "BIBREF8": {"ref_id": "b8", "title": "Synergetic use of thermal and visible imaging techniques for contactless and unobtrusive breathing measurement", "authors": [{"first": "Meng-Han", "middle": [], "last": "Hu", "suffix": ""}, {"first": "Guang-Tao", "middle": [], "last": "Zhai", "suffix": ""}, {"first": "Duo", "middle": [], "last": "Li", "suffix": ""}, {"first": "Ye-Zhao", "middle": [], "last": "Fan", "suffix": ""}, {"first": "Xiao-Hui", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Xiao-Kang", "middle": [], "last": "Yang", "suffix": ""}], "year": 2017, "venue": "Journal of biomedical optics", "volume": "22", "issn": "3", "pages": "", "other_ids": {}}, "BIBREF9": {"ref_id": "b9", "title": "Combination of near-infrared and thermal imaging techniques for the remote and simultaneous measurements of breathing and heart rates under sleep situation", "authors": [{"first": "Menghan", "middle": [], "last": "Hu", "suffix": ""}, {"first": "Guangtao", "middle": [], "last": "Zhai", "suffix": ""}, {"first": "Duo", "middle": [], "last": "Li", "suffix": ""}, {"first": "Yezhao", "middle": [], "last": "Fan", "suffix": ""}, {"first": "Huiyu", "middle": [], "last": "Duan", "suffix": ""}, {"first": "Wenhan", "middle": [], "last": "Zhu", "suffix": ""}, {"first": "Xiaokang", "middle": [], "last": "Yang", "suffix": ""}], "year": 2018, "venue": "PloS one", "volume": "13", "issn": "1", "pages": "", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "Remote monitoring of breathing dynamics using infrared thermography", "authors": [{"first": "Carina", "middle": [], "last": "Barbosa Pereira", "suffix": ""}, {"first": "Xinchi", "middle": [], "last": "Yu", "suffix": ""}, {"first": "Michael", "middle": [], "last": "Czaplik", "suffix": ""}, {"first": "Rolf", "middle": [], "last": "Rossaint", "suffix": ""}, {"first": "Vladimir", "middle": [], "last": "Blazek", "suffix": ""}, {"first": "Steffen", "middle": [], "last": "Leonhardt", "suffix": ""}], "year": 2015, "venue": "Biomedical optics express", "volume": "6", "issn": "11", "pages": "4378--4394", "other_ids": {}}, "BIBREF11": {"ref_id": "b11", "title": "A novel method for extracting respiration rate and relative tidal volume from infrared thermography", "authors": [{"first": "F", "middle": [], "last": "Gregory", "suffix": ""}, {"first": "Rodolfo", "middle": ["G"], "last": "Lewis", "suffix": ""}, {"first": "Stephen", "middle": ["W"], "last": "Gatto", "suffix": ""}, {"first": "", "middle": [], "last": "Porges", "suffix": ""}], "year": 2011, "venue": "Psychophysiology", "volume": "48", "issn": "7", "pages": "877--887", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "RGB-thermal imaging system collaborated with marker tracking for remote breathing rate measurement", "authors": [{"first": "Lushuang", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Ning", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Menghan", "middle": [], "last": "Hu", "suffix": ""}, {"first": "Guangtao", "middle": [], "last": "Zhai", "suffix": ""}], "year": 2019, "venue": "2019 IEEE Visual Communications and Image Processing", "volume": "", "issn": "", "pages": "1--4", "other_ids": {}}, "BIBREF13": {"ref_id": "b13", "title": "Rational use of face masks in the covid-19 pandemic", "authors": [{"first": "Shuo", "middle": [], "last": "Feng", "suffix": ""}, {"first": "Chen", "middle": [], "last": "Shen", "suffix": ""}, {"first": "Nan", "middle": [], "last": "Xia", "suffix": ""}, {"first": "Wei", "middle": [], "last": "Song", "suffix": ""}, {"first": "Mengzhen", "middle": [], "last": "Fan", "suffix": ""}, {"first": "Benjamin J", "middle": [], "last": "Cowling", "suffix": ""}], "year": 2020, "venue": "The Lancet Respiratory Medicine", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF14": {"ref_id": "b14", "title": "Mass masking in the covid-19 epidemic: people need guidance", "authors": [{"first": "Chi Chiu", "middle": [], "last": "Leung", "suffix": ""}, {"first": "Tai", "middle": ["Hing"], "last": "Lam", "suffix": ""}, {"first": "Kar Keung", "middle": [], "last": "Cheng", "suffix": ""}], "year": 2020, "venue": "Lancet", "volume": "395", "issn": "10228", "pages": "", "other_ids": {}}, "BIBREF15": {"ref_id": "b15", "title": "Performance characterization of deep learning models for breathing-based authentication on resource-constrained devices", "authors": [{"first": "Jagmohan", "middle": [], "last": "Chauhan", "suffix": ""}, {"first": "Jathushan", "middle": [], "last": "Rajasegaran", "suffix": ""}, {"first": "Suranga", "middle": [], "last": "Seneviratne", "suffix": ""}, {"first": "Archan", "middle": [], "last": "Misra", "suffix": ""}, {"first": "Aruna", "middle": [], "last": "Seneviratne", "suffix": ""}, {"first": "Youngki", "middle": [], "last": "Lee", "suffix": ""}], "year": 2018, "venue": "Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies", "volume": "2", "issn": "", "pages": "1--24", "other_ids": {}}, "BIBREF16": {"ref_id": "b16", "title": "Deep learning versus professional healthcare equipment: A fine-grained breathing rate monitoring model", "authors": [{"first": "Bang", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Xili", "middle": [], "last": "Dai", "suffix": ""}, {"first": "Haigang", "middle": [], "last": "Gong", "suffix": ""}, {"first": "Zihao", "middle": [], "last": "Guo", "suffix": ""}, {"first": "Nianbo", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Xiaomin", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Ming", "middle": [], "last": "Liu", "suffix": ""}], "year": 2018, "venue": "Mobile Information Systems", "volume": "2018", "issn": "", "pages": "", "other_ids": {}}, "BIBREF17": {"ref_id": "b17", "title": "Respiration-based emotion recognition with deep learning", "authors": [{"first": "Qiang", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Xianxiang", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Qingyuan", "middle": [], "last": "Zhan", "suffix": ""}, {"first": "Ting", "middle": [], "last": "Yang", "suffix": ""}, {"first": "Shanhong", "middle": [], "last": "Xia", "suffix": ""}], "year": 2017, "venue": "Computers in Industry", "volume": "92", "issn": "", "pages": "84--90", "other_ids": {}}, "BIBREF18": {"ref_id": "b18", "title": "A deep learning framework using passive wifi sensing for respiration monitoring", "authors": [{"first": "Zain", "middle": [], "last": "Usman Mahmood Khan", "suffix": ""}, {"first": "", "middle": [], "last": "Kabir", "suffix": ""}, {"first": "Ali", "middle": [], "last": "Syed", "suffix": ""}, {"first": "Syed Hassan", "middle": [], "last": "Hassan", "suffix": ""}, {"first": "", "middle": [], "last": "Ahmed", "suffix": ""}], "year": 2017, "venue": "GLOBECOM 2017-2017 IEEE Global Communications Conference", "volume": "", "issn": "", "pages": "1--6", "other_ids": {}}, "BIBREF19": {"ref_id": "b19", "title": "Deepbreath: Deep learning of breathing patterns for automatic stress recognition using low-cost thermal imaging in unconstrained settings", "authors": [{"first": "Youngjun", "middle": [], "last": "Cho", "suffix": ""}, {"first": "Nadia", "middle": [], "last": "Bianchi-Berthouze", "suffix": ""}, {"first": "Simon", "middle": ["J"], "last": "Julier", "suffix": ""}], "year": null, "venue": "2017 Seventh International Conference on Affective Computing and Intelligent Interaction", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF21": {"ref_id": "b21", "title": "Deep learning features for robust detection of acoustic events in sleep-disordered breathing", "authors": [{"first": "H", "middle": ["E"], "last": "Romero", "suffix": ""}, {"first": "N", "middle": [], "last": "Ma", "suffix": ""}, {"first": "G", "middle": ["J"], "last": "Brown", "suffix": ""}, {"first": "A", "middle": ["V"], "last": "Beeston", "suffix": ""}, {"first": "M", "middle": [], "last": "Hasan", "suffix": ""}], "year": 2019, "venue": "ICASSP 2019 -2019 IEEE International Conference on Acoustics, Speech and Signal Processing", "volume": "", "issn": "", "pages": "810--814", "other_ids": {}}, "BIBREF22": {"ref_id": "b22", "title": "Pyramidbox: A context-assisted single shot face detector", "authors": [{"first": "Xu", "middle": [], "last": "Tang", "suffix": ""}, {"first": "K", "middle": [], "last": "Daniel", "suffix": ""}, {"first": "Zeqiang", "middle": [], "last": "Du", "suffix": ""}, {"first": "Jingtuo", "middle": [], "last": "He", "suffix": ""}, {"first": "", "middle": [], "last": "Liu", "suffix": ""}], "year": 2018, "venue": "Proceedings of the European Conference on Computer Vision (ECCV)", "volume": "", "issn": "", "pages": "797--813", "other_ids": {}}, "BIBREF23": {"ref_id": "b23", "title": "Robust tracking of respiratory rate in high-dynamic range scenes using mobile thermal imaging", "authors": [{"first": "Youngjun", "middle": [], "last": "Cho", "suffix": ""}, {"first": "J", "middle": [], "last": "Simon", "suffix": ""}, {"first": "Nicolai", "middle": [], "last": "Julier", "suffix": ""}, {"first": "Nadia", "middle": [], "last": "Marquardt", "suffix": ""}, {"first": "", "middle": [], "last": "Bianchi-Berthouze", "suffix": ""}], "year": 2017, "venue": "Biomedical optics express", "volume": "8", "issn": "10", "pages": "4480--4503", "other_ids": {}}, "BIBREF24": {"ref_id": "b24", "title": "Finding structure in time", "authors": [{"first": "", "middle": [], "last": "Jeffrey L Elman", "suffix": ""}], "year": 1990, "venue": "Cognitive science", "volume": "14", "issn": "2", "pages": "179--211", "other_ids": {}}, "BIBREF25": {"ref_id": "b25", "title": "Long short-term memory", "authors": [{"first": "Sepp", "middle": [], "last": "Hochreiter", "suffix": ""}, {"first": "J\u00fcrgen", "middle": [], "last": "Schmidhuber", "suffix": ""}], "year": 1997, "venue": "Neural computation", "volume": "9", "issn": "8", "pages": "1735--1780", "other_ids": {}}, "BIBREF26": {"ref_id": "b26", "title": "Lstm: A search space odyssey", "authors": [{"first": "Klaus", "middle": [], "last": "Greff", "suffix": ""}, {"first": "K", "middle": [], "last": "Rupesh", "suffix": ""}, {"first": "Jan", "middle": [], "last": "Srivastava", "suffix": ""}, {"first": "", "middle": [], "last": "Koutn\u00edk", "suffix": ""}, {"first": "R", "middle": [], "last": "Bas", "suffix": ""}, {"first": "J\u00fcrgen", "middle": [], "last": "Steunebrink", "suffix": ""}, {"first": "", "middle": [], "last": "Schmidhuber", "suffix": ""}], "year": 2016, "venue": "IEEE transactions on neural networks and learning systems", "volume": "28", "issn": "", "pages": "2222--2232", "other_ids": {}}, "BIBREF27": {"ref_id": "b27", "title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "authors": [{"first": "Kyunghyun", "middle": [], "last": "Cho", "suffix": ""}, {"first": "Bart", "middle": [], "last": "Van Merri\u00ebnboer", "suffix": ""}, {"first": "Caglar", "middle": [], "last": "Gulcehre", "suffix": ""}, {"first": "Dzmitry", "middle": [], "last": "Bahdanau", "suffix": ""}, {"first": "Fethi", "middle": [], "last": "Bougares", "suffix": ""}, {"first": "Holger", "middle": [], "last": "Schwenk", "suffix": ""}, {"first": "Yoshua", "middle": [], "last": "Bengio", "suffix": ""}], "year": 2014, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1406.1078"]}}, "BIBREF28": {"ref_id": "b28", "title": "Neural machine translation by jointly learning to align and translate", "authors": [{"first": "Dzmitry", "middle": [], "last": "Bahdanau", "suffix": ""}, {"first": "Kyunghyun", "middle": [], "last": "Cho", "suffix": ""}, {"first": "Yoshua", "middle": [], "last": "Bengio", "suffix": ""}], "year": 2014, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1409.0473"]}}, "BIBREF29": {"ref_id": "b29", "title": "Attention is all you need", "authors": [{"first": "Ashish", "middle": [], "last": "Vaswani", "suffix": ""}, {"first": "Noam", "middle": [], "last": "Shazeer", "suffix": ""}, {"first": "Niki", "middle": [], "last": "Parmar", "suffix": ""}, {"first": "Jakob", "middle": [], "last": "Uszkoreit", "suffix": ""}, {"first": "Llion", "middle": [], "last": "Jones", "suffix": ""}, {"first": "Aidan", "middle": ["N"], "last": "Gomez", "suffix": ""}, {"first": "\u0141ukasz", "middle": [], "last": "Kaiser", "suffix": ""}, {"first": "Illia", "middle": [], "last": "Polosukhin", "suffix": ""}], "year": 2017, "venue": "Advances in neural information processing systems", "volume": "", "issn": "", "pages": "5998--6008", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "The pipeline of respiration data extraction: a) record the RGB video and thermal video through a FLIR one thermal camera; b) use face detection method to detect face and mask region in the RGB frames and then map the region to the thermal frames; c) capture the ROIs in the thermal frames of mask region by tracking method; d) extract the respiration data from the ROIs.", "latex": null, "type": "figure"}, "FIGREF1": {"text": "The structure of the BiGRU-AT network: the network consists of four layers: the input layer, the bidirectional layer, the attention layer and a final dense layer. The output is a 2 dimension tensor which indicates normal or abnormal respiration condition.", "latex": null, "type": "figure"}, "FIGREF2": {"text": "A Comparison of normal and abnormal respiratory data: a), b) are abnormal data collected from patients in the general ward of the respiratory department in Ruijin Hospital; c), d) are normal data collected from healthy volunteers.", "latex": null, "type": "figure"}, "FIGREF3": {"text": "Confusion matrices of the four models. Each row is the number of real labels and each column is the number of predicted labels. The left one is the result of BiGRU-AT, the right one is the result of LSTM.", "latex": null, "type": "figure"}, "FIGREF4": {"text": "The raw respiratory data obtained through the breathing data extraction algorithm with different types of masks.", "latex": null, "type": "figure"}, "FIGREF5": {"text": "The raw respiratory data which is obtained under the distance between camera and device from 0 to 200 cm.", "latex": null, "type": "figure"}, "FIGREF6": {"text": "The raw respiratory data obtained while the rotation from 45 degree of angle to 0 degree of angle. The blue line stands for the vertical rotation and the red line stands for the horizontal rotation.", "latex": null, "type": "figure"}, "TABREF0": {"text": "Exprimental results on the test set", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Model </td><td>Accuracy </td><td>Precision </td><td>Recall </td><td>F1%\n</td></tr><tr><td>BiGRU-AT </td><td>83.69% </td><td>90.23% </td><td>79.65% </td><td>84.61%\n</td></tr><tr><td>GRU-AT </td><td>79.31% </td><td>90.62% </td><td>74.24% </td><td>81.62%\n</td></tr><tr><td>BiLSTM-AT </td><td>74.46% </td><td>87.50% </td><td>69.78% </td><td>77.64%\n</td></tr><tr><td>LSTM </td><td>71.98% </td><td>72.07% </td><td>71.98% </td><td>71.97%\n</td></tr></table></body></html>"}}, "back_matter": []}