{"paper_id": "0c736525592cfb1d84e632b9499eefade63a6b0d", "metadata": {"title": "Modeling the Spread of COVID-19 Infection Using a Multilayer Perceptron", "authors": [{"first": "Zlatan", "middle": [], "last": "Car", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Rijeka", "location": {"addrLine": "Vukovarska 58", "postCode": "51000", "settlement": "Rijeka", "country": "Croatia"}}, "email": ""}, {"first": "Sandi", "middle": ["Baressi"], "last": "\u0160egota", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Rijeka", "location": {"addrLine": "Vukovarska 58", "postCode": "51000", "settlement": "Rijeka", "country": "Croatia"}}, "email": ""}, {"first": "Nikola", "middle": [], "last": "An\u0111eli\u0107", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Rijeka", "location": {"addrLine": "Vukovarska 58", "postCode": "51000", "settlement": "Rijeka", "country": "Croatia"}}, "email": ""}, {"first": "Ivan", "middle": [], "last": "Lorencin", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Rijeka", "location": {"addrLine": "Vukovarska 58", "postCode": "51000", "settlement": "Rijeka", "country": "Croatia"}}, "email": ""}, {"first": "Vedran", "middle": [], "last": "Mrzljak", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Rijeka", "location": {"addrLine": "Vukovarska 58", "postCode": "51000", "settlement": "Rijeka", "country": "Croatia"}}, "email": ""}]}, "abstract": [{"text": "Coronavirus (COVID-19) is a highly infectious disease that has captured the attention of the worldwide public. Modeling of such diseases can be extremely important in the prediction of their impact. While classic, statistical, modeling can provide satisfactory models, it can also fail to comprehend the intricacies contained within the data. In this paper, authors use a publicly available dataset, containing information on infected, recovered, and deceased patients in 406 locations over 51 days (22nd January 2020 to 12th March 2020). This dataset, intended to be a time-series dataset, is transformed into a regression dataset and used in training a multilayer perceptron (MLP) artificial neural network (ANN). The aim of training is to achieve a worldwide model of the maximal number of patients across all locations in each time unit. Hyperparameters of the MLP are varied using a grid search algorithm, with a total of 5376 hyperparameter combinations. Using those combinations, a total of 48384 ANNs are trained (16128 for each patient group-deceased, recovered, and infected), and each model is evaluated using the coefficient of determination (R2). Cross-validation is performed using K-fold algorithm with 5-folds. Best models achieved consists of 4 hidden layers with 4 neurons in each of those layers, and use a ReLU activation function, with R2 scores of 0.98599 for confirmed, 0.99429 for deceased, and 0.97941 for recovered patient models. When cross-validation is performed, these scores drop to 0.94 for confirmed, 0.781 for recovered, and 0.986 for deceased patient models, showing high robustness of the deceased patient model, good robustness for confirmed, and low robustness for recovered patient model.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "Coronavirus disease, code-named COVID-19, is an infectious disease caused by a virus, a member of the Betacoronavirus family named severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), previously referred to as 2019 novel coronavirus (2019-nCoV) [1, 2] . It is thought that the virus outbreak has animal origins, and it was first transmitted to humans in Wuhan province China, in November/December 2019 [3] [4] [5] .", "cite_spans": [{"start": 254, "end": 257, "text": "[1,", "ref_id": "BIBREF0"}, {"start": 258, "end": 260, "text": "2]", "ref_id": null}, {"start": 411, "end": 414, "text": "[3]", "ref_id": "BIBREF1"}, {"start": 415, "end": 418, "text": "[4]", "ref_id": "BIBREF2"}, {"start": 419, "end": 422, "text": "[5]", "ref_id": "BIBREF3"}], "ref_spans": [], "section": "Introduction"}, {"text": "At present, no approved vaccines or specific antivirals are available for COVID-19 [6, 7] . Previous SARS pandemic in 2002 and 2003 was controlled and finally stopped by conventional control measures, including travel restrictions and patient isolation. Currently, these measures are applied in almost all countries with the COVID-19 outbreak; however, their effectiveness depends on how rigorous they are [8, 9] . It follows that the methods enabling reliable prediction of spreading of COVID-19 would be of great benefit in persuading public opinion why it is crucial to adhere to these measures in the past decade [10, 11] .", "cite_spans": [{"start": 83, "end": 86, "text": "[6,", "ref_id": "BIBREF4"}, {"start": 87, "end": 89, "text": "7]", "ref_id": "BIBREF5"}, {"start": 406, "end": 409, "text": "[8,", "ref_id": "BIBREF6"}, {"start": 410, "end": 412, "text": "9]", "ref_id": null}, {"start": 617, "end": 621, "text": "[10,", "ref_id": "BIBREF8"}, {"start": 622, "end": 625, "text": "11]", "ref_id": "BIBREF9"}], "ref_spans": [], "section": "Introduction"}, {"text": "Modeling viral diseases such as COVID-19 is extremely important in determining their possible future impact. Modeling the spread and the effect of such a disease can be supremely important in understanding its impact [12] . While traditional, statistical, modeling can offer precise models [13] , artificial intelligence (AI) techniques could be the key to finding high-quality predictive models [14] . In this paper, the authors present a machine learning solution, a multilayer perceptron (MLP) artificial neural network (ANN) [15] , to model the spread of the disease, which predicts the maximal number of people who contracted the disease per location in each time unit, maximal number of people who recovered per location in each time unit, and maximal number of deaths per location in each time unit. MLP has been selected for its simplicity in comparison to other AI algorithms, due to authors wishing to test the possibility of modeling using comparatively simple methods, due to shorter training time associated with such methods, because the quick generation of results is important when modeling diseases, due to the as-fast-as-possible requirement for models with good enough regression performance. Modeling can be done on existing data, using statistical analyses. But, when it comes to extremely complex models, statistical analysis can fail to comprehend the intricacies contained in the analyzed data [16] . More complex algorithms, namely, AI algorithms and especially machine learning algorithms can be used to \"learn\" not just the general trend, but the intricacies of the data, which results in higher quality models produced [10] . AI algorithms have become increasingly applicable in various branches of science and industry, i.e., medicine [17] for the classification of various diseases as well as creating regression models for estimation and prediction. Models obtained by machine learning techniques adjust their parameters to fit their predictions to existing data, no matter what it contains. By doing this, the models take into account interinfluences of various input parameters that might not have been taken into consideration if traditional modeling methods were used [11] . This ability to take into account hard to observe intricacies stored inside data should lend itself well, when used in an attempt of regressing a complex model such as spread of COVID-19. Currently, existing models of COVID-19 spread have relatively poor results [18] or have made predictions which were proven to not correlate to real data [19, 20] .", "cite_spans": [{"start": 217, "end": 221, "text": "[12]", "ref_id": "BIBREF10"}, {"start": 290, "end": 294, "text": "[13]", "ref_id": null}, {"start": 396, "end": 400, "text": "[14]", "ref_id": "BIBREF12"}, {"start": 529, "end": 533, "text": "[15]", "ref_id": "BIBREF13"}, {"start": 1418, "end": 1422, "text": "[16]", "ref_id": "BIBREF14"}, {"start": 1647, "end": 1651, "text": "[10]", "ref_id": "BIBREF8"}, {"start": 1764, "end": 1768, "text": "[17]", "ref_id": "BIBREF15"}, {"start": 2203, "end": 2207, "text": "[11]", "ref_id": "BIBREF9"}, {"start": 2473, "end": 2477, "text": "[18]", "ref_id": "BIBREF16"}, {"start": 2551, "end": 2555, "text": "[19,", "ref_id": "BIBREF17"}, {"start": 2556, "end": 2559, "text": "20]", "ref_id": "BIBREF18"}], "ref_spans": [], "section": "Introduction"}, {"text": "In the research presented, the aim was to achieve an accurate regression model through the utilization of an AI algorithm using the data that existed during the time in which this research was performed. This was done in order to demonstrate the possibility of using AI algorithms in early modeling of infective disease, such as COVID-19, spread. The aim of the model is to observe all the collected data together, instead of separating it into localities, as that mode of observation could allow a machine learning method to achieve a better global model of viral spread. MLP algorithm is trained using a \"Novel Coronavirus (COVID-19) Cases\" [21] , by John Hopkins CSSE. At the time of this research being per-formed, the dataset contained 20706 data points and was split into the training (75%-15530 data points) and testing (25%-5176 data points) sets. The hyperparameters of the MLP are determined using a grid search algorithm. The robustness of the different models is tested using K-fold cross-validation algorithm. Achieved results are then evaluated using the R2 metric. A detailed look upon the techniques used has been given in Materials and Methods.", "cite_spans": [{"start": 643, "end": 647, "text": "[21]", "ref_id": "BIBREF19"}], "ref_spans": [], "section": "Introduction"}, {"text": "Materials and methods used in the research are presented in this section. The process from using and transforming the available data, modeling it using MLP with a multitude of hyperparameter combinations, and the final evaluation of results is described. The overview of the modeling process is given in Figure 1 .", "cite_spans": [], "ref_spans": [{"start": 304, "end": 312, "text": "Figure 1", "ref_id": null}], "section": "Materials and Methods"}, {"text": "2.1. Dataset Description. Dataset used in this research is obtained from a publicly available repository operated by the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE) and supported by ESRI Living Atlas Team and the Johns Hopkins University Applied Physics Lab (JHU APL) [21] . It contains the data for the coronavirus patients which describe the number of patients in a certain location (defined by the name of location, latitude, and longitude), for each day since the start of the COVID-19 infections (22 nd of January 2020) until 12 th of March 2020. Dataset is split into three groups-infected, recovered, and deceased. At the time of this research being performed, the dataset contained the data for 406 locations and 51 days. The geographical distribution of data contained in the dataset is given in Figure 2 , which shows the geographical distribution of infected patients at various points in time.", "cite_spans": [{"start": 303, "end": 307, "text": "[21]", "ref_id": "BIBREF19"}], "ref_spans": [{"start": 840, "end": 848, "text": "Figure 2", "ref_id": "FIGREF0"}], "section": "Materials and Methods"}, {"text": "Dataset, as published, is organized as time-series data-showing the spread of disease in various locations over time. The data collected at the time of this research being performed was insufficient to attempt a time-series AI modeling. To train the MLP, the dataset is rearranged to create a set of inputs and outputs. For each number of cases, the latitude Hyperparameter search Figure 1 : The process of AI modeling is shown. First, the data is collected and placed into a dataset. Part of that data is used for training and testing the various MLP hyperparameter combinations, in an attempt to find the best possible architecture. The most successful model can then be used to determine the future instances.", "cite_spans": [], "ref_spans": [{"start": 381, "end": 389, "text": "Figure 1", "ref_id": null}], "section": "Materials and Methods"}, {"text": "2 Computational and Mathematical Methods in Medicine and longitude of the location, as well as the date of data collection is added. The date is converted into the number of days since the first entry into the dataset. In this way, each data point contains information about the number of patients (contracted, recovered, or dead) at a given location, at a given day since the first noted case. Latitude, longitude, and the number of days since the first case are used as input data, with the output data being the number of patients in each group. In this manner, the time-series dataset is rearranged in a manner that makes it appropriate to train a regressive MLP.", "cite_spans": [], "ref_spans": [], "section": "Materials and Methods"}, {"text": "Finally, the dataset, consisting of a total of 20706 data points, is randomly split into five equal parts, or so-called folds. Each of these parts is used as a testing set, with the remaining parts used as a training set. This means that training for each architecture is repeated 5 times, with an 80%/20% (16565 randomly selected data points for training and 4141 data points for testing set) training-testing distribution.", "cite_spans": [], "ref_spans": [], "section": "Materials and Methods"}, {"text": "Multilayer perceptron (MLP) is a type of a fully connected, feed-forward artificial neural 3 Computational and Mathematical Methods in Medicine network (ANN), consisting of neurons arranged in layers [11] . At least three layers make up MLP: an input layer, an output layer, and one or more hidden layers. The output layer consists of a single neuron, the value of which is the output of the MLP ANN-in the presented research this is the predicted number of patients. The input layer consists of the neurons in the same number as the dataset inputs [22] . MLPs used in this research will as such have 3 neurons in the input layer-one for each of the input data points (latitude, longitude, days since infection).", "cite_spans": [{"start": 200, "end": 204, "text": "[11]", "ref_id": "BIBREF9"}, {"start": 549, "end": 553, "text": "[22]", "ref_id": "BIBREF20"}], "ref_spans": [], "section": "Multilayer Perceptron."}, {"text": "The reason for selecting MLP as the method used in this research was the ease of implementation of such methods. MLP is also known to provide high-quality models, while keeping the training time relatively low compared to more complex methods.", "cite_spans": [], "ref_spans": [], "section": "Multilayer Perceptron."}, {"text": "MLP is based on calculating the values of neurons in a current layer as the activated summation of weighted outputs of neurons in a previous layer, connected to the neuron [22, 23] . Activation refers to the sums of weighted inputs being used as inputs to the so-called activation function, which maps the input to the output either directly (identity activation), within certain limits (sigmoid, or tanh), or maps it while removing unwanted values (e.g., ReLU which removes negative values, and maps positive ones directly) [24] . The weights of the neuron connections are initially random, but then adjusted through the backward propagation process, in which the error for a forward propagated of the MLP results gets back-propagated through, and weights are adjusted proportionally to the error [25] .", "cite_spans": [{"start": 172, "end": 176, "text": "[22,", "ref_id": "BIBREF20"}, {"start": 177, "end": 180, "text": "23]", "ref_id": "BIBREF21"}, {"start": 525, "end": 529, "text": "[24]", "ref_id": "BIBREF22"}, {"start": 798, "end": 802, "text": "[25]", "ref_id": "BIBREF23"}], "ref_spans": [], "section": "Multilayer Perceptron."}, {"text": "Due to the fact that MLP regressor can only regress a single value, if the problem consists of multiple output values, a modular model consisting of multiple models must be used. While similarities are possible between models; training the models completely separately means that all the architectures will be tested, giving a higher chance to finding a better prediction model for each goal. In the research presented, three separate MLPs are trained-one for each of the goals-infected, recovered, and deceased patients.", "cite_spans": [], "ref_spans": [], "section": "Multilayer Perceptron."}, {"text": "To confirm the validity of the results, the cross-validation process has been performed. The cross-validation method used in this research is the K-Fold algorithm [22, 26] . During this process, the dataset is split into k subsets (in presented case k = 5). Then, each of them is used as a testing set, while the remaining k \u2212 1 subsets are used as a training dataset [27] . The result is then presented as the average of achieved scores, with standard deviation noted.", "cite_spans": [{"start": 163, "end": 167, "text": "[22,", "ref_id": "BIBREF20"}, {"start": 168, "end": 171, "text": "26]", "ref_id": "BIBREF24"}, {"start": 368, "end": 372, "text": "[27]", "ref_id": "BIBREF25"}], "ref_spans": [], "section": "Multilayer Perceptron."}, {"text": "The solution has been implemented using Python 3.8 programming language, using scikit-learn library [28] . Scikit-learn has been selected due to ease of use, as well as the fact that it contains the implementation of most of the methods used in this research [29] . ActiveState ActivePython implementation of Python and needed libraries has been used [30] . Training has been performed using a highperformance computer (HPC)-Bura Supercomputer. To train the models 16 HPC nodes, each containing 48 logical CPUs (24 physical cores on Intel Xeon E5), with 64 GB of RAM per each node [31] -resulting in total of 768 logical CPUs used. The operating system used is Red Hat Enterprise Linux, with kernel version 3.10.0-957.", "cite_spans": [{"start": 100, "end": 104, "text": "[28]", "ref_id": "BIBREF26"}, {"start": 259, "end": 263, "text": "[29]", "ref_id": "BIBREF27"}, {"start": 351, "end": 355, "text": "[30]", "ref_id": null}, {"start": 581, "end": 585, "text": "[31]", "ref_id": "BIBREF28"}], "ref_spans": [], "section": "Multilayer Perceptron."}, {"text": "Hyperparameters are values which define the architecture of the ANN model. Correct values of hyperparameters are crucial in achieving a quality model. To determine the best hyperparameter combination, the grid search algorithm has been used.", "cite_spans": [], "ref_spans": [], "section": "Hyperparameter Determination."}, {"text": "The grid search algorithm takes a set of possible parameters for each of the adjusted hyperparameters. Then, each possible combination of hyperparameters is determined [32] . Each of the combinations is used to train the MLP. To avoid the possibility of poor solutions due to the initial random setting of the weights, each set of hyperparameters is used for training three times. Each of the achieved models is then evaluated. The hyperparameters adjusted in performed research are [28, 29] :", "cite_spans": [{"start": 168, "end": 172, "text": "[32]", "ref_id": "BIBREF29"}, {"start": 483, "end": 487, "text": "[28,", "ref_id": "BIBREF26"}, {"start": 488, "end": 491, "text": "29]", "ref_id": "BIBREF27"}], "ref_spans": [], "section": "Hyperparameter Determination."}, {"text": "(i) solver-the algorithm used for recalculating the weights of the MLP during back propagation process in training (ii) initial learning rate \u03b1-value of learning rate at the beginning of training (iii) adjustment of learning rate-the way the learning rate will change during the training, and if it will be adjusted depending on the current value of cost function or not (iv) number of hidden layers and neurons-defined as tuple, in which each integer defines a single hidden layer and the integer value defines the number of neurons in that layer", "cite_spans": [], "ref_spans": [], "section": "Hyperparameter Determination."}, {"text": "(v) activation function-function used to transform the input values of the neuron to the output value of the neuron, and (vi) regularization parameter L2-parameter which limits the influence of input parameters, to avoid the ANN being trained with a bias towards a single input value which has a high correlation to the output; larger the parameter, more is the influence lowered", "cite_spans": [], "ref_spans": [], "section": "Hyperparameter Determination."}, {"text": "Possible hyperparameter values are given in Table 1 .", "cite_spans": [], "ref_spans": [{"start": 44, "end": 51, "text": "Table 1", "ref_id": "TABREF1"}], "section": "Hyperparameter Determination."}, {"text": "Estimation. Every obtained model is evaluated using the coefficient of determination (R2). The coefficient of determination defines how well is the variance which exists in the real data explained with the predicted data. The real output data, the actual number of patients, is contained in the vector y, while the predicted data, obtained from the trained model, is set into the vector\u02c6y. With that, the coefficient of determination R2 can be determined as the coefficient between the residual variance and total variance [33] :", "cite_spans": [{"start": 523, "end": 527, "text": "[33]", "ref_id": "BIBREF30"}], "ref_spans": [], "section": "Model Quality"}, {"text": "with m being the number of evaluated samples (length of vectors y and\u02c6y). R2 is defined in the range R2\u2208 [0,1], with 4 Computational and Mathematical Methods in Medicine the value of 0.0 meaning that none of the variances in real data is explained in the predicted data, and the value of 1.0 being the best possible value, meaning all of the variances is explained in the predicted data. Due to cross-validation being used, each architecture is trained 5 times-on differing data. To present the results of cross-validation, the average of R2 scores is calculated", "cite_spans": [], "ref_spans": [], "section": "Model Quality"}, {"text": "To show the variance between the scores on different folds, the standard deviation of the R2 scores is also presented \u00f0\u03c3 = ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi \u2211 5 t=1 \u00f0R 2 t \u2212 R 2 \u00de/5 q \u00de.", "cite_spans": [], "ref_spans": [], "section": "Model Quality"}, {"text": "In this section, the detailed descriptions of the achieved results are presented. These results were achieved using the methodology described in the previous section. After the presentation of the results, the results are discussed.", "cite_spans": [], "ref_spans": [], "section": "Results and Discussion"}, {"text": "Best models achieved show a high-quality regression, with R2 scores of 0.98599 for the confirmed patient model, 0.97941 for the recovered patient model, and 0.99429 for the deceased patient model. The best models achieved for all three goals (number of infections, recoveries, and deaths) have a same basic ANN architecture. These architectures consist of four hidden layers, and 16 total hidden neurons distributed equally among layers-4 neurons each.", "cite_spans": [], "ref_spans": [], "section": "Results."}, {"text": "Best models for all three outputs also use the ReLU activation function and the LBFGS solver. The best model for confirmed cases has a constant learning rate of 0.1 and has a regularization parameter of 0.0001. For the recovered cases, MLP uses a constant learning rate of 0.5 and a regularization parameter of 0.001. The model for predicting the number of deceased patients uses the adaptive learning rate of 0.01, with the regularization parameter set at 0.1. The hyperparameters of the best models are listed in Table 2 . Figure 3 shows the comparison of real data to data obtained from the model. Real data, sorted by days, as well as trends for all three modeled cases, are shown in subfigures. Subfigures (a), (c), and (e) demonstrate the comparison of real data, sorted by date for various locations and the data predicted by model. Each bar presents a number of patients in a given group, per location. For easier viewing, the maximum of each daily count is plotted as the envelope of the plotted data in (b), (d), and (f). These envelopes show an approximation of maximal disease spread per patient group, for both real data and modeled data, which shows that the modeled data follows the collected data closely. Table 3 shows the cross-validation results achieved for the best models shown in Table 2 .", "cite_spans": [], "ref_spans": [{"start": 515, "end": 522, "text": "Table 2", "ref_id": "TABREF2"}, {"start": 525, "end": 533, "text": "Figure 3", "ref_id": "FIGREF3"}, {"start": 1222, "end": 1229, "text": "Table 3", "ref_id": "TABREF3"}, {"start": 1303, "end": 1310, "text": "Table 2", "ref_id": "TABREF2"}], "section": "Results."}, {"text": "Training time, using 5-fold cross-validation, on the system used and described in the \"Materials and Methods\" section is shown in Table 4 . Taking into account 5376 training items, and training repeated 5 times due to cross-validation, for a total of 26880 models trained, this means that the average model training time is 0.088 minutes or 5.26 seconds.", "cite_spans": [], "ref_spans": [{"start": 130, "end": 137, "text": "Table 4", "ref_id": "TABREF4"}], "section": "Results."}, {"text": "3.2. Discussion. Results show that a similar architecture can be used for all three models, suggesting a similar trend Hidden layer sizes", "cite_spans": [], "ref_spans": [], "section": "Results."}, {"text": "(3), (6), (4, 4) , (3, 3, 3) , (6, 6, 6), (4, 3, 4), (12, 12, 12) , (4, 4, 3, 3) , (4, 4, 4, 4) , (6, 6, 6, 6) , (10, 5, 5, 10) , (3 Computational and Mathematical Methods in Medicine models, both the models for infected and recovered use a relatively high constant learning rate, while the deceased model uses a significantly lower learning rate but adapts over iterations. The regularization parameter is relatively low for the model of infections but raises for the recovered and deceased models-pointing to the fact that there is a higher influence of certain input parameters on the output of those models which needed to be suppressed. Models show poor tracking of sudden and unexpected changes, such as the sudden jump in infections around day 22. Still, the model demonstrates good tracking of overall model change, giving good predictions even after such unexpected leaps-if given time to adjust. Due to the largest number of cases being located in China, the model is largely fitted to that data. Future changes in the maximum number of infected, deceased, or recovered patients should be included in the model to further test its robustness.", "cite_spans": [{"start": 10, "end": 13, "text": "(4,", "ref_id": "BIBREF2"}, {"start": 14, "end": 16, "text": "4)", "ref_id": "BIBREF2"}, {"start": 19, "end": 22, "text": "(3,", "ref_id": "BIBREF1"}, {"start": 23, "end": 25, "text": "3,", "ref_id": "BIBREF1"}, {"start": 26, "end": 28, "text": "3)", "ref_id": "BIBREF1"}, {"start": 53, "end": 57, "text": "(12,", "ref_id": "BIBREF10"}, {"start": 58, "end": 61, "text": "12,", "ref_id": "BIBREF10"}, {"start": 62, "end": 65, "text": "12)", "ref_id": "BIBREF10"}, {"start": 68, "end": 71, "text": "(4,", "ref_id": "BIBREF2"}, {"start": 72, "end": 74, "text": "4,", "ref_id": "BIBREF2"}, {"start": 75, "end": 77, "text": "3,", "ref_id": "BIBREF1"}, {"start": 78, "end": 80, "text": "3)", "ref_id": "BIBREF1"}, {"start": 83, "end": 86, "text": "(4,", "ref_id": "BIBREF2"}, {"start": 87, "end": 89, "text": "4,", "ref_id": "BIBREF2"}, {"start": 90, "end": 92, "text": "4,", "ref_id": "BIBREF2"}, {"start": 93, "end": 95, "text": "4)", "ref_id": "BIBREF2"}, {"start": 98, "end": 101, "text": "(6,", "ref_id": "BIBREF4"}, {"start": 102, "end": 104, "text": "6,", "ref_id": "BIBREF4"}, {"start": 105, "end": 107, "text": "6,", "ref_id": "BIBREF4"}, {"start": 108, "end": 110, "text": "6)", "ref_id": "BIBREF4"}, {"start": 113, "end": 117, "text": "(10,", "ref_id": "BIBREF8"}, {"start": 118, "end": 120, "text": "5,", "ref_id": "BIBREF3"}, {"start": 121, "end": 123, "text": "5,", "ref_id": "BIBREF3"}, {"start": 124, "end": 127, "text": "10)", "ref_id": "BIBREF8"}, {"start": 130, "end": 132, "text": "(3", "ref_id": "BIBREF1"}], "ref_spans": [], "section": "Results."}, {"text": "Cross-validation performed shown across the solution space shows a drop in R2 scores. The model for deceased patients shows the lowest drop in scoring used. The model of confirmed cases shows a more significant drop from 0.986 to 0.94, but these results are still acceptable. The highest drop is shown in the model of recovered patients where R2 score drops from 0.97941 to 0.781, showing the low robustness of the model for recovered patients. The architectures of the models that show the best results remain the same when cross-validation is applied.", "cite_spans": [], "ref_spans": [], "section": "Results."}, {"text": "The aim of this research, which was to generate a model of coronavirus disease spread on a global level using machine learning methods, was achieved. The created models show a high fidelity to existing data, with the exception of the model for recovered patients. In comparison to already designed models, presented models show a higher accuracy, as well as tracking of deaths and recoveries. Additionally, the presented model is created using a simpler AI algorithm and uses a comparatively simple architecture, which has performance benefits in terms of computational time and resources [22] . Results demonstrate a clear ability to mathematically model a spread of an infective disease using AI on a relatively limited dataset, meaning that comparatively long periods of data collection are not strictly necessary to achieve a good model with AI algorithms. Obtained results point towards the ability to use such algorithms to model similar phenomena in the future.", "cite_spans": [{"start": 589, "end": 593, "text": "[22]", "ref_id": "BIBREF20"}], "ref_spans": [], "section": "Results."}, {"text": "The achieved models show that it is possible to acquire a quality model of novel viral infections using AI methods, with geographical and time data as inputs. In this research, high accuracy models have been achieved for all regression goals. Achieved results prove the fact that AI models can be used in modeling problems such as the spread and effect of infectious diseases. This means that the application of AI methods should be attempted in modeling the present and future spread of infective diseases, in an attempt to predict the impact of such infections on humankind. Model fitting to largely the Chinese patient population shows that using the number of patients per country is not necessarily a good metric to use as a training goal-further research should be invested in testing how different types of metrics (e.g., percentage of disease in population) affect model quality. The code and models achieved can be found at a public repository, made available by the authors [34] . Authors are also planning on the implementation of achieved models inside an easy to use and widely accessible web-interface.", "cite_spans": [{"start": 984, "end": 988, "text": "[34]", "ref_id": null}], "ref_spans": [], "section": "Conclusion"}, {"text": "Future work should apply other methods in an attempt to find even better models or models that are simpler to use, or more transparent than ones observed with MLP. Comparison of models for different infective diseases would be interesting. More data being acquired should enable the use of other techniques such as recurrent neural networks to be applied on the analyses of infection models using timeseries data.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "This research uses a publicly available dataset \"2019 Novel Coronavirus Data Repository\" published by Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE) available at: https://github.com/CSSEGISandData/ COVID-19. Models achieved, and the code used in their generation are available in a repository, located at: https://github .com/RitehAIandRobot/COVID-19-MLP [34] .", "cite_spans": [{"start": 387, "end": 391, "text": "[34]", "ref_id": null}], "ref_spans": [], "section": "Data Availability"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "The reproductive number of COVID-19 is higher compared to SARS coronavirus", "authors": [{"first": "Y", "middle": [], "last": "Liu", "suffix": ""}, {"first": "A", "middle": ["A"], "last": "Gayle", "suffix": ""}, {"first": "A", "middle": [], "last": "Wilder-Smith", "suffix": ""}, {"first": "J", "middle": [], "last": "Rockl\u00f6v", "suffix": ""}], "year": 2020, "venue": "2020. 9 Computational and Mathematical Methods in Medicine [2] Center for Disease Control and Prevention", "volume": "27", "issn": "", "pages": "", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "Coronavirus Disease (COVID-19). Our World in Data", "authors": [{"first": "M", "middle": [], "last": "Roser", "suffix": ""}, {"first": "H", "middle": [], "last": "Ritchie", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Novel Coronavirus (2019-nCoV) outbreak; a systematic review for published papers", "authors": [{"first": "A", "middle": [], "last": "Al-Gheethi", "suffix": ""}, {"first": "E", "middle": [], "last": "Noman", "suffix": ""}, {"first": "Q", "middle": ["A"], "last": "Al-Maqtari", "suffix": ""}], "year": 2020, "venue": "SSRN Electronic Journal", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "A pneumonia outbreak associated with a new coronavirus of probable bat origin", "authors": [{"first": "P", "middle": [], "last": "Zhou", "suffix": ""}, {"first": "X", "middle": ["L"], "last": "Yang", "suffix": ""}, {"first": "X", "middle": ["G"], "last": "Wang", "suffix": ""}], "year": 2020, "venue": "Nature", "volume": "579", "issn": "7798", "pages": "270--273", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "The COVID-19 epidemic", "authors": [{"first": "T", "middle": ["P"], "last": "Velavan", "suffix": ""}, {"first": "C", "middle": ["G"], "last": "Meyer", "suffix": ""}], "year": 2020, "venue": "Tropical Medicine & International Health", "volume": "25", "issn": "3", "pages": "278--280", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Functional assessment of cell entry and receptor usage for SARS-CoV-2 and other lineage B betacoronaviruses", "authors": [{"first": "M", "middle": [], "last": "Letko", "suffix": ""}, {"first": "A", "middle": [], "last": "Marzi", "suffix": ""}, {"first": "V", "middle": [], "last": "Munster", "suffix": ""}], "year": 2020, "venue": "Nature Microbiology", "volume": "5", "issn": "4", "pages": "562--569", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "World Health Organization, Coronavirus disease 2019 (covid-19) Situation Report-29, World Health Organization", "authors": [], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Report of the WHO-China Joint Mission on Coronavirus Disease 2019 (COVID-19), World Health Organization", "authors": [], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF9": {"ref_id": "b9", "title": "The continuing 2019-nCoV epidemic threat of novel coronaviruses to global health -The latest 2019 novel coronavirus outbreak in Wuhan, China", "authors": [{"first": "D", "middle": ["S"], "last": "Hui", "suffix": ""}, {"first": "E", "middle": [], "last": "Azhar", "suffix": ""}, {"first": "T", "middle": ["A"], "last": "Madani", "suffix": ""}], "year": 2020, "venue": "International Journal of Infectious Diseases", "volume": "91", "issn": "", "pages": "264--266", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "An Introduction to Infectious Disease Modelling", "authors": [{"first": "E", "middle": [], "last": "Vynnycky", "suffix": ""}, {"first": "R", "middle": [], "last": "White", "suffix": ""}], "year": 2010, "venue": "OUP oxford", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "Artificial intelligence for infectious disease big data analytics", "authors": [{"first": "Z", "middle": ["S"], "last": "Wong", "suffix": ""}, {"first": "J", "middle": [], "last": "Zhou", "suffix": ""}, {"first": "Q", "middle": [], "last": "Zhang", "suffix": ""}], "year": 2019, "venue": "Infection, Disease & Health", "volume": "24", "issn": "1", "pages": "44--48", "other_ids": {}}, "BIBREF13": {"ref_id": "b13", "title": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction", "authors": [{"first": "T", "middle": [], "last": "Hastie", "suffix": ""}, {"first": "R", "middle": [], "last": "Tibshirani", "suffix": ""}, {"first": "J", "middle": [], "last": "Friedman", "suffix": ""}], "year": 2009, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF14": {"ref_id": "b14", "title": "Which method predicts recidivism best?: a comparison of statistical, machine learning and data mining predictive models", "authors": [{"first": "N", "middle": [], "last": "Tollenaar", "suffix": ""}, {"first": "P", "middle": ["G M"], "last": "Van Der Heijden", "suffix": ""}], "year": 2013, "venue": "Journal of the Royal Statistical Society: Series A (Statistics in Society", "volume": "176", "issn": "2", "pages": "565--584", "other_ids": {}}, "BIBREF15": {"ref_id": "b15", "title": "Using multilayer perceptron with Laplacian edge detector for bladder cancer diagnosis", "authors": [{"first": "I", "middle": [], "last": "Lorencin", "suffix": ""}, {"first": "N", "middle": [], "last": "An\u0111eli\u0107", "suffix": ""}, {"first": "J", "middle": [], "last": "\u0160panjol", "suffix": ""}, {"first": "Z", "middle": [], "last": "Car", "suffix": ""}], "year": 2020, "venue": "Artificial Intelligence in Medicine", "volume": "102", "issn": "", "pages": "", "other_ids": {}}, "BIBREF16": {"ref_id": "b16", "title": "Artificial intelligence forecasting of covid-19 in China", "authors": [{"first": "Z", "middle": [], "last": "Hu", "suffix": ""}, {"first": "Q", "middle": [], "last": "Ge", "suffix": ""}, {"first": "L", "middle": [], "last": "Jin", "suffix": ""}, {"first": "M", "middle": [], "last": "Xiong", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF17": {"ref_id": "b17", "title": "Predictions of 2019-ncov transmission ending via comprehensive methods", "authors": [{"first": "T", "middle": [], "last": "Zeng", "suffix": ""}, {"first": "Y", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Z", "middle": [], "last": "Li", "suffix": ""}, {"first": "X", "middle": [], "last": "Liu", "suffix": ""}, {"first": "B", "middle": [], "last": "Qiu", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF18": {"ref_id": "b18", "title": "Finding an accurate early forecasting model from small dataset: a case of 2019-nCoV novel coronavirus outbreak", "authors": [{"first": "S", "middle": ["J"], "last": "Fong", "suffix": ""}, {"first": "G", "middle": [], "last": "Li", "suffix": ""}, {"first": "N", "middle": [], "last": "Dey", "suffix": ""}, {"first": "R", "middle": ["G"], "last": "Crespo", "suffix": ""}, {"first": "E", "middle": [], "last": "Herrera-Viedma", "suffix": ""}], "year": 2020, "venue": "International Journal of Interactive Multimedia and Artificial Intelligence", "volume": "6", "issn": "1", "pages": "132--140", "other_ids": {}}, "BIBREF19": {"ref_id": "b19", "title": "Novel Coronavirus (COVID-19) Cases", "authors": [{"first": "Johns", "middle": [], "last": "Hopkins", "suffix": ""}, {"first": "Csse", "middle": [], "last": "", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF20": {"ref_id": "b20", "title": "Deep Learning", "authors": [{"first": "I", "middle": [], "last": "Goodfellow", "suffix": ""}, {"first": "Y", "middle": [], "last": "Bengio", "suffix": ""}, {"first": "A", "middle": [], "last": "Courville", "suffix": ""}], "year": 2016, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF21": {"ref_id": "b21", "title": "Pattern Recognition and Machine Learning", "authors": [{"first": "C", "middle": ["M"], "last": "Bishop", "suffix": ""}], "year": 2006, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF22": {"ref_id": "b22", "title": "Searching for activation functions", "authors": [{"first": "P", "middle": [], "last": "Ramachandran", "suffix": ""}, {"first": "B", "middle": [], "last": "Zoph", "suffix": ""}, {"first": "Q", "middle": ["V"], "last": "Le", "suffix": ""}], "year": 2017, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF23": {"ref_id": "b23", "title": "Pattern recognition and feed-forward networks", "authors": [{"first": "C", "middle": ["M"], "last": "Bishop", "suffix": ""}], "year": 1999, "venue": "The MIT encyclopedia of the cognitive sciences", "volume": "13", "issn": "", "pages": "", "other_ids": {}}, "BIBREF24": {"ref_id": "b24", "title": "Genetic algorithm approach to Design of Multi-Layer Perceptron for combined cycle power plant electrical power output estimation", "authors": [{"first": "I", "middle": [], "last": "Lorencin", "suffix": ""}, {"first": "N", "middle": [], "last": "An\u0111eli\u0107", "suffix": ""}, {"first": "V", "middle": [], "last": "Mrzljak", "suffix": ""}, {"first": "Z", "middle": [], "last": "Car", "suffix": ""}], "year": 2019, "venue": "Energies", "volume": "12", "issn": "22", "pages": "", "other_ids": {}}, "BIBREF25": {"ref_id": "b25", "title": "Estimation of prediction error by using K-fold cross-validation", "authors": [{"first": "T", "middle": [], "last": "Fushiki", "suffix": ""}], "year": 2011, "venue": "Statistics and Computing", "volume": "21", "issn": "2", "pages": "137--146", "other_ids": {}}, "BIBREF26": {"ref_id": "b26", "title": "Scikit-learn: machine learning in Python", "authors": [{"first": "F", "middle": [], "last": "Pedregosa", "suffix": ""}, {"first": "G", "middle": [], "last": "Varoquaux", "suffix": ""}, {"first": "A", "middle": [], "last": "Gramfort", "suffix": ""}], "year": 2011, "venue": "Journal of Machine Learning Research", "volume": "12", "issn": "", "pages": "2825--2830", "other_ids": {}}, "BIBREF27": {"ref_id": "b27", "title": "API design for machine learning software: experiences from the scikit-learn project", "authors": [{"first": "L", "middle": [], "last": "Buitinck", "suffix": ""}, {"first": "G", "middle": [], "last": "Louppe", "suffix": ""}, {"first": "M", "middle": [], "last": "Blondel", "suffix": ""}], "year": 2013, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF28": {"ref_id": "b28", "title": "Computing resources", "authors": [], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF29": {"ref_id": "b29", "title": "Random search for hyperparameter optimization", "authors": [{"first": "J", "middle": [], "last": "Bergstra", "suffix": ""}, {"first": "Y", "middle": [], "last": "Bengio", "suffix": ""}], "year": 2012, "venue": "Journal of Machine Learning Research", "volume": "13", "issn": "", "pages": "281--305", "other_ids": {}}, "BIBREF30": {"ref_id": "b30", "title": "A note on a general definition of the coefficient of determination", "authors": [{"first": "N", "middle": ["J D"], "last": "Nagelkerke", "suffix": ""}], "year": 1991, "venue": "Biometrika", "volume": "78", "issn": "3", "pages": "691--692", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "Overview of geographical distributions for number of patients infected with COVID-19 at 15 th of February 2020 (a), 1st of March 2020 (b), and 12 th of March 2020 (c).", "latex": null, "type": "figure"}, "FIGREF2": {"text": "of infected patients in comparison to real data (b) Infection trend comparison", "latex": null, "type": "figure"}, "FIGREF3": {"text": "Continuedof deceased patients in comparison to real data (d) Death trend comparison", "latex": null, "type": "figure"}, "FIGREF4": {"text": "Continuedthree goals. The use of the ReLU activation function is not unexpected, as it eliminates the negative values, it is logical it is going to lend itself well to a model which predicts only positive values. Learning rates differ recovered patients comparison to real data (f) Recovery rate data comparison", "latex": null, "type": "figure"}, "FIGREF5": {"text": "Comparison of real and modeled data. Comparison of the number of cases for each input into the dataset are shown for infected (a), deceased (c), and recovered (e) patients, while the trend of the data and model through the days analyzed are shown for the infected (b), deceased (d), and recovered (f) patients.", "latex": null, "type": "figure"}, "TABREF1": {"text": "Hyperparameters used in training. First column lists the hyperparameter name, while the possible values of the hyperparameter are listed in the second column. The last column presents the number of hyperparameters, with the last row showing the total number of hyperparameter combinations, obtained and used during the grid search algorithm execution.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Hyperparameter </td><td>Possible values </td><td>Count\n</td></tr><tr><td>Solver </td><td>Adam, LBFGS </td><td>2\n</td></tr><tr><td>Initial learning rate </td><td>0.00001, 0.01, 0.1, 0.5 </td><td>4\n</td></tr><tr><td>Learning rate adjustment </td><td>Constant, adaptive, invscaling </td><td>3\n</td></tr><tr><td>Hidden layer sizes\n</td><td>(3), (6), (4, 4), (3, 3, 3), (6, 6, 6), (4, 3, 4), (12, 12, 12), (4, 4, 3, 3), (4, 4, 4, 4), (6, 6, 6, 6), (10, 5, 5, 10), (3, 3, 3, 3, 3), (10, 10, 10, 10, 10), (12, 12, 6, 6, 3, 3)\n</td><td>14\n</td></tr><tr><td>Activation functions </td><td>ReLU, identity, logistic, tanh </td><td>4\n</td></tr><tr><td>Regularization parameter </td><td>0.00001, 0.001, 0.01, 0.1 </td><td>4\n</td></tr><tr><td>Total number of hyperparameter combinations </td><td>5376\n</td></tr></table></body></html>"}, "TABREF2": {"text": "", "latex": null, "type": "table"}, "TABREF3": {"text": "", "latex": null, "type": "table"}, "TABREF4": {"text": "", "latex": null, "type": "table"}}, "back_matter": [{"text": "The authors declare that they have no conflicts of interest-financial or otherwise.", "cite_spans": [], "ref_spans": [], "section": "Conflicts of Interest"}, {"text": "This research has been (partly) supported by the CEEPUS network CIII-HR-0108, ", "cite_spans": [], "ref_spans": [], "section": "Acknowledgments"}, {"text": "Z.C. defined the hypothesis and initial idea with assistance from S.B.S., I.L., and N.A., and investigated potential AI methods which can be applied to the dataset. S.B.S., developed the dataset transformation from time series to a regression dataset, with assistance from N.A. and I.L., developed the grid search applied on the MLP modeling with assistance from N.A. N.A. searched for the relevant scientific papers. S.B.S. and V.M. defined how the models will be evaluated. N.A., S.B.S., I.L., and V.M. mutually wrote and structured the manuscript. I.L. designed the figures presented in the manuscript.", "cite_spans": [], "ref_spans": [], "section": "Authors' Contributions"}]}