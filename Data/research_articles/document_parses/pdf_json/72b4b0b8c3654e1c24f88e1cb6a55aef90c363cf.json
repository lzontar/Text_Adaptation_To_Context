{"paper_id": "72b4b0b8c3654e1c24f88e1cb6a55aef90c363cf", "metadata": {"title": "Improving Multi-turn Response Selection Models with Complementary Last-Utterance Selection by Instance Weighting", "authors": [{"first": "Kun", "middle": [], "last": "Zhou", "suffix": "", "affiliation": {"laboratory": "", "institution": "Peking University", "location": {"settlement": "Beijing", "country": "China"}}, "email": ""}, {"first": "Wayne", "middle": ["Xin"], "last": "Zhao", "suffix": "", "affiliation": {"laboratory": "", "institution": "Renmin University of China", "location": {"settlement": "Beijing", "country": "China"}}, "email": ""}, {"first": "Yutao", "middle": [], "last": "Zhu", "suffix": "", "affiliation": {"laboratory": "", "institution": "Universit\u00e9 de Montr\u00e9al", "location": {"settlement": "Montr\u00e9al", "region": "Qu\u00e9bec", "country": "Canada"}}, "email": "yutao.zhu@umontreal.ca"}, {"first": "Ji-Rong", "middle": [], "last": "Wen", "suffix": "", "affiliation": {"laboratory": "", "institution": "Renmin University of China", "location": {"settlement": "Beijing", "country": "China"}}, "email": "jrwen@ruc.edu.cn"}, {"first": "Jingsong", "middle": [], "last": "Yu", "suffix": "", "affiliation": {"laboratory": "", "institution": "Peking University", "location": {"settlement": "Beijing", "country": "China"}}, "email": ""}]}, "abstract": [{"text": "Open-domain retrieval-based dialogue systems require a considerable amount of training data to learn their parameters. However, in practice, the negative samples of training data are usually selected from an unannotated conversation data set at random. The generated training data is likely to contain noise and affect the performance of the response selection models. To address this difficulty, we consider utilizing the underlying correlation in the data resource itself to derive different kinds of supervision signals and reduce the influence of noisy data. More specially, we consider a main-complementary task pair. The main task (i.e., our focus) selects the correct response given the last utterance and context, and the complementary task selects the last utterance given the response and context. The key point is that the output of the complementary task is used to set instance weights for the main task. We conduct extensive experiments in two public datasets and obtain significant improvement in both datasets. We also investigate the variant of our approach in multiple aspects, and the results have verified the effectiveness of our approach.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "Recent years have witnessed remarkable progress in retrieval-based open-domain conversation systems [3, 6] . In the past few years, various methods have been proposed for response selection [1, 3, 16, 22] . A key problem in response selection is how to measure the matching degree between a conversation context and a response candidate. Many efforts have been made to construct an effective matching model with neural architectures [16, 22] . To construct the training data, a widely adopted approach is pairing a positive response with several randomly selected utterances as negative responses, since the labeling of true negative responses is very time-consuming. Although such method does not require labeled negative data, it is likely to bring noise during the random sampling process for negative responses. In real-world datasets, a randomly selected response is likely to be \"false negative\", in which the sampled response can reply to the last-utterance but is considered as a negative response. For example, the general utterance \"OK!\" or \"It's great.\" can safely respond to many conversations. As shown in existing studies [1, 7, 15] , the noise from random sampling will severely affect the performance of the matching model. However, we do not have any labeled data related to true negative samples. To address this difficulty, we find inspiration from the recent progress made in complementary learning [14, 17] . We design a main-complementary task pair. As shown in Fig. 1 , the left side is the main task (i.e., our focus) which selects the correct response given the last utterance and context, while the right side is the complementary task which selects the last utterance given the response and context. To implement such a connection, we derive a weighted margin-based optimization objective for the main task. This objective is general to work with various matching models. It elegantly utilizes different prospects in utterance selection, either last-utterance selection or response selection. The main task is assisted by the complementary task, and finally, its performance is improved.", "cite_spans": [{"start": 100, "end": 103, "text": "[3,", "ref_id": "BIBREF2"}, {"start": 104, "end": 106, "text": "6]", "ref_id": "BIBREF5"}, {"start": 190, "end": 193, "text": "[1,", "ref_id": "BIBREF0"}, {"start": 194, "end": 196, "text": "3,", "ref_id": "BIBREF2"}, {"start": 197, "end": 200, "text": "16,", "ref_id": "BIBREF15"}, {"start": 201, "end": 204, "text": "22]", "ref_id": "BIBREF21"}, {"start": 433, "end": 437, "text": "[16,", "ref_id": "BIBREF15"}, {"start": 438, "end": 441, "text": "22]", "ref_id": "BIBREF21"}, {"start": 1136, "end": 1139, "text": "[1,", "ref_id": "BIBREF0"}, {"start": 1140, "end": 1142, "text": "7,", "ref_id": "BIBREF6"}, {"start": 1143, "end": 1146, "text": "15]", "ref_id": "BIBREF14"}, {"start": 1419, "end": 1423, "text": "[14,", "ref_id": "BIBREF13"}, {"start": 1424, "end": 1427, "text": "17]", "ref_id": "BIBREF16"}], "ref_spans": [{"start": 1484, "end": 1490, "text": "Fig. 1", "ref_id": "FIGREF0"}], "section": "Introduction"}, {"text": "To summarize, the major novelty lies in that the proposed approach can capture different supervision signals from different perspectives, and it is effective to reduce the influence of noisy data. The approach is general and flexible to apply to various deep matching models. We conduct extensive experiments on two public data sets, and experimental results on both data sets indicate that the models learned with our approach can significantly outperform their counterparts learned with other strategies.", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "Recently, data-driven approaches for chatbots [3, 9] have achieved promising results. Existing work can be categorized into generation-based methods [6, 9, 11, 20] and retrieval-based methods [3, 18, 21] . The first group of approaches learn response generation from the data. Based on the sequence-to-sequence structure with attention mechanism [11] , multiple extensions have been made to tackle the \"safe response\" problem and generate informative responses [6, 20] . The retrievalbased methods try to find the most reasonable response from a large repository of conversational data [3, 16] . Recent work pays more attention to context-response matching for multi-turn response selection [16, 18, 22] .", "cite_spans": [{"start": 46, "end": 49, "text": "[3,", "ref_id": "BIBREF2"}, {"start": 50, "end": 52, "text": "9]", "ref_id": "BIBREF8"}, {"start": 149, "end": 152, "text": "[6,", "ref_id": "BIBREF5"}, {"start": 153, "end": 155, "text": "9,", "ref_id": "BIBREF8"}, {"start": 156, "end": 159, "text": "11,", "ref_id": "BIBREF10"}, {"start": 160, "end": 163, "text": "20]", "ref_id": "BIBREF19"}, {"start": 192, "end": 195, "text": "[3,", "ref_id": "BIBREF2"}, {"start": 196, "end": 199, "text": "18,", "ref_id": "BIBREF17"}, {"start": 200, "end": 203, "text": "21]", "ref_id": "BIBREF20"}, {"start": 346, "end": 350, "text": "[11]", "ref_id": "BIBREF10"}, {"start": 461, "end": 464, "text": "[6,", "ref_id": "BIBREF5"}, {"start": 465, "end": 468, "text": "20]", "ref_id": "BIBREF19"}, {"start": 586, "end": 589, "text": "[3,", "ref_id": "BIBREF2"}, {"start": 590, "end": 593, "text": "16]", "ref_id": "BIBREF15"}, {"start": 691, "end": 695, "text": "[16,", "ref_id": "BIBREF15"}, {"start": 696, "end": 699, "text": "18,", "ref_id": "BIBREF17"}, {"start": 700, "end": 703, "text": "22]", "ref_id": "BIBREF21"}], "ref_spans": [], "section": "Related Work"}, {"text": "Instance weighting is a semi-supervised approach proposed by Grandvale et al. [2] . The key idea is to utilize weighted margin-based optimization to train the model with a weight function to produce a reward for each instance. Then, researchers used this method to promote the model in noisy training data [8] , and extended this method to other tasks [1, 4] . A recent work showed that the instance weighting strategy can be extended to different machine learning models and validated the improvement in different tasks.", "cite_spans": [{"start": 78, "end": 81, "text": "[2]", "ref_id": "BIBREF1"}, {"start": 306, "end": 309, "text": "[8]", "ref_id": "BIBREF7"}, {"start": 352, "end": 355, "text": "[1,", "ref_id": "BIBREF0"}, {"start": 356, "end": 358, "text": "4]", "ref_id": "BIBREF3"}], "ref_spans": [], "section": "Related Work"}, {"text": "Our work is inspired by the work of using new learning strategies to distinguish the noise in training data [7, 10, 15] . Shang et al. [10] and Lison et al. [7] utilized instance weighting strategy in open domain dialog systems via simple methods. Wu et al. [15] altered the negative sampling strategy and utilized a sequence-to-sequence model to distinguish false negative samples. Feng et al. [1] proposed three co-teaching mechanisms to reduce noise.", "cite_spans": [{"start": 108, "end": 111, "text": "[7,", "ref_id": "BIBREF6"}, {"start": 112, "end": 115, "text": "10,", "ref_id": "BIBREF9"}, {"start": 116, "end": 119, "text": "15]", "ref_id": "BIBREF14"}, {"start": 135, "end": 139, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 157, "end": 160, "text": "[7]", "ref_id": "BIBREF6"}, {"start": 258, "end": 262, "text": "[15]", "ref_id": "BIBREF14"}, {"start": 395, "end": 398, "text": "[1]", "ref_id": "BIBREF0"}], "ref_spans": [], "section": "Related Work"}, {"text": "Different from aforementioned works, we utilize the last-utterance selection task as the complementary task to assist the response selection task by computing the instance weights. This complementary task is similar to the main task since it just exchanges the last utterance with the response. Our method is similar to a dual-learning approach and the difference is that the complementary model is not optimized together with the main model but only provides the instance weights to assist the main task. Besides, the two tasks own the same neural architecture, but leverage different supervision signals from the data.", "cite_spans": [], "ref_spans": [], "section": "Related Work"}, {"text": "We denote a conversation as {u 1 , \u00b7 \u00b7 \u00b7 , u j , \u00b7 \u00b7 \u00b7 , u n }, where each utterance u j is a conversation sentence. A dialogue system is built to give the next utterance u n+1 to reply u n . We refer to the last known utterance (i.e., u n ) as last-utterance, and the utterance to be predicted (i.e., u n+1 ) as response.", "cite_spans": [], "ref_spans": [], "section": "Preliminaries"}, {"text": "We assume a training set represented by", "cite_spans": [], "ref_spans": [], "section": "Preliminaries"}, {"text": "where U qi denotes the previous utterances {u 1 , \u00b7 \u00b7 \u00b7 , u n\u22121 }. q i and r i denote the lastutterance and response respectively. y i is a label indicating whether r i is an appropriate response to the entire conversation context consisting of U qi and q i .", "cite_spans": [], "ref_spans": [], "section": "Preliminaries"}, {"text": "A retrieval-based dialogue system is designed to select the correct response r from a candidate response pool R based on the context (namely U q and q). This is also commonly called multi-turn response selection task [16, 18] . Formally, we usually solve this task by learning a matching model between last utterance and response given the context to compute the conditional probability of Pr(y = 1|q, r, U q ), which indicates the probability that r can appropriately reply to q. For simplification, we omit U q and represent the probability by Pr(y = 1|q, r).", "cite_spans": [{"start": 217, "end": 221, "text": "[16,", "ref_id": "BIBREF15"}, {"start": 222, "end": 225, "text": "18]", "ref_id": "BIBREF17"}], "ref_spans": [], "section": "Preliminaries"}, {"text": "A commonly adopted loss for the matching model is the Cross-Entropy as:", "cite_spans": [], "ref_spans": [], "section": "Preliminaries"}, {"text": "This is indeed a binary classification task. The optimization loss drives the probability of the positive utterance to be one and the negative utterance to be zero. ", "cite_spans": [], "ref_spans": [], "section": "Preliminaries"}, {"text": "In this section, we present the proposed approach to learning matching models for multi-turn response selection. Our idea is to assign different weights to training instances, so that we can force the model to focus on confident training instances. An overall illustration of the proposed approach is shown in Fig. 2 . In our approach, a general weight-enhanced margin-based optimization objective is given, where the weights indicate the reliability level of different instances. We design a complementary task that is to predict last-utterance for automatically setting these weights of training instances used in the main task.", "cite_spans": [], "ref_spans": [{"start": 310, "end": 316, "text": "Fig. 2", "ref_id": "FIGREF1"}], "section": "Approach"}, {"text": "Previous methods treat all sampled responses equally, which is easily influenced by the noise in training data. To address this problem, we propose a general weighted-enhanced optimization objective. We consider a pairwise setting: each training instance consists of a positive response and a negative response for a last utterance, denoted by r + and r \u2212 . For convenience, we assume each positive response is paired with a single negative sample.", "cite_spans": [], "ref_spans": [], "section": "A Pairwise Weight-Enhanced Optimization Objective"}, {"text": "The basic idea is to minimize the Weighted Margin-based Loss in a pairwise way, which is defined as:", "cite_spans": [], "ref_spans": [], "section": "A Pairwise Weight-Enhanced Optimization Objective"}, {"text": "where w i is the weight for the i-instance consisting of r + i and r \u2212 i . \u03b3 \u2265 0 is a parameter to control the threshold of difference. Pr(y = 1|r + i , q i ) and Pr(y = 1|r \u2212 i , q i ) denote the conditional probabilities of an utterance being an appropriate and inappropriate response for q. When the probability of a negative response is larger than a positive one, we penalize it by summing the difference into the loss. This objective is general to work with various matching methods.", "cite_spans": [], "ref_spans": [], "section": "A Pairwise Weight-Enhanced Optimization Objective"}, {"text": "A major difficulty in setting weights (shown in Eq. 1) is that there is no external supervision information. Inspired by the recent progress made in self-supervised learning and co-teaching [1, 7] , we leverage supervision signals from the data itself. Since response selection aims to select a suitable response from a candidate response pool, we devise a complementary task (i.e., last-utterance selection) that is trained with an assistant signal for setting the weights.", "cite_spans": [{"start": 190, "end": 193, "text": "[1,", "ref_id": "BIBREF0"}, {"start": 194, "end": 196, "text": "7]", "ref_id": "BIBREF6"}], "ref_spans": [], "section": "Instance Weighting with Last-Utterance Selection Model"}, {"text": "Last-Utterance Selection. Similar to response selection, here q \u2212 can be sampled negative utterances. The complementary task captures data characteristics from a different perspective, so that the learned complementary model can be used to set weights by providing evidence on instance importance. Instance Weighting. After learning the last-utterance selection model, we now utilize it to set weights for training instances. The basic idea is if an utterance is a proper response, it should well match the real last-utterance q + . On the contrary, for a true negative response, it should be uninformative to predict the last-utterance. Therefore, we introduce a new measure \u0394 to compute the degree that an utterance is a true positive response as:", "cite_spans": [], "ref_spans": [], "section": "Instance Weighting with Last-Utterance Selection Model"}, {"text": "where Pr(y = 1|q + , r) and Pr(y = 1|q \u2212 , r) are the conditional probabilities of q + and q \u2212 learned by the last-utterance selection model. In this way, a false negative response tends to yield a large \u0394 value, since it is able to reply to q + and contains useful information to discriminate between q + and q \u2212 . With this measure, we introduce our solution to set the weights defined in Eq. 2. Recall that a training instance is a pair of positive and \"negative\" utterances, and we want to assign a weighted score indicating how much attention the response selection model should pay. Intuitively, a good training instance should be able to provide useful information to discriminate between positive and negative responses. We define the instance weighting formula as:", "cite_spans": [], "ref_spans": [], "section": "Instance Weighting with Last-Utterance Selection Model"}, {"text": "where is a parameter to adjust the mean value of weights, and we constrain the weight w i to be less equal to 1. From this formula, we can see that a large weight w i tends to correspond to a large \u0394 r + i (a more informative positive response) and a small \u0394 r \u2212 i (a less discriminative negative utterance).", "cite_spans": [], "ref_spans": [], "section": "Instance Weighting with Last-Utterance Selection Model"}, {"text": "In this part, we present the complete learning approach.", "cite_spans": [], "ref_spans": [], "section": "Complete Learning Approach and Optimization"}, {"text": "We instantiate matching models for response selection. Our learning algorithm can work with any deep matching models. Here, we consider two recently proposed attention-based matching models, namely SMN [16] and DAM [22] . The SMN model is an RNN-based model. It first constructs semantic representations for context and response by GRU. Then, the matching features are captured by word-level and sequence-level similarity matrix. Finally a convolution neural network is adopted to distill important matching information as a matching vector and an utterance-level GRU is used to compute the matching score. The DAM model is a deep attention-based model which constructs semantic representation for context and response by a multilayer transformer. Then, the word-level matching features are captured by crossattention and self-attention layers. Finally a 3D-convolution is adopted to compute the matching score. These two models are selected due to their state-of-the-art performance on multi-turn response selection. Besides, previous studies have also adapted them with techniques such as weak-supervised learning [16] and co-teach learning [1] .", "cite_spans": [{"start": 202, "end": 206, "text": "[16]", "ref_id": "BIBREF15"}, {"start": 215, "end": 219, "text": "[22]", "ref_id": "BIBREF21"}, {"start": 1116, "end": 1120, "text": "[16]", "ref_id": "BIBREF15"}, {"start": 1143, "end": 1146, "text": "[1]", "ref_id": "BIBREF0"}], "ref_spans": [], "section": "Instantiation of the Deep Matching Models."}, {"text": "Learning and Optimization. Given a matching model, we first pre-train it with the cross-entropy in Eq. 1. This step aims to obtain a basic model that will be further fine-tuned by our approach. For each instance consisting of a positive and a negative response, the last-utterance selection model computes the \u0394 value for each response by Eq. 3. Then, the weights are derived by Eq. 4 and utilized in the fine-tuning process by Eq. 2. The gradient will back-propagate to optimize the parameters in the response selection model (the gradient to lastutterance selection model is obstructed). This training approach encourages the model to focus on more confident instances with the supervision signal from the complementary task.", "cite_spans": [], "ref_spans": [], "section": "Instantiation of the Deep Matching Models."}, {"text": "Discussions. In addition to the measure defined in Eq. 4, we consider using other alternatives to compute w i , such as Jaccard similarity and embedding cosine similarity between positive and negative responses. Indeed, it is also possible to replace our multi-turn last-utterance selection model with a single-turn last-utterance selection model to reduce the influence of the context information. Currently, we do not fine-tune the last-utterance selection model, since there is no significant improvement from this strategy in our early experiments. More details will be discussed in Sect. 5.3.", "cite_spans": [], "ref_spans": [], "section": "Instantiation of the Deep Matching Models."}, {"text": "In this section, we first set up the experiments, and then report the results and analysis.", "cite_spans": [], "ref_spans": [], "section": "Experiment"}, {"text": "Construction of the Datasets. To evaluate the performance of our approach, we use two public open-domain multi-turn conversation datasets. The first dataset is Douban Conversation Corpus (Douban) which is a multi-turn Chinese conversation data set crawled from Douban group 1 . This dataset consists of one million context-response pairs for training, 50,000 pairs for validation, and 6,670 pairs for test. Another dataset is E-commerce Dialogue Corpus (ECD) [19] . It consists of real-world conversations between customers and customer service staff in Taobao 2 . There are one million context-response pairs in the training set, and 10,000 pairs in both the validation set and the test set. For both datasets, the negative responses in the training set and the validation set are randomly sampled and the ratio of the positive and the negative is 1:1 3 . In the test set, each context has 10 response candidates retrieved from an index whose appropriateness regarding to the context is judged by human annotators.", "cite_spans": [{"start": 459, "end": 463, "text": "[19]", "ref_id": "BIBREF18"}], "ref_spans": [], "section": "Experimental Setup"}, {"text": "Task Setting. We implement our method as Sect. 4.3. We select DAM [22] and SMN [16] as response selection models. We only select DAM [22] as our lastutterance selection model not only due to its strong feature extraction ability, but also for guaranteeing the gain only comes from the response selection model. The pre-training process follows the setting in [16, 22] . During the instance weighting, we choose 50 as the size of the mini-batches. We use Adam optimizer [5] with the learning rate as 1e-4. All gradients are clipped by 1.0 to stabilize the training process. We tune \u03b3 in {0,1/8,2/8,3/8,4/8}, and finally choose 2/8 for Douban dataset, 4/8 for ECD dataset. And we test in {0,1/4,2/4,3/4}, and find 2/4 is the best choice for both datasets.", "cite_spans": [{"start": 66, "end": 70, "text": "[22]", "ref_id": "BIBREF21"}, {"start": 79, "end": 83, "text": "[16]", "ref_id": "BIBREF15"}, {"start": 133, "end": 137, "text": "[22]", "ref_id": "BIBREF21"}, {"start": 359, "end": 363, "text": "[16,", "ref_id": "BIBREF15"}, {"start": 364, "end": 367, "text": "22]", "ref_id": "BIBREF21"}, {"start": 469, "end": 472, "text": "[5]", "ref_id": "BIBREF4"}], "ref_spans": [], "section": "Experimental Setup"}, {"text": "Following the works [16, 22] , we use Mean Average Presion (MAP), Mean Reciprocal Rank (MRR) and Precision at position 1 (P@1) as evaluation metrics.", "cite_spans": [{"start": 20, "end": 24, "text": "[16,", "ref_id": "BIBREF15"}, {"start": 25, "end": 28, "text": "22]", "ref_id": "BIBREF21"}], "ref_spans": [], "section": "Experimental Setup"}, {"text": "Baseline Models. We combine our approach with SMN and DAM to validate the effect. Besides, we compare our models with a number of baseline models: SMN [16] and DAM [22] : We utilize the pre-training results of the two models as baselines to validate the promotion of our proposed method. Single-turn models: MV-LSTM [12] and match-LSTM [13] are the typical singleturn matching models. They concatenate all utterances in contexts as a long document for matching. Multi-view [21] : It measures the matching degree between a context and a response candidate in both a word view and an utterance view. DL2R [18] : It represents each utterance in contexts by RNNs and CNNs, and the matching score is computed based on the concatenation of the representations.", "cite_spans": [{"start": 151, "end": 155, "text": "[16]", "ref_id": "BIBREF15"}, {"start": 164, "end": 168, "text": "[22]", "ref_id": "BIBREF21"}, {"start": 316, "end": 320, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 336, "end": 340, "text": "[13]", "ref_id": "BIBREF12"}, {"start": 473, "end": 477, "text": "[21]", "ref_id": "BIBREF20"}, {"start": 603, "end": 607, "text": "[18]", "ref_id": "BIBREF17"}], "ref_spans": [], "section": "Experimental Setup"}, {"text": "In addition to these baseline models, we denote the model with our proposed weighting method as Model-WM. Table 1 . Results on two datasets. Numbers marked with * indicate that the improvement is statistically significant compared with the pre-trained baseline (t-test with p-value < 0.05). We copy the numbers from [16] for the baseline models. Because the first four baselines obtain similar results in Douban dataset, we only implement two of them in ECD dataset.", "cite_spans": [{"start": 316, "end": 320, "text": "[16]", "ref_id": "BIBREF15"}], "ref_spans": [{"start": 106, "end": 113, "text": "Table 1", "ref_id": null}], "section": "Experimental Setup"}, {"text": "Douban ECD ", "cite_spans": [], "ref_spans": [], "section": "Dataset"}, {"text": "We present the results of all comparison methods in Table 1 . First, these methods show a consistent trend on both datasets over all metrics, i.e., DAM-WM > DAM > SMN-WM > SMN > other models. We can conclude that DAM and SMN are the best baselines in this task than other models because they can capture more semantic features from word-level and sentence-level matching information. Second, our method yields improvement in SMN and DAM on two datasets, and most of these promotions are statistically significant (t-test with p-value < 0.05). This proves the effectiveness of our instance weighting method. Third, the promotion on Douban dataset by our approach is larger than that on ECD dataset. The difference may stem from the distribution of test sets of the two data. The test set of Douban is built from random sampling, while that of the ECD dataset is constructed by a response retrieval system. Therefore, the negative samples are more semantically similar to the positive ones. It is difficult to yield improvement by our approach with SMN and DAM in ECD dataset. Fourth, our method yields less improvement in SMN than DAM. A possible reason is that DAM fits our method better than SMN because DAM is a deep attention-based network, which owns stronger learning capacity. Another possible reason is that DAM is less sensitive to noisy training data since we have observed that the convergence process of SMN is not as stable as DAM. ", "cite_spans": [], "ref_spans": [{"start": 52, "end": 59, "text": "Table 1", "ref_id": null}], "section": "Results and Analysis"}, {"text": "In this section, we explore a series of variations of our method. We replace the multi-turn last-utterance selection with other models or replace the weight produced by Eq. 4 with other heuristic methods. In this part, our experiments are conducted on Douban dataset with DAM [22] as our base model.", "cite_spans": [{"start": 276, "end": 280, "text": "[22]", "ref_id": "BIBREF21"}], "ref_spans": [], "section": "Variations of Our Method"}, {"text": "We consider the following methods, which change the weight produced by Eq. 4 with heuristic methods. DAM-uniform: we fix the weight as one and follow the same procedure of our learning approach, to validate the effectiveness of our dynamic weight strategy. DAM-random: we replace the weight model as a random function to produce random values varied in [0,1]. DAM-Jaccard : we use the Jaccard similarity between positive response and negative response as the weight. DAM-embedding [7] : we use the cosine similarity between the representation of positive and negative response as the weight. For DAM model, we calculate the average hidden state of all the words in the response as its representation.", "cite_spans": [{"start": 481, "end": 484, "text": "[7]", "ref_id": "BIBREF6"}], "ref_spans": [], "section": "Heuristic Method."}, {"text": "Model-Based Method. We consider the following methods, which change the computing approach of \u0394 in Eq. 3 by substituting our complementary model with other similar models. DAM-last-WM replaces the multi-turn last-utterance selection model with a single-turn last-utterance selection model. This method is used to prove the effectiveness of the context information U in the last-utterance selection model. DAM-DAM replaces the last-utterance selection model by a response selection model. We utilize DAM model to produce P r(y = 1|q + , r) and P r(y = 1|q \u2212 , r). DAM-dual is a prime-dual approach. The response selection model is the prime model and the last-utterance selection model is the dual model. The two approaches learn instance weights for each other as Eq. 2.", "cite_spans": [], "ref_spans": [], "section": "Heuristic Method."}, {"text": "Result Analysis. Table 2 reports the results of these different variations of our method on Douban dataset. First, most of these variants outperform DAM model. It demonstrates that these instance weight strategies are effective in noisy data training. Among them, DAM-WM achieves the best results for all the three evaluation metrics. It indicates that our proposed method is more effective. Second, the improvement yielded by heuristic methods is less than model-based methods. A possible reason is that neural networks own stronger semantic capacity and the weights produced by these models can better distinguish noise in training data. Third, heuristic methods achieve worse performance than DAM-uniform. It indicates that Jaccard similarity and cosine similarity of representation are not proper instance weighting functions and bring a negative effect on response selection model. Moreover, all these model-based methods receive similar results in all three metrics and outperform DAM model. It indicates that these methods are effective but not as powerful as our proposed method. For DAM-DAM model, a possible reason is that it cannot provide more useful signal for this task than our proposed method. For DAM-last-WM, its last-utterance selection model only utilizes the last utterance therefore it cannot select positive last-utterance confidently 4 , therefore the distinguish ratio becomes noisy and low confident. For DAM-dual model, we observe that the dual-learning approach does not improve the performance of the last-utterance selection task, the reason may be that the response selection task and last-utterance selection task are not an appropriate dual-task or the dual-learning approach is not proper. We will conduct further investigation to find an appropriate dual-learning approach for this task.", "cite_spans": [], "ref_spans": [{"start": 17, "end": 24, "text": "Table 2", "ref_id": "TABREF1"}], "section": "Heuristic Method."}, {"text": "Previously, we have shown the effectiveness of our method. In this section, we qualitatively analyze why our method can yield good performance.", "cite_spans": [], "ref_spans": [], "section": "Case Study"}, {"text": "We calculate the weights of all the instances in training data of Douban dataset, and select the instances with maximum and minimum weight (1.0 and 0.0) respectively. We present some of them in Table 3 and annotate them manually. The first case receives a weight of 0.0, which demonstrates that the case is identified as inappropriate negative case by our last-utterance selection model. The last case receives a weight of 1.0, and we can identify the positive and negative responses. This case study shows that our instance weighting method can identify the false negative samples and punish them with less weight. Table 3 . Samples with the maximum and minimum weight learned by our approach. Green checkmarks indicate that the response candidates are proper replies of the contexts from human annotated, while red cross marks indicate inappropriate replies. The first case receives a weight of 0.0 and the negative responses can respond to the contexts to some extent. The second case receives a weight of 1.0 and the negative responses are unrelated to contexts. ", "cite_spans": [], "ref_spans": [{"start": 194, "end": 201, "text": "Table 3", "ref_id": null}, {"start": 616, "end": 623, "text": "Table 3", "ref_id": null}], "section": "Case Study"}, {"text": "Previous studies mainly focus on the neural architecture for multi-turn retrievalbased dialog systems, but neglect the fundamental problem from noisy training data. In this paper, we proposed a novel learning approach that was able to effectively reduce the influence of noisy data. We utilized a complementary task to learn the weights for training instances that were used by the main task. The main task was furthermore fine-tuned according to a weight-enhanced marginbased loss. Such an approach can force the model to focus on more confident training instances. Experimental results on two public datasets have demonstrated the effectiveness of our proposed method. As future work, we will design other instance weighting methods to detect noise in open domain multi-turn response selection task. Furthermore, we will consider combining our approach with more learning paradigms such as dual-learning and adversarial-learning.", "cite_spans": [], "ref_spans": [], "section": "Conclusion and Future Work"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Learning a matching model with co-teaching for multi-turn response selection in retrieval-based dialogue systems", "authors": [{"first": "J", "middle": [], "last": "Feng", "suffix": ""}, {"first": "C", "middle": [], "last": "Tao", "suffix": ""}, {"first": "W", "middle": [], "last": "Wu", "suffix": ""}, {"first": "Y", "middle": [], "last": "Feng", "suffix": ""}, {"first": "D", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "R", "middle": [], "last": "Yan", "suffix": ""}], "year": 2019, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1906.04413"]}}, "BIBREF1": {"ref_id": "b1", "title": "Semi-supervised learning by entropy minimization", "authors": [{"first": "Y", "middle": [], "last": "Grandvalet", "suffix": ""}, {"first": "Y", "middle": [], "last": "Bengio", "suffix": ""}], "year": 2004, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "An information retrieval approach to short text conversation", "authors": [{"first": "Z", "middle": [], "last": "Ji", "suffix": ""}, {"first": "Z", "middle": [], "last": "Lu", "suffix": ""}, {"first": "H", "middle": [], "last": "Li", "suffix": ""}], "year": 2014, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1408.6988"]}}, "BIBREF3": {"ref_id": "b3", "title": "Instance weighting for domain adaptation in NLP", "authors": [{"first": "J", "middle": [], "last": "Jiang", "suffix": ""}, {"first": "C", "middle": [], "last": "Zhai", "suffix": ""}], "year": 2007, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "Adam: a method for stochastic optimization", "authors": [{"first": "D", "middle": ["P"], "last": "Kingma", "suffix": ""}, {"first": "J", "middle": [], "last": "Ba", "suffix": ""}], "year": 2014, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "A diversity-promoting objective function for neural conversation models", "authors": [{"first": "J", "middle": [], "last": "Li", "suffix": ""}, {"first": "M", "middle": [], "last": "Galley", "suffix": ""}, {"first": "C", "middle": [], "last": "Brockett", "suffix": ""}, {"first": "J", "middle": [], "last": "Gao", "suffix": ""}, {"first": "W", "middle": ["B"], "last": "Dolan", "suffix": ""}], "year": 2015, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "Not all dialogues are created equal: instance weighting for neural conversational models", "authors": [{"first": "P", "middle": [], "last": "Lison", "suffix": ""}, {"first": "S", "middle": [], "last": "Bibauw", "suffix": ""}], "year": 2017, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF7": {"ref_id": "b7", "title": "Class noise mitigation through instance weighting", "authors": [{"first": "U", "middle": [], "last": "Rebbapragada", "suffix": ""}, {"first": "C", "middle": ["E"], "last": "Brodley", "suffix": ""}], "year": 2007, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Building end-to-end dialogue systems using generative hierarchical neural network models", "authors": [{"first": "I", "middle": [], "last": "Serban", "suffix": ""}, {"first": "A", "middle": [], "last": "Sordoni", "suffix": ""}, {"first": "Y", "middle": [], "last": "Bengio", "suffix": ""}, {"first": "A", "middle": ["C"], "last": "Courville", "suffix": ""}, {"first": "J", "middle": [], "last": "Pineau", "suffix": ""}], "year": 2015, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF9": {"ref_id": "b9", "title": "Learning to converse with noisy data: generation with calibration", "authors": [{"first": "M", "middle": [], "last": "Shang", "suffix": ""}, {"first": "Z", "middle": [], "last": "Fu", "suffix": ""}, {"first": "N", "middle": [], "last": "Peng", "suffix": ""}, {"first": "Y", "middle": [], "last": "Feng", "suffix": ""}, {"first": "D", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "R", "middle": [], "last": "Yan", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "A neural conversational model", "authors": [{"first": "O", "middle": [], "last": "Vinyals", "suffix": ""}, {"first": "Q", "middle": ["V"], "last": "Le", "suffix": ""}], "year": 2015, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF11": {"ref_id": "b11", "title": "Match-SRNN: modeling the recursive matching structure with spatial RNN", "authors": [{"first": "S", "middle": [], "last": "Wan", "suffix": ""}, {"first": "Y", "middle": [], "last": "Lan", "suffix": ""}, {"first": "J", "middle": [], "last": "Xu", "suffix": ""}, {"first": "J", "middle": [], "last": "Guo", "suffix": ""}, {"first": "L", "middle": [], "last": "Pang", "suffix": ""}, {"first": "X", "middle": [], "last": "Cheng", "suffix": ""}], "year": 2016, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1604.04378"]}}, "BIBREF12": {"ref_id": "b12", "title": "Learning natural language inference with LSTM", "authors": [{"first": "S", "middle": [], "last": "Wang", "suffix": ""}, {"first": "J", "middle": [], "last": "Jiang", "suffix": ""}], "year": 2015, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1512.08849"]}}, "BIBREF13": {"ref_id": "b13", "title": "Iterative learning with open-set noisy labels", "authors": [{"first": "Y", "middle": [], "last": "Wang", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF14": {"ref_id": "b14", "title": "Learning matching models with weak supervision for response selection in retrieval-based chatbots", "authors": [{"first": "Y", "middle": [], "last": "Wu", "suffix": ""}, {"first": "W", "middle": [], "last": "Wu", "suffix": ""}, {"first": "Z", "middle": [], "last": "Li", "suffix": ""}, {"first": "M", "middle": [], "last": "Zhou", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF15": {"ref_id": "b15", "title": "Sequential matching network: a new architecture for multi-turn response selection in retrieval-based chatbots", "authors": [{"first": "Y", "middle": [], "last": "Wu", "suffix": ""}, {"first": "W", "middle": [], "last": "Wu", "suffix": ""}, {"first": "C", "middle": [], "last": "Xing", "suffix": ""}, {"first": "M", "middle": [], "last": "Zhou", "suffix": ""}, {"first": "Z", "middle": [], "last": "Li", "suffix": ""}], "year": 2016, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF16": {"ref_id": "b16", "title": "Dual learning for machine translation", "authors": [{"first": "Y", "middle": [], "last": "Xia", "suffix": ""}], "year": 2016, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF17": {"ref_id": "b17", "title": "Learning to respond with deep neural networks for retrieval-based human-computer conversation system", "authors": [{"first": "R", "middle": [], "last": "Yan", "suffix": ""}, {"first": "Y", "middle": [], "last": "Song", "suffix": ""}, {"first": "H", "middle": [], "last": "Wu", "suffix": ""}], "year": 2016, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF18": {"ref_id": "b18", "title": "Modeling multi-turn conversation with deep utterance aggregation", "authors": [{"first": "Z", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "J", "middle": [], "last": "Li", "suffix": ""}, {"first": "P", "middle": [], "last": "Zhu", "suffix": ""}, {"first": "H", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "G", "middle": [], "last": "Liu", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF19": {"ref_id": "b19", "title": "Unsupervised context rewriting for open domain conversation", "authors": [{"first": "K", "middle": [], "last": "Zhou", "suffix": ""}, {"first": "K", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Y", "middle": [], "last": "Wu", "suffix": ""}, {"first": "S", "middle": [], "last": "Liu", "suffix": ""}, {"first": "J", "middle": [], "last": "Yu", "suffix": ""}], "year": 2019, "venue": "EMNLP-IJCNLP 2019", "volume": "", "issn": "", "pages": "1834--1844", "other_ids": {}}, "BIBREF20": {"ref_id": "b20", "title": "Multi-view response selection for human-computer conversation", "authors": [{"first": "X", "middle": [], "last": "Zhou", "suffix": ""}], "year": 2016, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF21": {"ref_id": "b21", "title": "Multi-turn response selection for chatbots with deep attention matching network", "authors": [{"first": "X", "middle": [], "last": "Zhou", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "The case of response and last-utterance selection model.", "latex": null, "type": "figure"}, "FIGREF1": {"text": "The overall sketch of our approach. Our approach contains a main task (Loss Optimization Module) and a complementary task (Instance Weight Calculation Module). Last-utterance selection model Mutte is utilized to calculate the instance weight, while response selection model Mres is utilized to calculate the loss for optimization.", "latex": null, "type": "figure"}, "FIGREF2": {"text": "0.584* 0.636* 0.459* 0.686 0.771* 0.647*", "latex": null, "type": "figure"}, "FIGREF3": {"text": "I am 1.63 meters tall and about 94 kilos, is it too thin? Nice idea Last Utterance It is just in the right places Hello, online celebrity Pos Response I am small boned and look thinner, so the people around me always laugh at me. ( \u221a ) I'm not online celebrity. ( \u221a ) Neg Response Haha, I think so. ( \u221a ) If you carry too many things, please think over again. (\u00d7)", "latex": null, "type": "figure"}, "TABREF0": {"text": "1st Utterance: where can I buy past National Geographic magazine 2nd Utterance: You can buy them in Shanghai Confucian temple, it seems 7 yuan one book. Last Utterance: _________________________________________ Response: Of course, you can buy French language and German language editions. Utterance Candidates: 1.Really, is it still available now? 2.Yesterday I have a dinner with him, but he always talked about his first love, does it mean I don`t have a chance? ...... Last-utterance Selection Model Response Candidates: 1.Sure, you can buy French and German language editions. 2.I get it. ...... 1st Utterance: where can I buy past National Geographic magazine 2nd Utterance: You can buy them in Shanghai Confucian temple, it seems 7 yuan one book. Last Utterance: Really, is it still available now? Response: _____________________________________________", "latex": null, "type": "table"}, "TABREF1": {"text": "Evaluation of DAM with different weighting strategies on Douban dataset.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Method </td><td>Models </td><td>MAP </td><td>MRR </td><td>P@1\n</td></tr><tr><td>Original </td><td>DAM </td><td>0.551 </td><td>0.598 </td><td>0.423\n</td></tr><tr><td>Heuristic </td><td>DAM-uniform </td><td>0.577 </td><td>0.623 </td><td>0.433\n</td></tr><tr><td>DAM-random </td><td>0.549 </td><td>0.594 </td><td>0.399\n</td></tr><tr><td>\u00a0</td><td>DAM-jaccard </td><td>0.572 </td><td>0.622 </td><td>0.438\n</td></tr><tr><td>Model-based </td><td>DAM-embedding </td><td>0.573 </td><td>0.615 </td><td>0.426\n</td></tr><tr><td>DAM-DAM </td><td>0.580 </td><td>0.627 </td><td>0.438\n</td></tr><tr><td>DAM-last-WM </td><td>0.578 </td><td>0.625 </td><td>0.439\n</td></tr><tr><td>Ours </td><td>DAM-dual </td><td>0.579 </td><td>0.621 </td><td>0.430\n</td></tr><tr><td>DAM-WM </td><td>0.584 </td><td>0.636 </td><td>0.459\n</td></tr></table></body></html>"}}, "back_matter": []}