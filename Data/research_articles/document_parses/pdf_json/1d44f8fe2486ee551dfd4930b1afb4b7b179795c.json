{"paper_id": "1d44f8fe2486ee551dfd4930b1afb4b7b179795c", "metadata": {"title": "Stacked Convolutional Neural Network for Diagnosis of COVID-19 Disease from X-ray Images", "authors": [{"first": "Mahesh", "middle": [], "last": "Gour", "suffix": "", "affiliation": {"laboratory": "", "institution": "Maulana Azad National Institute of Technology", "location": {"postCode": "462003", "settlement": "Bhopal", "region": "MP", "country": "India"}}, "email": ""}, {"first": "Sweta", "middle": [], "last": "Jain", "suffix": "", "affiliation": {"laboratory": "", "institution": "Maulana Azad National Institute of Technology", "location": {"postCode": "462003", "settlement": "Bhopal", "region": "MP", "country": "India"}}, "email": ""}]}, "abstract": [{"text": "Automatic and rapid screening of COVID-19 from the chest X-ray images has become an urgent need in this pandemic situation of SARS-CoV-2 worldwide in 2020. However, accurate and reliable screening of patients is a massive challenge due to the discrepancy between COVID-19 and other viral pneumonia in X-ray images. In this paper, we design a new stacked convolutional neural network model for the automatic diagnosis of COVID-19 disease from the chest X-ray images. We obtain different sub-models from the VGG19 and developed a 30layered CNN model (named as CovNet30) during the training, and obtained sub-models are stacked together using logistic regression. The proposed CNN model combines the discriminating power of the different CNN's sub-models and classifies chest X-ray images into COVID-19, Normal, and Pneumonia classes.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}, {"text": "In addition, we generate X-ray images dataset referred to as COVID19CXr, which includes 2764 chest x-ray images of 1768 patients from the three publicly available data repositories. The proposed stacked CNN achieves an accuracy of 92.74%, the sensitivity of 93.33%, PPV of 92.13%, and F1-score of 0.93 for the classification of X-ray images. Our proposed approach shows its superiority over the existing methods for the diagnosis of the COVID-19 from the X-ray images.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "The virus has serious consequences as its serial interval is 5 to 7.5 days, and the rate of reproduction is 2 to 3 [1] people. The coronavirus infection can incite SARS (Severe Acute Respiratory Syndrome), which might unfold serious health impacts.", "cite_spans": [{"start": 115, "end": 118, "text": "[1]", "ref_id": "BIBREF0"}], "ref_spans": [], "section": ""}, {"text": "It is estimated that many people are healthy carriers of a virus, and they are the reason for about 5% to 10% of acute respiratory infections [2] . A critical step to fight against the COVID-19 is to identify the infected people so that they get immediate treatment and isolate them to control the multiplying of the spread of the infection.", "cite_spans": [{"start": 142, "end": 145, "text": "[2]", "ref_id": "BIBREF1"}], "ref_spans": [], "section": ""}, {"text": "The COVID-19 panic has increased due to the unavailability of fast and accurate diagnosis systems to test the infected people. According to the World Health Organization (WHO), the diagnosis of COVID-19 cases must be confirmed by molecular assay, such as the reverse transcription polymerase chain reaction (RT-PCR) pathological test using throat swab samples [3] . While RT-PCR has become a standard tool for confirmation of COVID-19, but it is a very time consuming, laborious, and manual process, and there is a limitation of availability of diagnostic kits and sample collection. The availability of COVID-19 testing kits is limited as compared to the increasing amount of infected people; hence there is a need to rely on different diagnosis methodologies.", "cite_spans": [{"start": 360, "end": 363, "text": "[3]", "ref_id": "BIBREF2"}], "ref_spans": [], "section": ""}, {"text": "The coronavirus targets the epithelial cells that affect patients respiratory tract, which can be analyzed by the radiological images of a patients lungs.", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "Some early studies also show that patients present anomalies in chest x-ray images, which are the typical characteristics of COVID-19 infected patients [4, 5] .", "cite_spans": [{"start": 152, "end": 155, "text": "[4,", "ref_id": "BIBREF3"}, {"start": 156, "end": 158, "text": "5]", "ref_id": "BIBREF4"}], "ref_spans": [], "section": ""}, {"text": "Hence, the development of the computer-aided diagnosis system for the automatic analysis of radiological images can be very helpful in identifying infected patients at a faster rate. Some the advantage of the using X-ray images for COVID-19 screening as follows:", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "\u2022 Enable fast screening and rapid triaging of patients suspected of COVID-19.", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "\u2022 Making use of readily available and accessible radiological images.", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "\u2022 Portable and easy to setup, these systems can be setup in the isolation room, which significantly minimizes the risk of transmission.", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "Network (CNN) motivated us to develop a highly reliable computer-aided diagnosis (CAD) systems for the rapid detection of the COVID-19 using chest X-ray images. It will enable and enhance the automation in the screening phase, which is the crucial part of the COVID-19 pandemic. In this study, we design a new stacked convolutional neural network for automatic diagnosis of COVID-19 disease from the chest X-ray images. To train the proposed model, we generated chest X-ray images dataset, with the combination and modification of three publicly available datasets [6, 7, 8] , which we will refer to as COVID19CXr.", "cite_spans": [{"start": 565, "end": 568, "text": "[6,", "ref_id": "BIBREF5"}, {"start": 569, "end": 571, "text": "7,", "ref_id": "BIBREF6"}, {"start": 572, "end": 574, "text": "8]", "ref_id": "BIBREF7"}], "ref_spans": [], "section": "Recent advancements in deep learning specifically in Convolution Neural"}, {"text": "The organization of this paper as follows: Section 2 presents the related work. Section 3 describes the proposed stacked CNN model for the classification of COVID-19, Normal, and Pneumonia X-ray images. Section 4 describes the COVID19CXr dataset generation process and details the experimental results, performance comparison. Finally, the conclusion is drawn in Section 5.", "cite_spans": [], "ref_spans": [], "section": "Recent advancements in deep learning specifically in Convolution Neural"}, {"text": "Over the past 40 years, many computer-aided systems have been developed for the diagnosis of lung disease [9] and achieved promising results for automatic detecting lung abnormality from the radiological images [10, 11, 12] .", "cite_spans": [{"start": 106, "end": 109, "text": "[9]", "ref_id": "BIBREF8"}, {"start": 211, "end": 215, "text": "[10,", "ref_id": "BIBREF9"}, {"start": 216, "end": 219, "text": "11,", "ref_id": "BIBREF10"}, {"start": 220, "end": 223, "text": "12]", "ref_id": "BIBREF11"}], "ref_spans": [], "section": "RELATED WORK"}, {"text": "Recently, automatic CAD of COVID-19 using radiological images has drawn a lot of attention of researchers and as a result several approaches have been introduced in literature. They have published a series of research articles [13, 14] demonstrating the CAD systems for the detection of COVID-19 using radiological images. Butt at el. [15] Similarly, Narin et al. [17] have applied ResNet50, InceptionV3 and Inception-ResNetV2 using transfer learning for classification of the X-ray images into normal and COVID-19 class. This method achieved good performance with an accuracy of 98 % with ResNet50. However, the number of X-ray images are only 100 and the number of images was very less. Wang et al. [18] have proposed an open-source COVID-Net model based on the projection-expansion-projection design pattern for COVID-19 cases detection from the X-ray images. In this study, the authors reported an accuracy of 92.6 %. Oh et al. [19] have proposed patch-based CNN approach, to train ResNet18 model using image patches that have been extracted from the chest x-ray images. For decision making, they used the majority voting strategy, which resulted in an accuracy of 88.9 %.", "cite_spans": [{"start": 227, "end": 231, "text": "[13,", "ref_id": "BIBREF12"}, {"start": 232, "end": 235, "text": "14]", "ref_id": "BIBREF13"}, {"start": 335, "end": 339, "text": "[15]", "ref_id": "BIBREF14"}, {"start": 364, "end": 368, "text": "[17]", "ref_id": "BIBREF16"}, {"start": 701, "end": 705, "text": "[18]", "ref_id": "BIBREF17"}, {"start": 932, "end": 936, "text": "[19]", "ref_id": "BIBREF18"}], "ref_spans": [], "section": "RELATED WORK"}, {"text": "An objected detection based DarkCovidNet model has been proposed by Ozturk et al. [20] for automatic detection of COVID-19 cases from the Xray images. They have reported accuracy of 98.08 % for binary classification of X-ray images into COVID-19 and no-findings, and also this approach has achieves an accuracy of 87.02 % for multi-class classification of X-ray images into COVID-19, no-findings and pneumonia. Pereira et al. [21] have proposed a hierarchical classification approach, in which they extracted deep features by InceptionV3 and tested texture descriptors. They investigated early and late fusion techniques for combining the strength of descriptor and classifiers. Their hierarchical classification approach achieved F1-Score of 0.89 for the COVID-19 identification in the X-ray images.", "cite_spans": [{"start": 82, "end": 86, "text": "[20]", "ref_id": null}, {"start": 426, "end": 430, "text": "[21]", "ref_id": "BIBREF21"}], "ref_spans": [], "section": "RELATED WORK"}, {"text": "Attention-based deep 3D multiple instance learning approach has been proposed by the Han et al. [22] for automatic screening of COVID-19 from the CT images. Their algorithm achieved an accuracy of 97.9%. Wang et al. [23] developed a weakly supervised deep learning framework, in which lung region was segmented by UNet from the CT images and 3D deep neural network is applied on the segmented region for predicting probability of COVID-19 infections.", "cite_spans": [{"start": 96, "end": 100, "text": "[22]", "ref_id": "BIBREF22"}, {"start": 216, "end": 220, "text": "[23]", "ref_id": "BIBREF23"}], "ref_spans": [], "section": "RELATED WORK"}, {"text": "Authors reported an accuracy of 90.10%.", "cite_spans": [], "ref_spans": [], "section": "RELATED WORK"}, {"text": "Ucar et al. [24] proposed a SqueezeNet CNN model with Bayesian optimization for diagnosis of the COVID-19 from X-ray images. They reported an accuracy of 98.26 %. Afshar et al. [25] developed a capsule network-based framework for the classification of the X-ray images into Normal, bacterial, Non-COVID, and COVID-19 cases. The authors reported an accuracy of 95.7 % and a sensitivity of 90 %. Sethy et al. [26] extracted deep features of X-ray images from the pre-trained CNN, and support vector machine (SVM) has been applied on the extracted feature to classify x-ray images. The authors achieved an accuracy of 95.38% using ResNet50 with the SVM classifier.", "cite_spans": [{"start": 12, "end": 16, "text": "[24]", "ref_id": "BIBREF24"}, {"start": 177, "end": 181, "text": "[25]", "ref_id": "BIBREF25"}, {"start": 407, "end": 411, "text": "[26]", "ref_id": "BIBREF26"}], "ref_spans": [], "section": "RELATED WORK"}, {"text": "The Convolution Neural Network is the driving concept of deep learning algorithms in computer vision, which led to outstanding performance in most of the pattern recognition tasks such as image classification [27, 28, 29] , object localization, segmentation and detection [30, 31, 32] . It has also shown its superiority in the medical image analysis for image classification, and segmentation problem [33, 34, 35, 36] , especially in lung-related diseases such as lung nodule detection [37] , pneumonia detection [38] , and pulmonary tuberculosis [39] . CNN automatically learns a low to the high level of useful feature representations and integrates feature extraction and classification stages in a single pipeline, which is trainable in an end-to-end manner without requiring any manual design and expert human intervention.", "cite_spans": [{"start": 209, "end": 213, "text": "[27,", "ref_id": "BIBREF27"}, {"start": 214, "end": 217, "text": "28,", "ref_id": "BIBREF28"}, {"start": 218, "end": 221, "text": "29]", "ref_id": "BIBREF29"}, {"start": 272, "end": 276, "text": "[30,", "ref_id": "BIBREF30"}, {"start": 277, "end": 280, "text": "31,", "ref_id": "BIBREF31"}, {"start": 281, "end": 284, "text": "32]", "ref_id": "BIBREF32"}, {"start": 402, "end": 406, "text": "[33,", "ref_id": "BIBREF33"}, {"start": 407, "end": 410, "text": "34,", "ref_id": "BIBREF34"}, {"start": 411, "end": 414, "text": "35,", "ref_id": null}, {"start": 415, "end": 418, "text": "36]", "ref_id": "BIBREF37"}, {"start": 487, "end": 491, "text": "[37]", "ref_id": "BIBREF38"}, {"start": 514, "end": 518, "text": "[38]", "ref_id": "BIBREF39"}, {"start": 548, "end": 552, "text": "[39]", "ref_id": "BIBREF40"}], "ref_spans": [], "section": "METHODOLOGY"}, {"text": "In this work, we have developed a deep learning-based stacked convolutional neural network for the rapid screening of COVID-19 patients using X-ray images.", "cite_spans": [], "ref_spans": [], "section": "METHODOLOGY"}, {"text": "The proposed COVID-19 detection method includes three modules as shown in the Figure 1 . In the first module, a new 30-layered CNN model is built and trained on the chest X-ray images from scratch, which will be referred to as CovNet30 (Covid-19 Network of 30-layers). In the second module, a pretrained VGG19 model [27] is fine-tuned on X-ray images for the diagnosis of COVID-19 disease. Finally, in the last module, five CNN's sub-models are obtained, during the training of CovNet30 and VGG19 models. The output of CNN's sub-models are stacked together by applying logistic regression [40] ", "cite_spans": [{"start": 316, "end": 320, "text": "[27]", "ref_id": "BIBREF27"}, {"start": 589, "end": 593, "text": "[40]", "ref_id": "BIBREF41"}], "ref_spans": [{"start": 78, "end": 86, "text": "Figure 1", "ref_id": "FIGREF1"}], "section": "METHODOLOGY"}, {"text": "The CovNet30 is a task-specific, 30-layered convolutional neural network for X-ray images classification. It learns the non-linear, discriminative features directly from the chest X-ray images at multiple levels of abstraction. A detailed layer configuration of the CovNet30 network is shown in Table 1 . CovNet30 is sequential network, in which Convolutional layer with ReLU activation, pooling layer, Batch Normalization layer and dropout layer are added repetitively. Every layer of CovNet30 produce a volume of activation to the next layer through a differentiable function. Description of layers are given as follows:", "cite_spans": [], "ref_spans": [{"start": 295, "end": 302, "text": "Table 1", "ref_id": "TABREF1"}], "section": "CovNet30 Architecture and Training"}, {"text": "\u2022 Convolution Layer extracts features from the input volume by performing convolution operation. In the convolution operation, the dot product is computed between the kernels and connected local regions of the input volume of activation.", "cite_spans": [], "ref_spans": [], "section": "CovNet30 Architecture and Training"}, {"text": "\u2022 ReLU activation function is an elementwise activation function. If x is input of ReLU then it produce max(0, x) (non-negative value) in the output.", "cite_spans": [], "ref_spans": [], "section": "CovNet30 Architecture and Training"}, {"text": "\u2022 Pooling layer down sampling feature maps and reduces the computation in the network.", "cite_spans": [], "ref_spans": [], "section": "CovNet30 Architecture and Training"}, {"text": "\u2022 Batch Normalization layer speed up the learning process and improves network stability by minimizing the internal covariate shift.", "cite_spans": [], "ref_spans": [], "section": "CovNet30 Architecture and Training"}, {"text": "\u2022 Dropout is a regularization method, which prevents the network from the overfitting by dropping out units in the network.", "cite_spans": [], "ref_spans": [], "section": "CovNet30 Architecture and Training"}, {"text": "CovNet30 has been trained on the X-ray images in a supervised manner.", "cite_spans": [], "ref_spans": [], "section": "CovNet30 Architecture and Training"}, {"text": "Cross-entropy loss function is used to calculate the training error and which is minimize using the ADAM optimizer [41] . Cross-entropy loss function is mathematical represented in equation (1).", "cite_spans": [{"start": 115, "end": 119, "text": "[41]", "ref_id": "BIBREF42"}], "ref_spans": [], "section": "CovNet30 Architecture and Training"}, {"text": "Where t i and p i are the target value and predicted probability for each class i in C.", "cite_spans": [], "ref_spans": [], "section": "CovNet30 Architecture and Training"}, {"text": "In the experiment, the values of hyper-parameter are set as follows: learning rate to 0.001, the batch size to 16, and dropout probability to 0.15. we experimentally find that these are the best suitable values of hyper-parameters for network training.", "cite_spans": [], "ref_spans": [], "section": "CovNet30 Architecture and Training"}, {"text": "The VGG19 is a pre-trained network that is trained on the ImageNet dataset, which achieved state-of-the-art performance on ILSVRC Challenge 2014. It also achieves outstanding performance on the other image recognition datasets.", "cite_spans": [], "ref_spans": [], "section": "Fine-Tuning of VGG19"}, {"text": "Hence, we have also used VGG19 along with CovNet30 for generating submodels.", "cite_spans": [], "ref_spans": [], "section": "Fine-Tuning of VGG19"}, {"text": "To fine-tune the VGG19 on X-ray images, the top layers (Fully-connected layer, and Softmax layer) of the VGG19 network are removed. We added new layers such as two Convolutional layers with ReLU activation, a Global Average", "cite_spans": [], "ref_spans": [], "section": "Fine-Tuning of VGG19"}, {"text": "Pooling layer, a Fully-connected layer, and a Softmax layer, at the top of the VGG19 network. Hyper parameters for the fine-tuning of VGG19 are same as the CovNet30.", "cite_spans": [], "ref_spans": [], "section": "Fine-Tuning of VGG19"}, {"text": "Stacked generalization [42] is an ensemble approach in which a new model learns how to incorporate the best predictions of multiple existing models. The proposed approach hypothesized that different CNN's sub-models learn nonlinear discriminative features and semantic image representation from the images at different levels. Thus a stacked ensemble CNN model will be generalized and highly accurate. This section describes the proposed stacked convolutional neural network.", "cite_spans": [{"start": 23, "end": 27, "text": "[42]", "ref_id": "BIBREF43"}], "ref_spans": [], "section": "Stacked Convolutional Neural network"}, {"text": "The pseudo-code of sub-models generation process is given in Algorithm 1. The hypothesis representation of logistic regression model is as shown below:", "cite_spans": [], "ref_spans": [], "section": "Stacked Convolutional Neural network"}, {"text": "Where H i \u03b8 (x) is estimated probability p(y = i/x; \u03b8) for each class i (where i \u2208 {0 : COV ID \u2212 19, 1 : N ormal, 2 : P neumonia}) of a image x.", "cite_spans": [], "ref_spans": [], "section": "Stacked Convolutional Neural network"}, {"text": "Next, we train a logistic regression model H i \u03b8 (x) using a one-vs-rest scheme [43] for each class i. For its training, we prepared dataset by providing X-ray images from the validation set to each of the sub-models and collects predictions.", "cite_spans": [{"start": 80, "end": 84, "text": "[43]", "ref_id": "BIBREF44"}], "ref_spans": [], "section": "Stacked Convolutional Neural network"}, {"text": "In this case, every sub-model j predicts three probabilities (P 1 ji , P 2 ji , P 3 ji )", "cite_spans": [], "ref_spans": [], "section": "Stacked Convolutional Neural network"}, {"text": "for each X-ray image i of that a given image i belongs to each of the COVID-19, Normal, and Pneumonia classes. Let's say M X-ray images in the validation set, and we concatenate the output probabilities of these five sub-models that become our feature vector P M \u00d715 for the training of the logistic regression model.", "cite_spans": [], "ref_spans": [], "section": "Stacked Convolutional Neural network"}, {"text": "After training of the stacked model, on new input image x from the test set, to make a prediction, pick the class i that maximizes max i (H i \u03b8 (x)).", "cite_spans": [], "ref_spans": [], "section": "Stacked Convolutional Neural network"}, {"text": "This section presents the details of the dataset, evaluation metrics, experiments results and performance comparison.", "cite_spans": [], "ref_spans": [], "section": "EXPERIMENTS"}, {"text": "In order to train and evaluate the performance of the proposed model, we generated X-ray images dataset, with the combination and modification of three publicly available datasets [6, 7, 8] , which are referred as COVID19CXr. The [6] and 2) \"COVID-19 Image Data Collection\" [7] . Pneumonia and Normal cases images are included from the \"Mendeley data 2\" [8] . Figure 2 shows the sample chest X-ray images of COVID-19, Normal and Pneumonia classes from the COVID19CXr dataset.", "cite_spans": [{"start": 180, "end": 183, "text": "[6,", "ref_id": "BIBREF5"}, {"start": 184, "end": 186, "text": "7,", "ref_id": "BIBREF6"}, {"start": 187, "end": 189, "text": "8]", "ref_id": "BIBREF7"}, {"start": 274, "end": 277, "text": "[7]", "ref_id": "BIBREF6"}, {"start": 354, "end": 357, "text": "[8]", "ref_id": "BIBREF7"}], "ref_spans": [{"start": 360, "end": 368, "text": "Figure 2", "ref_id": "FIGREF2"}], "section": "Covid19CXr Dataset Generation"}, {"text": "For the performance assessment of the proposed method, we have used 5fold cross-validation approach, in which the dataset is divided into 5-folds at the patient level. Table 2 gives details of the distribution of images in the training set, validation set, and test set corresponding to each fold. The training set and validation set are used while training the network, and an hold-out test set is used for the performance assessment of the proposed model.", "cite_spans": [], "ref_spans": [{"start": 168, "end": 175, "text": "Table 2", "ref_id": "TABREF3"}], "section": "Covid19CXr Dataset Generation"}, {"text": "To assess the performance of proposed method we have used sensitivity, ", "cite_spans": [], "ref_spans": [], "section": "Evaluation Metrics"}, {"text": "Specif icity = T N (T N + F P ) (8)", "cite_spans": [], "ref_spans": [], "section": "Evaluation Metrics"}, {"text": "Where true positive (TP), true negative (TN), false positive (FP), and false negative (FN) are the parameters of confusion matrix. The present study deals with a multi-class problem; therefore, to get the overall metric score of the method, we calculated the mean of each metric.", "cite_spans": [], "ref_spans": [], "section": "Evaluation Metrics"}, {"text": "In order to evaluate the performance of our proposed stacked convolutional neural network, we conduct a set of experiments. In the first experiment, data augmentation techniques such as flip, rotation, shear, zoom, and shift have been applied on a training set. Thereafter, the augmented training set is utilized for the training of CovNet30 model and fine-tuning VGG19 model. In the second experiment, the stacked CNN model is trained on the validation set.", "cite_spans": [], "ref_spans": [], "section": "Results and discussion"}, {"text": "Finally, evaluation results are produced on the test set. We repeat the same \"Err \u00b1 CI\": classification error (Err) with 95% confidence interval (CI).", "cite_spans": [], "ref_spans": [], "section": "Results and discussion"}, {"text": "\"AUC \u00b1 CI\": area under the curve (AUC) with 95% confidence interval (CI).", "cite_spans": [], "ref_spans": [], "section": "Results and discussion"}, {"text": "set of experiments five times for each fold. The following sections represent the experimental results and performance comparison.", "cite_spans": [], "ref_spans": [], "section": "Results and discussion"}, {"text": "4.3.1. Discrimination power of stacked CNN model: Table 3 presents the diagnostic performance of stacked CNN and it shows good discrimination ability for the diagnosis of the COVID-19 from the chest", "cite_spans": [], "ref_spans": [{"start": 50, "end": 57, "text": "Table 3", "ref_id": "TABREF4"}], "section": "Results and discussion"}, {"text": "(e) Fold5 dition, the confidence interval for the classification error and AUC is calculated at the 95% confidence level. As shown in Table 3 the classification error of the proposed model is 7.26% \u00b1 2.16% at the 95% confidence level. In terms of sensitivity, specificity, and PPV, proposed model also shows sig- Table 6 . It can be observed from Table 6 that for the multiclass classification task, the proposed approach shows the superiority over the methods in [18, 19, 20, 21] , except the method in [24] , which has higher accuracy.", "cite_spans": [{"start": 464, "end": 468, "text": "[18,", "ref_id": "BIBREF17"}, {"start": 469, "end": 472, "text": "19,", "ref_id": "BIBREF18"}, {"start": 473, "end": 476, "text": "20,", "ref_id": null}, {"start": 477, "end": 480, "text": "21]", "ref_id": "BIBREF21"}, {"start": 504, "end": 508, "text": "[24]", "ref_id": "BIBREF24"}], "ref_spans": [{"start": 134, "end": 141, "text": "Table 3", "ref_id": "TABREF4"}, {"start": 313, "end": 320, "text": "Table 6", "ref_id": "TABREF8"}, {"start": 347, "end": 354, "text": "Table 6", "ref_id": "TABREF8"}], "section": "Results and discussion"}, {"text": "However, sensitivity is higher for our approach.", "cite_spans": [], "ref_spans": [], "section": "Performance comparison:"}, {"text": "Some of the salient features of stacked CNN can be summarized as: \u2022 The proposed method is based on the stacked generalization of CNN's sub-models, which minimizes the variance of predictions and reduces generalization error. As of the result, stacked CNN yields high diagnosis accuracy in the X-ray images.", "cite_spans": [], "ref_spans": [], "section": "Performance comparison:"}, {"text": "\u2022 The proposed stacked CNN model produces very less false positive (type 1) and false negative (type 2) error, which confirms that the stacked CNN is reliable for clinical uses.", "cite_spans": [], "ref_spans": [], "section": "Performance comparison:"}, {"text": "\u2022 The proposed model is developed based on a less complex network, which computationally efficient and shows its stability on a small dataset.", "cite_spans": [], "ref_spans": [], "section": "Performance comparison:"}, {"text": "In this paper, we introduced a new stacked convolutional neural network for the automatic diagnosis of the COVID19 from the Chest X-ray images. In the proposed method, CNN's sub-models have obtained from our developed ", "cite_spans": [], "ref_spans": [], "section": "CONCLUSION"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Serial interval of novel coronavirus (covid-19) infections, International journal of infectious diseases", "authors": [{"first": "H", "middle": [], "last": "Nishiura", "suffix": ""}, {"first": "N", "middle": ["M"], "last": "Linton", "suffix": ""}, {"first": "A", "middle": ["R"], "last": "Akhmetzhanov", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "Emerging coronaviruses: genome structure, replication, and pathogenesis", "authors": [{"first": "Y", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Q", "middle": [], "last": "Liu", "suffix": ""}, {"first": "D", "middle": [], "last": "Guo", "suffix": ""}], "year": 2020, "venue": "Journal of medical virology", "volume": "92", "issn": "4", "pages": "418--423", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Novel coronavirus (2019-ncov) technical guidance: laboratory testing for 2019-ncov in humans, World Health Organization", "authors": [{"first": "W", "middle": ["H"], "last": "Organization", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Imaging profile of the covid-19 infection: radiologic findings and literature review", "authors": [{"first": "M.-Y", "middle": [], "last": "Ng", "suffix": ""}, {"first": "E", "middle": ["Y"], "last": "Lee", "suffix": ""}, {"first": "J", "middle": [], "last": "Yang", "suffix": ""}, {"first": "F", "middle": [], "last": "Yang", "suffix": ""}, {"first": "X", "middle": [], "last": "Li", "suffix": ""}, {"first": "H", "middle": [], "last": "Wang", "suffix": ""}, {"first": "M", "middle": ["M"], "last": "Lui", "suffix": ""}, {"first": "C", "middle": ["S"], "last": "Lo", "suffix": ""}, {"first": "B", "middle": [], "last": "Leung", "suffix": ""}, {"first": "P.-L", "middle": [], "last": "Khong", "suffix": ""}], "year": 2020, "venue": "", "volume": "2", "issn": "", "pages": "", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "Clinical features of patients infected with 2019 novel coronavirus in wuhan, china", "authors": [{"first": "C", "middle": [], "last": "Huang", "suffix": ""}, {"first": "Y", "middle": [], "last": "Wang", "suffix": ""}, {"first": "X", "middle": [], "last": "Li", "suffix": ""}, {"first": "L", "middle": [], "last": "Ren", "suffix": ""}, {"first": "J", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "Y", "middle": [], "last": "Hu", "suffix": ""}, {"first": "L", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "G", "middle": [], "last": "Fan", "suffix": ""}, {"first": "J", "middle": [], "last": "Xu", "suffix": ""}, {"first": "X", "middle": [], "last": "Gu", "suffix": ""}], "year": 2020, "venue": "The lancet", "volume": "395", "issn": "10223", "pages": "497--506", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Figure 1 covid-19 chest x-ray data initiative", "authors": [{"first": "C", "middle": [], "last": "", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "Covid-19 image data collection", "authors": [{"first": "J", "middle": ["P"], "last": "Cohen", "suffix": ""}, {"first": "P", "middle": [], "last": "Morrison", "suffix": ""}, {"first": "L", "middle": [], "last": "Dao", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2003.11597"]}}, "BIBREF7": {"ref_id": "b7", "title": "Labeled optical coherence tomography (oct) and chest x-ray images for classification", "authors": [{"first": "D", "middle": [], "last": "Kermany", "suffix": ""}, {"first": "K", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "M", "middle": [], "last": "Goldbaum", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Computer-aided diagnosis in medical imaging: historical review, current status and future potential", "authors": [{"first": "K", "middle": [], "last": "Doi", "suffix": ""}], "year": 2007, "venue": "Computerized medical imaging and graphics", "volume": "31", "issn": "4-5", "pages": "198--211", "other_ids": {}}, "BIBREF9": {"ref_id": "b9", "title": "Texture analysis of medical images", "authors": [{"first": "G", "middle": [], "last": "Castellano", "suffix": ""}, {"first": "L", "middle": [], "last": "Bonilha", "suffix": ""}, {"first": "L", "middle": [], "last": "Li", "suffix": ""}, {"first": "F", "middle": [], "last": "Cendes", "suffix": ""}], "year": 2004, "venue": "Clinical radiology", "volume": "59", "issn": "12", "pages": "1061--1069", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "Automatic detection of abnormalities in chest radiographs using local texture analysis", "authors": [{"first": "B", "middle": [], "last": "Van Ginneken", "suffix": ""}, {"first": "S", "middle": [], "last": "Katsuragawa", "suffix": ""}, {"first": "B", "middle": ["M"], "last": "Ter Haar Romeny", "suffix": ""}, {"first": "K", "middle": [], "last": "Doi", "suffix": ""}, {"first": "M", "middle": ["A"], "last": "Viergever", "suffix": ""}], "year": 2002, "venue": "IEEE transactions on medical imaging", "volume": "21", "issn": "2", "pages": "139--149", "other_ids": {}}, "BIBREF11": {"ref_id": "b11", "title": "Automatic tuberculosis screening using chest radiographs", "authors": [{"first": "S", "middle": [], "last": "Jaeger", "suffix": ""}, {"first": "A", "middle": [], "last": "Karargyris", "suffix": ""}, {"first": "S", "middle": [], "last": "Candemir", "suffix": ""}, {"first": "L", "middle": [], "last": "Folio", "suffix": ""}, {"first": "J", "middle": [], "last": "Siegelman", "suffix": ""}, {"first": "F", "middle": [], "last": "Callaghan", "suffix": ""}, {"first": "Z", "middle": [], "last": "Xue", "suffix": ""}, {"first": "K", "middle": [], "last": "Palaniappan", "suffix": ""}, {"first": "R", "middle": ["K"], "last": "Singh", "suffix": ""}, {"first": "S", "middle": [], "last": "Antani", "suffix": ""}], "year": 2013, "venue": "IEEE transactions on medical imaging", "volume": "33", "issn": "2", "pages": "233--245", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "Review of artificial intelligence techniques in imaging data acquisition, segmentation and diagnosis for covid-19", "authors": [{"first": "F", "middle": [], "last": "Shi", "suffix": ""}, {"first": "J", "middle": [], "last": "Wang", "suffix": ""}, {"first": "J", "middle": [], "last": "Shi", "suffix": ""}, {"first": "Z", "middle": [], "last": "Wu", "suffix": ""}, {"first": "Q", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Z", "middle": [], "last": "Tang", "suffix": ""}, {"first": "K", "middle": [], "last": "He", "suffix": ""}, {"first": "Y", "middle": [], "last": "Shi", "suffix": ""}, {"first": "D", "middle": [], "last": "Shen", "suffix": ""}], "year": 2020, "venue": "IEEE Reviews in Biomedical Engineering", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF13": {"ref_id": "b13", "title": "The role of imaging in the detection and management of covid-19: a review", "authors": [{"first": "D", "middle": [], "last": "Dong", "suffix": ""}, {"first": "Z", "middle": [], "last": "Tang", "suffix": ""}, {"first": "S", "middle": [], "last": "Wang", "suffix": ""}, {"first": "H", "middle": [], "last": "Hui", "suffix": ""}, {"first": "L", "middle": [], "last": "Gong", "suffix": ""}, {"first": "Y", "middle": [], "last": "Lu", "suffix": ""}, {"first": "Z", "middle": [], "last": "Xue", "suffix": ""}, {"first": "H", "middle": [], "last": "Liao", "suffix": ""}, {"first": "F", "middle": [], "last": "Chen", "suffix": ""}, {"first": "F", "middle": [], "last": "Yang", "suffix": ""}], "year": 2020, "venue": "IEEE Reviews in Biomedical Engineering", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF14": {"ref_id": "b14", "title": "Deep learning system to screen coronavirus disease 2019 pneumonia", "authors": [{"first": "C", "middle": [], "last": "Butt", "suffix": ""}, {"first": "J", "middle": [], "last": "Gill", "suffix": ""}, {"first": "D", "middle": [], "last": "Chun", "suffix": ""}, {"first": "B", "middle": ["A"], "last": "Babu", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF15": {"ref_id": "b15", "title": "Application of deep learning technique to manage covid-19 in routine clinical practice using ct images: Results of 10 convolutional neural networks", "authors": [{"first": "A", "middle": ["A"], "last": "Ardakani", "suffix": ""}, {"first": "A", "middle": ["R"], "last": "Kanafi", "suffix": ""}, {"first": "U", "middle": ["R"], "last": "Acharya", "suffix": ""}, {"first": "N", "middle": [], "last": "Khadem", "suffix": ""}, {"first": "A", "middle": [], "last": "Mohammadi", "suffix": ""}], "year": 2020, "venue": "Computers in Biology and Medicine", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF16": {"ref_id": "b16", "title": "Automatic detection of coronavirus disease (covid-19) using x-ray images and deep convolutional neural networks", "authors": [{"first": "A", "middle": [], "last": "Narin", "suffix": ""}, {"first": "C", "middle": [], "last": "Kaya", "suffix": ""}, {"first": "Z", "middle": [], "last": "Pamuk", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2003.10849"]}}, "BIBREF17": {"ref_id": "b17", "title": "Covid-net: A tailored deep convolutional neural network design for detection of covid-19 cases from chest radiography images", "authors": [{"first": "L", "middle": [], "last": "Wang", "suffix": ""}, {"first": "A", "middle": [], "last": "Wong", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2003.09871"]}}, "BIBREF18": {"ref_id": "b18", "title": "Deep learning covid-19 features on cxr using limited training data sets", "authors": [{"first": "Y", "middle": [], "last": "Oh", "suffix": ""}, {"first": "S", "middle": [], "last": "Park", "suffix": ""}, {"first": "J", "middle": ["C"], "last": "Ye", "suffix": ""}], "year": 2020, "venue": "IEEE Transactions on Medical Imaging", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF20": {"ref_id": "b20", "title": "Automated detection of covid-19 cases using deep neural networks with x-ray images", "authors": [{"first": "", "middle": [], "last": "Acharya", "suffix": ""}], "year": 2020, "venue": "Computers in Biology and Medicine", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF21": {"ref_id": "b21", "title": "Covid-19 identification in chest x-ray images on flat and hierarchical classification scenarios", "authors": [{"first": "R", "middle": ["M"], "last": "Pereira", "suffix": ""}, {"first": "D", "middle": [], "last": "Bertolini", "suffix": ""}, {"first": "L", "middle": ["O"], "last": "Teixeira", "suffix": ""}, {"first": "C", "middle": ["N"], "last": "Silla", "suffix": ""}, {"first": "Y", "middle": ["M"], "last": "Costa", "suffix": ""}], "year": 2020, "venue": "Computer Methods and Programs in Biomedicine", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF22": {"ref_id": "b22", "title": "Prior-attention residual learning for more discriminative covid-19 screening in ct images", "authors": [{"first": "J", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Y", "middle": [], "last": "Bao", "suffix": ""}, {"first": "Y", "middle": [], "last": "Wen", "suffix": ""}, {"first": "H", "middle": [], "last": "Lu", "suffix": ""}, {"first": "H", "middle": [], "last": "Luo", "suffix": ""}, {"first": "Y", "middle": [], "last": "Xiang", "suffix": ""}, {"first": "X", "middle": [], "last": "Li", "suffix": ""}, {"first": "C", "middle": [], "last": "Liu", "suffix": ""}, {"first": "D", "middle": [], "last": "Qian", "suffix": ""}], "year": 2020, "venue": "IEEE Transactions on Medical Imaging", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF23": {"ref_id": "b23", "title": "Weakly supervised deep learning for covid-19 infection detection and classification from ct images", "authors": [{"first": "S", "middle": [], "last": "Hu", "suffix": ""}, {"first": "Y", "middle": [], "last": "Gao", "suffix": ""}, {"first": "Z", "middle": [], "last": "Niu", "suffix": ""}, {"first": "Y", "middle": [], "last": "Jiang", "suffix": ""}, {"first": "L", "middle": [], "last": "Li", "suffix": ""}, {"first": "X", "middle": [], "last": "Xiao", "suffix": ""}, {"first": "M", "middle": [], "last": "Wang", "suffix": ""}, {"first": "E", "middle": ["F"], "last": "Fang", "suffix": ""}, {"first": "W", "middle": [], "last": "Menpes-Smith", "suffix": ""}, {"first": "J", "middle": [], "last": "Xia", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2004.06689"]}}, "BIBREF24": {"ref_id": "b24", "title": "Covidiagnosis-net: Deep bayes-squeezenet based diagnostic of the coronavirus disease 2019 (covid-19) from x-ray images", "authors": [{"first": "F", "middle": [], "last": "Ucar", "suffix": ""}, {"first": "D", "middle": [], "last": "Korkmaz", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF25": {"ref_id": "b25", "title": "Covid-caps: A capsule network-based framework for identification of covid-19 cases from x-ray images", "authors": [{"first": "P", "middle": [], "last": "Afshar", "suffix": ""}, {"first": "S", "middle": [], "last": "Heidarian", "suffix": ""}, {"first": "F", "middle": [], "last": "Naderkhani", "suffix": ""}, {"first": "A", "middle": [], "last": "Oikonomou", "suffix": ""}, {"first": "K", "middle": ["N"], "last": "Plataniotis", "suffix": ""}, {"first": "A", "middle": [], "last": "Mohammadi", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2004.02696"]}}, "BIBREF26": {"ref_id": "b26", "title": "Detection of coronavirus disease (covid-19) based on deep features", "authors": [{"first": "P", "middle": ["K"], "last": "Sethy", "suffix": ""}, {"first": "S", "middle": ["K"], "last": "Behera", "suffix": ""}], "year": 2020, "venue": "Preprints", "volume": "2020030300", "issn": "", "pages": "", "other_ids": {}}, "BIBREF27": {"ref_id": "b27", "title": "Imagenet classification with deep convolutional neural networks", "authors": [{"first": "A", "middle": [], "last": "Krizhevsky", "suffix": ""}, {"first": "I", "middle": [], "last": "Sutskever", "suffix": ""}, {"first": "G", "middle": ["E"], "last": "Hinton", "suffix": ""}], "year": 2012, "venue": "", "volume": "", "issn": "", "pages": "1097--1105", "other_ids": {}}, "BIBREF28": {"ref_id": "b28", "title": "Deep residual learning for image recognition", "authors": [{"first": "K", "middle": [], "last": "He", "suffix": ""}, {"first": "X", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "S", "middle": [], "last": "Ren", "suffix": ""}, {"first": "J", "middle": [], "last": "Sun", "suffix": ""}], "year": 2016, "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition", "volume": "", "issn": "", "pages": "770--778", "other_ids": {}}, "BIBREF29": {"ref_id": "b29", "title": "Very deep convolutional networks for largescale image recognition", "authors": [{"first": "K", "middle": [], "last": "Simonyan", "suffix": ""}, {"first": "A", "middle": [], "last": "Zisserman", "suffix": ""}], "year": 2014, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1409.1556"]}}, "BIBREF30": {"ref_id": "b30", "title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "authors": [{"first": "R", "middle": [], "last": "Girshick", "suffix": ""}, {"first": "J", "middle": [], "last": "Donahue", "suffix": ""}, {"first": "T", "middle": [], "last": "Darrell", "suffix": ""}, {"first": "J", "middle": [], "last": "Malik", "suffix": ""}], "year": 2014, "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition", "volume": "", "issn": "", "pages": "580--587", "other_ids": {}}, "BIBREF31": {"ref_id": "b31", "title": "Fast r-cnn", "authors": [{"first": "R", "middle": [], "last": "Girshick", "suffix": ""}], "year": 2015, "venue": "Proceedings of the IEEE international conference on computer vision", "volume": "", "issn": "", "pages": "1440--1448", "other_ids": {}}, "BIBREF32": {"ref_id": "b32", "title": "Deeprnnetseg: Deep residual neural network for nuclei segmentation on breast cancer histopathological images", "authors": [{"first": "M", "middle": [], "last": "Gour", "suffix": ""}, {"first": "S", "middle": [], "last": "Jain", "suffix": ""}, {"first": "R", "middle": [], "last": "", "suffix": ""}], "year": 2019, "venue": "International Conference on Computer Vision and Image Processing", "volume": "", "issn": "", "pages": "243--253", "other_ids": {}}, "BIBREF33": {"ref_id": "b33", "title": "U-net: Convolutional networks for biomedical image segmentation", "authors": [{"first": "O", "middle": [], "last": "Ronneberger", "suffix": ""}, {"first": "P", "middle": [], "last": "Fischer", "suffix": ""}, {"first": "T", "middle": [], "last": "Brox", "suffix": ""}], "year": 2015, "venue": "International Conference on Medical image computing and computer-assisted intervention", "volume": "", "issn": "", "pages": "234--241", "other_ids": {}}, "BIBREF34": {"ref_id": "b34", "title": "Residual learning based cnn for breast cancer histopathological image classification", "authors": [{"first": "M", "middle": [], "last": "Gour", "suffix": ""}, {"first": "S", "middle": [], "last": "Jain", "suffix": ""}, {"first": "T", "middle": ["S"], "last": "Kumar", "suffix": ""}], "year": 2020, "venue": "International Journal of Imaging Systems and Technology", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF36": {"ref_id": "b36", "title": "Medical image analysis using convolutional neural networks: a review", "authors": [{"first": "", "middle": [], "last": "Khan", "suffix": ""}], "year": 2018, "venue": "Journal of medical systems", "volume": "42", "issn": "11", "pages": "", "other_ids": {}}, "BIBREF37": {"ref_id": "b37", "title": "Deep learning in medical image analysis", "authors": [{"first": "D", "middle": [], "last": "Shen", "suffix": ""}, {"first": "G", "middle": [], "last": "Wu", "suffix": ""}, {"first": "H.-I", "middle": [], "last": "Suk", "suffix": ""}], "year": 2017, "venue": "Annual review of biomedical engineering", "volume": "19", "issn": "", "pages": "221--248", "other_ids": {}}, "BIBREF38": {"ref_id": "b38", "title": "Lung nodule detection in ct using 3d convolutional neural networks", "authors": [{"first": "X", "middle": [], "last": "Huang", "suffix": ""}, {"first": "J", "middle": [], "last": "Shan", "suffix": ""}, {"first": "V", "middle": [], "last": "Vaidya", "suffix": ""}], "year": 2017, "venue": "2017 IEEE 14th International Symposium on Biomedical Imaging", "volume": "", "issn": "", "pages": "379--383", "other_ids": {}}, "BIBREF39": {"ref_id": "b39", "title": "Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning", "authors": [{"first": "P", "middle": [], "last": "Rajpurkar", "suffix": ""}, {"first": "J", "middle": [], "last": "Irvin", "suffix": ""}, {"first": "K", "middle": [], "last": "Zhu", "suffix": ""}, {"first": "B", "middle": [], "last": "Yang", "suffix": ""}, {"first": "H", "middle": [], "last": "Mehta", "suffix": ""}, {"first": "T", "middle": [], "last": "Duan", "suffix": ""}, {"first": "D", "middle": [], "last": "Ding", "suffix": ""}, {"first": "A", "middle": [], "last": "Bagul", "suffix": ""}, {"first": "C", "middle": [], "last": "Langlotz", "suffix": ""}, {"first": "K", "middle": [], "last": "Shpanskaya", "suffix": ""}], "year": 2017, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1711.05225"]}}, "BIBREF40": {"ref_id": "b40", "title": "Tx-cnn: Detecting tuberculosis in chest x-ray images using convolutional neural network", "authors": [{"first": "C", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Y", "middle": [], "last": "Cao", "suffix": ""}, {"first": "M", "middle": [], "last": "Alcantara", "suffix": ""}, {"first": "B", "middle": [], "last": "Liu", "suffix": ""}, {"first": "M", "middle": [], "last": "Brunette", "suffix": ""}, {"first": "J", "middle": [], "last": "Peinado", "suffix": ""}, {"first": "W", "middle": [], "last": "Curioso", "suffix": ""}], "year": 2017, "venue": "2017 IEEE International Conference on Image Processing (ICIP)", "volume": "", "issn": "", "pages": "2314--2318", "other_ids": {}}, "BIBREF41": {"ref_id": "b41", "title": "Stacked regressions", "authors": [{"first": "L", "middle": [], "last": "Breiman", "suffix": ""}], "year": 1996, "venue": "Machine learning", "volume": "24", "issn": "1", "pages": "49--64", "other_ids": {}}, "BIBREF42": {"ref_id": "b42", "title": "Adam: A method for stochastic optimization", "authors": [{"first": "D", "middle": ["P"], "last": "Kingma", "suffix": ""}, {"first": "J", "middle": [], "last": "Ba", "suffix": ""}], "year": 2014, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1412.6980"]}}, "BIBREF43": {"ref_id": "b43", "title": "Stacked generalization", "authors": [{"first": "D", "middle": ["H"], "last": "Wolpert", "suffix": ""}], "year": 1992, "venue": "Neural networks", "volume": "5", "issn": "2", "pages": "241--259", "other_ids": {}}, "BIBREF44": {"ref_id": "b44", "title": "Scikit-learn: Machine learning in Python", "authors": [{"first": "F", "middle": [], "last": "Pedregosa", "suffix": ""}, {"first": "G", "middle": [], "last": "Varoquaux", "suffix": ""}, {"first": "A", "middle": [], "last": "Gramfort", "suffix": ""}, {"first": "V", "middle": [], "last": "Michel", "suffix": ""}, {"first": "B", "middle": [], "last": "Thirion", "suffix": ""}, {"first": "O", "middle": [], "last": "Grisel", "suffix": ""}, {"first": "M", "middle": [], "last": "Blondel", "suffix": ""}, {"first": "P", "middle": [], "last": "Prettenhofer", "suffix": ""}, {"first": "R", "middle": [], "last": "Weiss", "suffix": ""}, {"first": "V", "middle": [], "last": "Dubourg", "suffix": ""}, {"first": "J", "middle": [], "last": "Vanderplas", "suffix": ""}, {"first": "A", "middle": [], "last": "Passos", "suffix": ""}, {"first": "D", "middle": [], "last": "Cournapeau", "suffix": ""}, {"first": "M", "middle": [], "last": "Brucher", "suffix": ""}, {"first": "M", "middle": [], "last": "Perrot", "suffix": ""}, {"first": "E", "middle": [], "last": "Duchesnay", "suffix": ""}], "year": 2011, "venue": "Journal of Machine Learning Research", "volume": "12", "issn": "", "pages": "2825--2830", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "coronavirus disease 2019 (COVID-19) pandemic has put the livelihoods and health of the massive population in a critical position. It has led to the disturbance throughout the public life of the world population. The severe acute respiratory syndrome coronavirus 2 (SARSCoV-2) belongs to the family of Coronavirus, which get transmitted in the people based on the infection in the form of direct contact or fomites. The primary symptoms of coronavirus infection are fever, cough and fatigue. In several cases coronavirus cause severe respiratory problems like Pneumonia, lung disorders and kidney malfunction.", "latex": null, "type": "figure"}, "FIGREF1": {"text": "Block diagram of proposed Stacked CNN model for building a new final CNN model for diagnosis of COVID-19 disease from X-ray images. A detailed description of the proposed approach is given in the following section:", "latex": null, "type": "figure"}, "FIGREF2": {"text": "COVID19CXr includes 2764 chest X-ray images of 1768 patients. Out of 2764 images, 270 images of 170 patients belong to a COVID-19 class, 1139 images of Samples of X-ray images of Chest from the database; where image in (a) COVID-19, (b) NORMAL, (c) PEUMONIA 1015 patients belong to Normal class and 1355 images of 583 patients belong to a Pneumonia class. COVID-19 images are obtained from the two publicly available repositories: 1) \"Figure-1 COVID-19 Chest X-ray Dataset Initiative\"", "latex": null, "type": "figure"}, "FIGREF3": {"text": "specificity, accuracy, positive prediction value (PPV), F1-score, area under the curve (AUC) and confusion matrix as evaluation metrics. The mathematical definition for the evaluation metrics is given below (in Eqn. (5), Eqn. (6), Eqn. (7), Eqn. (8) and Eqn. (9) respectively):", "latex": null, "type": "figure"}, "FIGREF4": {"text": "Confusion matrix for stacked CNN model on the different folds.X-ray images. The proposed model achieved mean sensitivity of 93.33 %, specificity of 95.81 %, PPV of 92.74 %, and accuracy of 92.74 % to classify: COVID-19, Normal and Pneumonia classes. Our method achieved good sensitivity; so that we can limit the miss classification of the COVID-19 positive cases. In ad-", "latex": null, "type": "figure"}, "FIGREF5": {"text": "ROC curve for stacked CNN model on the different folds.", "latex": null, "type": "figure"}, "FIGREF6": {"text": "For a deeper exploration of the performances of the proposed method the confusion matrix and receiver operating characteristic (ROC) curve (with AUC's CI) corresponding to each fold are evaluated and shown in Figure 3 and Figure 4, respectively. It can be observed from the confusion matrix the proposed model produce very less false negative and false positive, specifically for the COVID-19 cases compared to other cases of COVID19CXr dataset. For COVID-19 cases, it is essential to minimize the wrong diagnosis. On the other hand, the ROC curve shows the stability of the proposed stacked CNN model, and the present model achieved a mean AUC of 0.994 for COVID-19 class and a mean AUC of 0.984 along with CI of [0.012]for all categories.", "latex": null, "type": "figure"}, "FIGREF7": {"text": "CovNet30 model and pre-trained VGG19 model. Stacked CNN model ensemble the sub-models using logistic regression, for deriving a powerful model for image classification than individual sub-models. The proposed model is able to learn image discriminative features and retrieved the diverse information present in the X-ray images of the chest. It achieves a classification accuracy of 92.74%, sensitivity of 93.33%, PPV of 92.13%, and F1-score of 0.93 on the chest X-ray images of COVID19CXr dataset. Our proposed approach shows its superiority over the existing methods for the diagnosis of the COVID-19 from the X-ray images. Our experiments results show the effectiveness of the stacked CNN for classification of COVID-19, Normal, and Pneumonia X-ray images. More importantly, the proposed model outperforms the pre-trained VGG19 and CovNet30 model for the classification of X-ray images.", "latex": null, "type": "figure"}, "TABREF0": {"text": "have studied various CNN models technically and proposed a model with the combination of 2D and 3D CNN models for the classification of the CT images into COVID-19, Influenza viral pneumonia, or no-infection. Their approach achieved a sensitivity of 98.2 % and specificity of 92.2 %. Ardakani et al. [16] have presented the application of deep learning in COVID-19 detection using CT images. Authors tested ten pre-trained CNN models namely AlexNet, MobileNet-V2 VGG-16, VGG-19, ResNet-18, ResNet-50, ResNet-101, SqueezeNet, GoogleNet, and Xception. Their experiment results showed that ResNet101 performed best with area under the curve (AUC) of 0.99 over 1020 CT images of 194 patients.", "latex": null, "type": "table"}, "TABREF1": {"text": "Detailed layer configuration of CovNet30 network", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Layer Name </td><td>Type </td><td>Kernal Size </td><td>Output </td><td>Parameters\n</td></tr><tr><td>conv2D 1 </td><td>Convolutional + ReLU </td><td>7 \u00d7 7 </td><td>218 \u00d7 218 \u00d7 32 </td><td>4736\n</td></tr><tr><td>max pooling 1 </td><td>Max Pooling </td><td>2 \u00d7 2 </td><td>109 \u00d7 109 \u00d7 32 </td><td>0\n</td></tr><tr><td>batchNo 1 </td><td>Batch Normalization </td><td>- </td><td>109 \u00d7 109 \u00d7 32 </td><td>128\n</td></tr><tr><td>conv2D 2 </td><td>Convolutional + ReLU </td><td>5 \u00d7 5 </td><td>105 \u00d7 105 \u00d7 64 </td><td>51264\n</td></tr><tr><td>max pooling 2 </td><td>Max Pooling </td><td>2 \u00d7 2 </td><td>52 \u00d7 52 \u00d7 64 </td><td>0\n</td></tr><tr><td>batchNo 2 </td><td>Batch Normalization </td><td>- </td><td>52 \u00d7 52 \u00d7 64 </td><td>256\n</td></tr><tr><td>dropout 1 </td><td>Dropout </td><td>- </td><td>52 \u00d7 52 \u00d7 64 </td><td>0\n</td></tr><tr><td>conv2D 3 </td><td>Convolutional + ReLU </td><td>3 \u00d7 3 </td><td>50 \u00d7 50 \u00d7 128 </td><td>73856\n</td></tr><tr><td>max pooling 3 </td><td>Max Pooling </td><td>2 \u00d7 2 </td><td>25 \u00d7 25 \u00d7 128 </td><td>0\n</td></tr><tr><td>batchNo 3 </td><td>Batch Normalization </td><td>- </td><td>25 \u00d7 25 \u00d7 128 </td><td>512\n</td></tr><tr><td>dropout 2 </td><td>Dropout </td><td>- </td><td>25 \u00d7 25 \u00d7 128 </td><td>0\n</td></tr><tr><td>conv2D 4 </td><td>Convolutional + ReLU </td><td>3 \u00d7 3 </td><td>23 \u00d7 23 \u00d7 128 </td><td>147584\n</td></tr><tr><td>max pooling 4 </td><td>Max Pooling </td><td>2 \u00d7 2 </td><td>11 \u00d7 11 \u00d7 128 </td><td>0\n</td></tr><tr><td>batchNo 4 </td><td>Batch Normalization </td><td>- </td><td>11 \u00d7 11 \u00d7 128 </td><td>512\n</td></tr><tr><td>dropout 3 </td><td>Dropout </td><td>- </td><td>11 \u00d7 11 \u00d7 128 </td><td>0\n</td></tr><tr><td>conv2D 5 </td><td>Convolutional + ReLU </td><td>3 \u00d7 3 </td><td>9 \u00d7 9 \u00d7 256 </td><td>295168\n</td></tr><tr><td>batchNo 5 </td><td>Batch Normalization </td><td>- </td><td>9 \u00d7 9 \u00d7 256 </td><td>1024\n</td></tr><tr><td>dropout 4 </td><td>Dropout </td><td>- </td><td>9 \u00d7 9 \u00d7 256 </td><td>0\n</td></tr><tr><td>conv2D 6 </td><td>Convolutional + ReLU </td><td>3 \u00d7 3 </td><td>7 \u00d7 7 \u00d7 256 </td><td>590080\n</td></tr><tr><td>batchNo 6 </td><td>Batch Normalization </td><td>- </td><td>7 \u00d7 7 \u00d7 256 </td><td>1024\n</td></tr><tr><td>dropout 5 </td><td>Dropout </td><td>- </td><td>7 \u00d7 7 \u00d7 256 </td><td>0\n</td></tr><tr><td>conv2D 7 </td><td>Convolutional + ReLU </td><td>3 \u00d7 3 </td><td>5 \u00d7 5 \u00d7 512 </td><td>1180160\n</td></tr><tr><td>batchNo 7 </td><td>Batch Normalization </td><td>- </td><td>5 \u00d7 5 \u00d7 512 </td><td>2048\n</td></tr><tr><td>dropout 6 </td><td>Dropout </td><td>- </td><td>5 \u00d7 5 \u00d7 512 </td><td>0\n</td></tr><tr><td>conv2D 8 </td><td>Convolutional + ReLU </td><td>3 \u00d7 3 </td><td>3 \u00d7 3 \u00d7 512 </td><td>2359808\n</td></tr><tr><td>batchNo 8 </td><td>Batch Normalization </td><td>- </td><td>3 \u00d7 3 \u00d7 512 </td><td>2048\n</td></tr><tr><td>dropout 7 globAvgPooling </td><td>Dropout </td><td>- </td><td>3 \u00d7 3 \u00d7 512 </td><td>0\n</td></tr><tr><td>Global AvgPooling </td><td>- </td><td>512 </td><td>0\n</td></tr><tr><td>FC 1 </td><td>Fully Connected + ReLU </td><td>- </td><td>1000 </td><td>513000\n</td></tr><tr><td>FC 2 </td><td>Fully Connected + Softmax </td><td>- </td><td>3 </td><td>3003\n</td></tr></table></body></html>"}, "TABREF3": {"text": "Images distribution in the train set, validation set and test set, corresponding to", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Fold (s) </td><td>Data set (s) </td><td>COVID-19 </td><td>Normal </td><td>Pneumonia </td><td>Total\n</td></tr><tr><td>Train Set </td><td>189 </td><td>798 </td><td>948 </td><td>1935\n</td></tr><tr><td>Fold1 </td><td>Validation set </td><td>25 </td><td>113 </td><td>136 </td><td>274</td></tr><tr><td>Test Set </td><td>56 </td><td>228 </td><td>271 </td><td>555\n</td></tr><tr><td>Fold2 </td><td>Train Set </td><td>190 </td><td>799 </td><td>951 </td><td>1940\n</td></tr><tr><td>Validation set </td><td>27 </td><td>113 </td><td>135 </td><td>275</td></tr><tr><td>Test Set </td><td>53 </td><td>227 </td><td>269 </td><td>549\n</td></tr><tr><td>Fold3 </td><td>Train Set </td><td>189 </td><td>798 </td><td>950 </td><td>1937\n</td></tr><tr><td>Validation set </td><td>26 </td><td>113 </td><td>134 </td><td>273</td></tr><tr><td>Test Set </td><td>55 </td><td>228 </td><td>271 </td><td>554\n</td></tr><tr><td>Fold4 </td><td>Train Set </td><td>193 </td><td>797 </td><td>945 </td><td>1935\n</td></tr><tr><td>Validation set </td><td>27 </td><td>114 </td><td>136 </td><td>277</td></tr><tr><td>Test Set </td><td>50 </td><td>228 </td><td>274 </td><td>552\n</td></tr><tr><td>Fold5 </td><td>Train Set </td><td>189 </td><td>798 </td><td>952 </td><td>1939\n</td></tr><tr><td>Validation set </td><td>25 </td><td>113 </td><td>136 </td><td>274</td></tr><tr><td>Test Set </td><td>56 </td><td>228 </td><td>267 </td><td>551\n</td></tr></table></body></html>"}, "TABREF4": {"text": "Diagnosis performance of stacked CNN model.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>\u00a0</td><td>Sensitivity\n</td><td>Specificity\n</td><td>Accuracy\n</td><td>Err \u00b1 CI\n</td><td>PPV\n</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>Fold (s)\n</td><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>F1-Score </td><td>AUC \u00b1 CI\n</td></tr><tr><td>(%)\n</td><td>(%)\n</td><td>(%)\n</td><td>(%)\n</td><td>(%)\n</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>Fold1 </td><td>95.5 </td><td>98.19 </td><td>96.94 </td><td>3.06\u00b11.42 </td><td>97.69 </td><td>0.97 </td><td>0.989\u00b10.003\n</td></tr><tr><td>Fold2 </td><td>92.66 </td><td>94.97 </td><td>91.44 </td><td>8.56\u00b12.39 </td><td>91.32 </td><td>0.92 </td><td>0.982\u00b10.015\n</td></tr><tr><td>Fold3 </td><td>91.45 </td><td>95.01 </td><td>91.34 </td><td>8.66\u00b12.35 </td><td>92.13 </td><td>0.92 </td><td>0.982\u00b10.011\n</td></tr><tr><td>Fold4 </td><td>92.47 </td><td>94.77 </td><td>90.22 </td><td>9.78\u00b12.48 </td><td>85.97 </td><td>0.88 </td><td>0.977\u00b10.023\n</td></tr><tr><td>Fold5 </td><td>94.59 </td><td>96.12 </td><td>93.74 </td><td>6.26\u00b12.02 </td><td>93.54 </td><td>0.94 </td><td>0.981\u00b10.009\n</td></tr><tr><td>Mean </td><td>93.33 </td><td>95.81 </td><td>92.74 </td><td>7.26\u00b12.16 </td><td>92.13 </td><td>0.93 </td><td>0.984\u00b10.012\n</td></tr></table></body></html>"}, "TABREF5": {"text": "shows the performance comparison of the proposed method, VGG19", "latex": null, "type": "table"}, "TABREF6": {"text": "Performance comparison for different methods.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>\u00a0</td><td>\u00a0</td><td>Method\n</td><td>\u00a0</td></tr><tr><td>Metric\n</td><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>VGG19 </td><td>CovNet30 </td><td>Proposed\n</td></tr><tr><td>Accuracy (%) </td><td>89.86\u00b12.21 </td><td>87.73\u00b13.08 </td><td>92.74\u00b12.68\n</td></tr><tr><td>Sensitivity (%) </td><td>90.34\u00b14.24 </td><td>86.80\u00b14.05 </td><td>93.33\u00b11.66\n</td></tr><tr><td>Specificity (%) </td><td>94.15\u00b11.26 </td><td>93.49\u00b11.39 </td><td>95.81\u00b11.43\n</td></tr><tr><td>PPV (%) </td><td>90.53\u00b12.96 </td><td>84.54\u00b15.23 </td><td>92.13\u00b14.23\n</td></tr><tr><td>F1-score </td><td>0.90\u00b10.03 </td><td>0.85\u00b10.04 </td><td>0.93\u00b10.03\n</td></tr><tr><td>AUC </td><td>0.97\u00b10.01 </td><td>0.97\u00b10.02 </td><td>0.98\u00b10.01\n</td></tr></table></body></html>"}, "TABREF7": {"text": "Performance evaluation of the sub-models. nificant performance improvements by 2.99% \u223c 6.53%, 1.66% \u223c 2.32%, and 1.6% \u223c 7.59%, respectively. Further,Table 5represents the performance of the individual sub-models and the proposed stacked CNN model corresponding to each fold. Our stacked ensemble CNN model achieved better performance as compared to all sub-models, over the each fold.A variety of deep learning-based studies have already been proposed in past studies for COVID-19 diagnosis from the chest X-ray images. The performance comparison of the proposed method in the present study with some of related studies are shown in theTable 6.Since COVID-19 is a new epidemic and there are limited number of COVID-19 X-ray images are available publicly for developing CAD systems for COVID-19 detection. Studies in[26] and[17] have just developed on the 25 and 50 images for each class, respectively. Other studies in the[18,19,20,21,24] have used less 200 COVID-19 images for developing their methods. In this study, a total of 2764 X-ray images has been used to develop our model, including 270 COVID-19 images, which the largest number of COVID-19 images among all the studies in", "latex": null, "type": "table"}, "TABREF8": {"text": "Performance comparison with existing methods", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Author (s) </td><td>Method\n</td><td>Dataset\n</td><td>Classification Task </td><td>Results\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>Modality </td><td>Subjects\n</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>Narin et al. [17] </td><td>Pre-Train CNN </td><td>X-ray\n</td><td>50 COVID-19,\n50 Normal\n</td><td>Binary: COVID-19, Normal\n</td><td>97 % (Acc)\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>183 COVID-19,\n</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>Wang et al. [18] </td><td>COVID-Net </td><td>X-ray\n</td><td>8066 Normal, 5538 non-COVID19\n</td><td>Multiclass: COVID-19, Normal, Non-COVID19\n</td><td>92.6% (Acc)\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>191 Normal,\n</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>54 Bacterial,\n</td><td>Multiclass: Normal,\n</td><td>\u00a0</td></tr><tr><td>Oh et al. [19] </td><td>ResNet18 </td><td>X-ray\n</td><td>57 Tuberculosis,\n</td><td>Bacterial, Tuberculosis,\n</td><td>88.9% (Acc)\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>20 Viral, 180 COVID-19\n</td><td>Viral, COVID-19\n</td><td>\u00a0</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>127 COVID-19,\n</td><td>Binary: COVID-19,\n</td><td>98.08% (Acc)\n</td></tr><tr><td>Ozturk et al. [20] </td><td>DarkCovidNet </td><td>X-ray\n</td><td>500 no-findings,\n</td><td>No-findings\n</td><td>\u00a0</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>500 pneumonia\n</td><td>Multiclass: COVID-19,\n</td><td>87.02% (Acc)\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>No-findings, Pneumonia\n</td><td>\u00a0</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>200 Normal,\n</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>180 COVID-19,\n</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>Hierarchical: Normal,\n</td><td>\u00a0</td></tr><tr><td>Pereira et al. [21]\n</td><td>Deep features,\n</td><td>\u00a0</td><td>22 SARS,\n</td><td>COVID-19, SARS,\n</td><td>\u00a0</td></tr><tr><td>Texture features,\n</td><td>X-ray\n</td><td>20 MERS,\n</td><td>\u00a0</td><td>0.89 (F1-score)\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>MERS, Pneumocystis,\n</td><td>\u00a0</td></tr><tr><td>\u00a0</td><td>Fusion techniques\n</td><td>\u00a0</td><td>22 Pneumocystis,\n</td><td>Streptococcus, Varicella\n</td><td>\u00a0</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>24 Streptococcus,\n</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>20 Varicella\n</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>1583 Normal,\n</td><td>Multiclass: Normal,\n</td><td>95.7 % (Acc),\n</td></tr><tr><td>Ucar et al. [24] </td><td>SqueezeNet CNN </td><td>X-ray\n</td><td>4290 Pneumonia,\n</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>76 COVID-19\n</td><td>Pneumonia, COVID-19\n</td><td>90 % (Sens)\n</td></tr><tr><td>Sethy et al. [26] </td><td>Deep feature, SVM </td><td>X-ray\n</td><td>25 COVID-19+,\n25 COVID-19-\n</td><td>Binary: COVID-19+,\n</td><td>95.38% (Acc)\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>270 COVID-19,\n</td><td>COVID-19-\n</td><td>92.74% (Acc)\n</td></tr><tr><td>Proposed Method </td><td>Stacked CNN </td><td>X-ray\n</td><td>1139 Normal,\n</td><td>Multiclass: COVID-19,\n</td><td>93.33 % (Sens)\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td><td>1355 Pneumonia\n</td><td>Normal, Pneumonia\n</td><td>0.93 (F1-Score)\n</td></tr></table></body></html>"}}, "back_matter": []}