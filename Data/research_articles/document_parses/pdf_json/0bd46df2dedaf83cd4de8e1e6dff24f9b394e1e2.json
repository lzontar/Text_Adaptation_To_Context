{
    "paper_id": "0bd46df2dedaf83cd4de8e1e6dff24f9b394e1e2",
    "metadata": {
        "title": "Semantic Tracking in Peer-to-Peer Topic Maps Management",
        "authors": [
            {
                "first": "Asanee",
                "middle": [],
                "last": "Kawtrakul",
                "suffix": "",
                "affiliation": {
                    "laboratory": "NAiST Research Laboratory",
                    "institution": "Kasetsart University",
                    "location": {
                        "settlement": "Bangkok",
                        "country": "Thailand"
                    }
                },
                "email": "asanee.kawtrakul@nectec.or.th"
            },
            {
                "first": "Chaiyakorn",
                "middle": [],
                "last": "Yingsaeree",
                "suffix": "",
                "affiliation": {
                    "laboratory": "NAiST Research Laboratory",
                    "institution": "Kasetsart University",
                    "location": {
                        "settlement": "Bangkok",
                        "country": "Thailand"
                    }
                },
                "email": ""
            },
            {
                "first": "Frederic",
                "middle": [],
                "last": "Andres",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "National Institute of Informatics",
                    "location": {
                        "settlement": "Tokyo",
                        "country": "Japan"
                    }
                },
                "email": "andres@nii.ac.jp"
            }
        ]
    },
    "abstract": [
        {
            "text": "This paper presents a collaborative semantic tracking framework based on topic maps which aims to integrate and organize the data/information resources that spread throughout the Internet in the manner that makes them useful for tracking events such as natural disaster, and disease dispersion. We present the architecture we defined in order to support highly relevant semantic management and to provide adaptive services such as statistical information extraction technique for document summarization. In addition, this paper also carries out a case study on disease dispersion domain using the proposed framework.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "This paper gives an overview of a generic architecture we are currently building as part of the Semantic Tracking project in cooperation with the FAO AOS project [32] . Initiated by FAO and KU, the Semantic Tracking project aims at providing a wide area collaborative semantic tracking portal for monitoring important events related to agriculture and environment, such as disease dispersion, flooding, or dryness.",
            "cite_spans": [
                {
                    "start": 162,
                    "end": 166,
                    "text": "[32]",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "This implies to deal with any kind of multilingual internet news and other online articles (e.g. wiki-like knowledge and web logs); it describes the world around us rapidly by talking about the update events, states of affairs, knowledge, people and experts who participate in.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Therefore, the Semantic Tracking project targets to provide adaptive services to large group of users (e.g. operator, decision makers), depending on all the knowledge we have about the environment (users themselves, communities they are involved in, and device he's using). This vision requires defining an advanced model for the classification, the evaluation, and the distribution of multilingual semantic resources. Our approach fully relies on state of the art knowledge management strategies. We define a global collaborative architecture that allows us to handle resources from the gathering to the dissemination.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "However, sources of these data are scattered across several locations and web sites with heterogeneous formats that offer a large volume of unstructured information. Moreover, the needed knowledge was too difficult to find since the traditional search engines return ranked retrieval lists that offer little or no information on semantic relationships among those scattered information, and, even if it was found, the located information often overload since there was no content digestion. Accordingly, the automatic extraction of information expressions, especially the spatial and temporal information of the events, in natural language text with question answering system has become more obvious as a system that strives for moving beyond information retrieval and simple database query.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "However, one major problem that needs to be solved is the recognition of events which attempts to capture the richness of event-related information with their temporal and spatial information from unstructured text. Various advanced technologies including name entities recognition and related information extraction, which need natural language processing techniques, and other information technologies, such as geomedia processing, are utilized part of emerging methodologies for information extraction and aggregation with problem-solving solutions (e.g. \"know-how\" from livestock experts from countries with experiences in handling bird flu situation). Furthermore, ontological topic maps are used for organizing related knowledge.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In this paper, we present our proposal aiming to integrate and organize the data/information resources dispersed across web resources in a manner that makes them useful for tracking events such as natural disaster, and disease dispersion. The remainder of this paper is structured as follows: Section 2 describes the key issues in information tracking as nontrivial problems; In Section 3 we introduce the framework architecture and its related many-sorted algebra. Section 4 gives more details of the system process regarding the information extraction module. Section 5 discusses the personalized services (e.g. knowledge retrieval service and visualization service) provided for collaborative environments. Finally, in Section 6, we conclude and give some forthcoming issues.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Collecting and extracting data from the Internet have two main nontrivial problems: overload and scattered information, and salient information and semantic extraction from unstructured text. Many experiences [20, 21, and 35] have been done regarding event tracking or special areas or areas related to events monitoring (e.g. the best practice for governments to handle bird flu situation), the collection of important events and their related information (e.g. virus transmission from one area to other locations and from livestock to humans).",
            "cite_spans": [
                {
                    "start": 209,
                    "end": 225,
                    "text": "[20, 21, and 35]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Key Issues of Information Tracking"
        },
        {
            "text": "Firstly, target data used for semantic extraction are organized and processed to convey understanding, experience, accumulated learning, and expertise. However, sources of these data are scattered across several locations and websites with heterogeneous formats. For example, the information about Bird Flu consisting of policy for controlling the events, disease infection management, and outbreak situation may appear in different websites as shown in Fig. 1 . Egypt -update 5  16 February 2007  The Egyptian Ministry of Health and  Population has confirmed the country's  13th death from H5N1 avian influenza.  The 37-year-old female whose infection was announced on 15 February, died today. Consequently, collecting required information from scattered resources is very difficult since the semantic relations among those resources are not directly stated. Although it is possible to gather those information, the collected information often overload since there is no content digestion. Accordingly, solving those problems manually is impossible. It will consume a lot of time and CPU power. The system that can collect, extract and organize those information according to contextual dimensions automatically, is our research goal for knowledge construction and organization.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 454,
                    "end": 460,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 463,
                    "end": 629,
                    "text": "Egypt -update 5  16 February 2007  The Egyptian Ministry of Health and  Population has confirmed the country's  13th death from H5N1 avian influenza.  The 37-year-old",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Key Issues of Information Tracking"
        },
        {
            "text": "Secondly, only salient information must be extracted to reduce time consumption for users to consume the information. In many case, most of salient information (e.g. time of the event, location that event occurred, the detail of the event) are left implicitly in the texts.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Avian influenza -situation in"
        },
        {
            "text": "For example: in the text in Fig. 1 , the time expression \"15 February\" mentioned only \"date and month\" of the bird flu event but did not mention the 'year'. The patient and her condition (i.e. '37-year-old female', and 'died') was caused by bird flu which is written in the text as 'Avian influenza' and 'H5N1 avian influenza'. Accordingly, the essential component of computational model for event information capturing is the recognition of interested entities including time expression, such as 'yesterday', 'last Monday', and 'two days before', which becomes an important part in the development of more robust intelligent information system for event tracking.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 28,
                    "end": 34,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Avian influenza -situation in"
        },
        {
            "text": "Information extraction in traditional way processes a set of related entities in the format of slot and filler, but the description of information in Thai text such as locations, patient's condition, and time expressions can not be limited to a set of related entities because of the problems of using zero anaphora [17] . Moreover, to activate the frame for filling the information, name entity classification must be robust as it has been shown in [5] .",
            "cite_spans": [
                {
                    "start": 316,
                    "end": 320,
                    "text": "[17]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 450,
                    "end": 453,
                    "text": "[5]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Avian influenza -situation in"
        },
        {
            "text": "In this section, we give an overview of the modeling we are providing. Preliminary parts of our framework have been previously introduced to the Natural Language Processing and Database community [15] . In the following, we present our P2P framework and related many-sorted algebra modeling.",
            "cite_spans": [
                {
                    "start": 196,
                    "end": 200,
                    "text": "[15]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "A P2P Framework of Information Extraction for Event Tracking"
        },
        {
            "text": "Let us introduce our design approach of an ontological topic map for event semantic tracking. The ontological topic map [22] helps to establish a standardized, formally and coherently defined classification regarding event tracking. One of our current focus and challenges has to develop a comprehensive ontology, which defines the terminology set, data structure and operations regarding semantic tracking and monitoring in the field of agriculture and environment.",
            "cite_spans": [
                {
                    "start": 120,
                    "end": 124,
                    "text": "[22]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "Our Framework's Semantic Tracking Algebra"
        },
        {
            "text": "The Semantic Tracking Algebra is a formal and executable instantiation of the resulting event tracking ontology. Our algebra has to achieve two tasks: (1) first, it serves as a knowledge layer between the users (e.g. agriculture experts) and the system administration (e.g. IT scientists and researchers).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Our Framework's Semantic Tracking Algebra"
        },
        {
            "text": "Let us remind the notion of many sorted algebra [13] . Such algebra consists of several sets of values and a set of operations (functions) between these sets. Our Semantic Tracking Algebra is a domain-specific many-sorted algebra incorporating a type system for agriculture and environment data. It consists of two sets of symbols called sorts (e.g. topic, RSS postings) and operators (e.g. tm_transcribe, semantic_similarity); the function sections constitute the signature of the algebra. Its sorts, operators, sets, and functions are derived from our agriculture ontology. Second order signature [14] is based on two coupled many-sorted signatures where the toplevel signature provides kinds (set of types) as sorts (e.g. DATA, RESOURCE, SEMANTIC_DATA) and type constructors as operators (e.g. set).",
            "cite_spans": [
                {
                    "start": 48,
                    "end": 52,
                    "text": "[13]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 599,
                    "end": 603,
                    "text": "[14]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Our Framework's Semantic Tracking Algebra"
        },
        {
            "text": "To illustrate the approach, we assume the following simplified many-sorted algebra:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Our Framework's Semantic Tracking Algebra"
        },
        {
            "text": "Kinds DATA, RESOURCE, SEMANTIC_DATA, TOPIC_MAPS, SET Type constructor -> DATA topic -> RESOURCE rss, htm // resource document type -> SEMANTIC_DATA lsi_sm, rss_sm, htm_sm // Semantic and metadata vectors -> TM tm(topic maps)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Our Framework's Semantic Tracking Algebra"
        },
        {
            "text": "Unary operations \u2200 resource in RESOURCE, resource \u2192 sm: SEMANTIC_DATA,tm tm_transcribe \u2200 sm in SEMANTIC_DATA sm \u2192 set(tm) semantic_similarity",
            "cite_spans": [],
            "ref_spans": [],
            "section": "TM ->SET set"
        },
        {
            "text": "The notion sm:SEMANTIC_DATA is to be read as \"some type sm in SEMANTIC_DATA,\" and means there is a typing mapping associated with the tm_transcribe operator. Each operator determines the result type within the kind of SEMANTIC_DATA, depending on the given operand resource types.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "TM ->SET set"
        },
        {
            "text": "The semantic merging operation takes two or more operands that are all topic maps values. The select takes an operand type set (tm) and a predicate of type topic and returns a subset of the operand set fulfilling the predicate. From the implementation of view, the resource algebra is an extensible library package providing a collection of resource data types and operations for agriculture and environment resource computation. The major research challenge will be the formalization and the standardization of cultural resource data types and semantic operations through ISO standardization. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Binary operations"
        },
        {
            "text": "As shown in Fig. 2 , the proposed framework consists of six main services. The detail of each service is outlined as followed:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 12,
                    "end": 18,
                    "text": "Fig. 2",
                    "ref_id": null
                }
            ],
            "section": "Framework of P2P Semantics Tracking System"
        },
        {
            "text": "To generate useful knowledge from collected documents, two important modules, information extraction and knowledge extraction, are utilized. Ontological topic maps and domain-related ontologies defined in OWL [9] are used as a knowledge base to facilitate the knowledge construction and storage process as it has been shown in Garsho's review [11] . The standard ISO / IEC Topic Maps (ISO 13250) facilitates the knowledge interoperability and composition. The information extraction and integration module is responsible for summarizing the document into a predefined frame-like/structured database, such as <disease name, dispersion location and time, status of patient's condition>. The knowledge extraction and generalization is responsible for extracting useful knowledge (e.g. general symptom of disease) from collected document. Latent semantic analysis will be applied to find new knowledge or relationships that are not explicitly stored in the knowledge repository. Language engineering and knowledge engineering techniques are key methods to build the target platform. For language engineering, word segmentation [31] , named entity recognition [6] , shallow parsing [28] , shallow anaphora resolution and discourse processing [6, 7, and 12] have been used. For knowledge engineering, ontological engineering, task-oriented ontology, ontology maintenance [16] and Topic Maps [5] model have been applied.",
            "cite_spans": [
                {
                    "start": 209,
                    "end": 212,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 343,
                    "end": 347,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1123,
                    "end": 1127,
                    "text": "[31]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1155,
                    "end": 1158,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1177,
                    "end": 1181,
                    "text": "[28]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 1365,
                    "end": 1369,
                    "text": "[16]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1385,
                    "end": 1388,
                    "text": "[5]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Information and Knowledge Extraction and Management Services:"
        },
        {
            "text": "The information, both unstructured and semi-structured documents are gathered from many sources. Periodic web crawler and HTML Parser [33] are used to collect and organize related information. The domain specific parser [17] is used to extract and generate meta-data (e.g. title, author, and date) for interoperability between disparate and distributed information. The output of this stage is stored in the document warehouse.",
            "cite_spans": [
                {
                    "start": 134,
                    "end": 138,
                    "text": "[33]",
                    "ref_id": null
                },
                {
                    "start": 220,
                    "end": 224,
                    "text": "[17]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Distributed Information Collection Management Service:"
        },
        {
            "text": "To organize the information scattered at several locations and websites, Textual Semantics Extraction [27] is used to create a semantic metadata for each document stored in the document warehouse. Guided by domain-based ontologies associated to reasoning processes [23] and Ontological topic map, the extraction process can be taught of as a process for assigning a topic to considered documents or extracting contextual metadata from documents following Xiao's approach [36] .",
            "cite_spans": [
                {
                    "start": 102,
                    "end": 106,
                    "text": "[27]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 265,
                    "end": 269,
                    "text": "[23]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 471,
                    "end": 475,
                    "text": "[36]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Content-based Metadata Extraction Service:"
        },
        {
            "text": "Knowledge Retrieval Service: This module is responsible for creating response to users' query. The query processing based on TMQL-like requests is used to interact with the Knowledge management layer.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Content-based Metadata Extraction Service:"
        },
        {
            "text": "Knowledge Visualization: After obtaining all required information from the previous module, the last step is to provide the means to help users consume that information in an efficient way. To do this, many visualization functions is provided. For example, Spatial Visualization can be used to visualize the information extracted from the Information Extraction module and Graph-based Visualization can be used to display hierarchal categorization in the topic maps in an interactive way [27] . Due to page limitation, this paper will focus in only Information Extraction module, Knowledge Retrieval Service module and Knowledge Visualization Service module.",
            "cite_spans": [
                {
                    "start": 488,
                    "end": 492,
                    "text": "[27]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Content-based Metadata Extraction Service:"
        },
        {
            "text": "The proposed model for extracting information from unstructured documents consists of three main components, namely Entity Recognition, Relation Extraction, and Output Generation, as illustrate in Fig. 3 . The Entity Recognition module is responsible for locating and classifying atomic elements in the text into predefined categories such as the names of diseases, locations, and expressions of times. The Relation Extraction module is responsible for recognizing the relations between entities recognized by the Entity Recognition module. The output of this step is a graph representing relations among entities where a node in the graph represents an entity and the link between nodes represents the relationship of two entities. The Output Generation module is responsible for generating the n-tuple representing extracted information from the relation graph. The details of each module are described as followed.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 197,
                    "end": 203,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "Information Extractions"
        },
        {
            "text": "To recognize an entity in the text, the proposed system utilizes the work of H. Chanlekha and A. Kawtrakul [6] that extracts entity using maximum entropy [2] , heuristic information and dictionary. The extraction process consists of three steps. Firstly, the candidates of entity boundary are generated by using heuristic rules, dictionary, and statistic of word co-occurrence. Secondly, each generated candidate is then tested against the probability distribution modeled by using maximum entropy. The features used to model the probability distribution can be classified into four categories: Word Features, Lexical Features, Dictionary Features, and Blank Features as described in [7] . Finally, the undiscovered entity is extracted by matching the extracted entity against the rest of the document. The experiment with 135,000 words corpus, 110,000 words for training and 25,000 words for testing, shown that the precision, recall and f-score of the proposed method are 87.60%, 87.80%, 87.70% respectively.",
            "cite_spans": [
                {
                    "start": 107,
                    "end": 110,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 154,
                    "end": 157,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 684,
                    "end": 687,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Entity Recognition"
        },
        {
            "text": "To extract the relation amongst the extracted entities, the proposed system formulates the relation extraction problem as a classification problem. Each pair of extracted entity is tested against the probability distribution modeled by using maximum entropy to determine whether they are related or not. If they are related, the system will create an edge between the nodes representing those entities. The features used to model the probability distribution are solely based on the surface form of the word surrounding the considered entities; specifically, we use the word n-gram and the location relative to considered entities as features. The surrounding context is classified into three disjointed zone: prefix, infix, and suffix. The infix is further segmented into smaller chunks by limiting the number of words in each chunk. For example, to recognize the relation between VICTIM and CONDITION in the sentence \"The [VICTIM] whose [CONDITION] was announced on ....\", the prefix, infix and suffix in this context is 'the', 'whose', and 'was announced on ....' respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Relation Extraction"
        },
        {
            "text": "To determine and to assess the \"best\" n-gram parameter and number of words in each chunk of the system, we conduct the experiment with 257 documents, 232 documents for training and 25 documents for testing. We vary the n-gram parameter from 1 to 7 and set the number of words in each chunk as 3, 5, 7, 10, 13, and 15. The result is illustrated in Fig. 4 . The evident shows that f-score is maximum when n-gram is 4 and number of words in each chunk is 7. The precision, recall and f-score at the maximum f-score are 58.59%, 32.68% and 41.96% respectively.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 347,
                    "end": 353,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Fig. 3. Overview of the information extraction module"
        },
        {
            "text": "After obtaining a graph representing relations between extracted entities, the final step of information extraction is to transform the relation graph into the n-tuple representing extracted information. Heuristic information is employed to guide the transformation process. For example, to extract the information about disease outbreak (i.e. disease name, time, location, condition, and victim), the transformation process will starts by analyzing the entity of the type condition, since each n-tuple can contain only one piece of information about the condition. It then travels the graph to obtain all entities that are related to considered condition entity. After obtaining all related entities, the output n-tuple is generated by filtering all related entities using constrain imposed by the property of each slot. If the slot can contains only one entity, the entity that has the maximum probability will be chosen to fill the slot. In general, if the slot can contain up to n entities, the top-n entities will be selected. In addition, if there is no entity to fill the required slot, the mode (most frequent) of the entity of that slot will be used to fill instead. The time expression normalization using rule-based system and synonym resolution using ontology are also performed in this step to generalize the output n-tuple. The example of the input and output of the system are illustrated in Fig. 3 . ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 1407,
                    "end": 1413,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "Output Generation"
        },
        {
            "text": "Distributed adaptive and automated services require exploiting all the environmental knowledge stored in ontological topic maps that is available about the elements involved in the processes [24] . An important category of this knowledge is related to devices' states; indeed, knowing if a device is on, in sleep mode, off, if its battery still has autonomy of five minutes or four days, or if it has a wired or wireless connection, etc. helps adapting services that can be delivered to this device. For each device, we consider a state control that is part of the device's profile. Then, of course, we use the information contained in communities' and users' profiles. Personalized services rely on user-related contexts such as localization, birth date, languages abilities, professional activities, hobbies, communities' involvement, etc. that give clues to the system about users' expectations and abilities. In the remainder of this section, we present the two main adaptive services: the knowledge service and the knowledge visualization service based on our model.",
            "cite_spans": [
                {
                    "start": 191,
                    "end": 195,
                    "text": "[24]",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "Adaptive Services"
        },
        {
            "text": "The Knowledge Retrieval Service module is responsible for interacting with the topic maps repository to generate answers to user's TMQL-like queries [33] . The framework currently supports three types of query. The detail of each query type is summarized in Table 1 . ",
            "cite_spans": [
                {
                    "start": 149,
                    "end": 153,
                    "text": "[33]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 258,
                    "end": 265,
                    "text": "Table 1",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Knowledge Retrieval Service"
        },
        {
            "text": "The Knowledge Visualization Service is responsible for representing the extracted information and knowledge in an efficient way. Users require to access to concise organization of the knowledge. Schneiderman in [12] pointed that \"the visual information-seeking mantra is overview first, zoom and filter, then details ondemand\". In order to locate relevant information quickly and explore the semanticrelated structure, our flexible approach regarding two ways of visualizations (spatialbased or graph-based visualization) is described in the following.",
            "cite_spans": [
                {
                    "start": 211,
                    "end": 215,
                    "text": "[12]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Knowledge Visualization Service"
        },
        {
            "text": "The spatial-based visualization functions help users to visualize the extracted information (e.g. the bird flu outbreak situation extracted in Fig. 3 .) using web-based geographical information system, such as Google Earth. This kind of visualization allows the users to click on the map to get the outbreak situation of the area according to their requests. In addition, by viewing the information in the map users can see the spatial relations amongst the outbreak situations easier than without the map. One usage example of Google Earth integrated system for visualizing the extracted information about bird flu situation is shown in Fig. 5 . 6 Related Works",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 143,
                    "end": 149,
                    "text": "Fig. 3",
                    "ref_id": null
                },
                {
                    "start": 638,
                    "end": 644,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Spatial Visualization"
        },
        {
            "text": "We agree that distributed knowledge management has to assume two principles [4] related to the classification: (1) autonomy of classification for each knowledge management unit (such as community), and (2) coordination of these units in order to ensure a global consistency. Having a decentralized peer-to-peer knowledge management, the SWAP platform [25] is designed to enable knowledge sharing in a distributed environment. Pinto et al. provide interesting updates and changes support between peers. However, vocabularies in SWAP have to be harmonized; which implies to have some loss of knowledge consistency. But even if we share the approach of core knowledge structure that is expendable, the vocabulary, in our case, is common and fully shared by the community, so the knowledge evaluation and comparison can be more effective. Moreover, SWAP provides some kind of personalization (user interface mainly) but does not go as far as the Semantic Tracking does. From our point of view, SWAP definitely lacks environmental knowledge management that is required to perform advanced services; on the other hand, DBGlobe [26] is a service-oriented peer-to-peer system where mobile peers carrying data provide the base for services to be performed. Its knowledge structure is quite similar to our project as it is using metadata about devices, users and data within profiles; moreover, communities are also focused on one semantic concept. DBGlobe relies on AXML [3] in order to perform embedded calls to Web services within XML. Thus, it provides a very good support for performing services but does not focus on users and environments knowledge in order to offer optimized authoritarian adaptive services. Described as a P2P DBMS, AmbientDB [10] relies on the concept of Ambient Intelligence, which is very similar to our vision of adaptive services with automatic cooperation between devices and personalization. However, although AmbientDB is using the effective Chord Distributed Hash Table to index the metadata related to resources, it lacks the environmental knowledge management provided inside our project that is necessary to achieve adaptive collaborative distribution and personalized query optimization.",
            "cite_spans": [
                {
                    "start": 76,
                    "end": 79,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 351,
                    "end": 355,
                    "text": "[25]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 1121,
                    "end": 1125,
                    "text": "[26]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 1462,
                    "end": 1465,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1742,
                    "end": 1746,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 1989,
                    "end": 1997,
                    "text": "Table to",
                    "ref_id": null
                }
            ],
            "section": "Distributed Services"
        },
        {
            "text": "The extraction framework described in this paper is closely related to ProMED-PLUS [37] , a system for the automatic \"fact\" extraction from plain-text reports about outbreaks of infectious epidemics around the world to database, and MiTAP [8] , a prototype SARS detecting, monitoring and analyzing system. The difference between our framework and those systems is that we also emphasize on generating the semantic relations among the collected resources and organizing those information by using topic map model.",
            "cite_spans": [
                {
                    "start": 83,
                    "end": 87,
                    "text": "[37]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 239,
                    "end": 242,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Semantic Tracking"
        },
        {
            "text": "The proposed information extraction model that formulates the relation extraction problem as a classification problem is motivated by the work of J.Suzuki et. al. [30] . This innovated work has proposed a HDAG kernel solving many problems in natural language processing. The use of classification methods in information extraction is not new. Intuitively, one can view the information extraction problem as a problem of classifying a fragment of text into a predefined category which results in a simple information extraction system such as a system for extracting information from job advertisements [38] and business cards [19] . However, those techniques require the assumption that there should be only one set of information in each document, while our model could support more than one set of information.",
            "cite_spans": [
                {
                    "start": 163,
                    "end": 167,
                    "text": "[30]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 602,
                    "end": 606,
                    "text": "[38]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 626,
                    "end": 630,
                    "text": "[19]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Semantic Tracking"
        },
        {
            "text": "As communities generate increasing amounts of transactions and deal with fast growing data, it is very important to provide new strategies for their collaborative management of knowledge. In this paper, we presented and described our proposal regarding Information Modeling for Adaptive Semantic Management which aims at extracting information and knowledge from unstructured documents that spread throughout the Internet by emphasizing on information extraction technique, event tracking and knowledge organizing. We first motivated the need for such modeling in order to provide personalized services to users who are involved in semantic tracking communities. The motivation for this work is definitely to improve user's access to semantic information and to reach high satisfaction levels for decision making. Then, we gave an overview of our approach's algebra with its operators, focusing on update and consistency policies. We finally proposed and defined adaptive services that enable collaborative project to automatically dispatch semantic and to make the query results more relevant.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion and Forthcoming Issues"
        },
        {
            "text": "This challenging work needs more complicate natural language processing with deeply semantic relations interpretation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion and Forthcoming Issues"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Know-what: A Development of Object Property Extraction from Thai Texts and Query System",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kongwan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kawtrakul",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Proceedings of SNLP-2005",
            "volume": "",
            "issn": "",
            "pages": "974--9942",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "A maximum entropy approach to natural language processing",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "L"
                    ],
                    "last": "Berger",
                    "suffix": ""
                },
                {
                    "first": "S.-A",
                    "middle": [
                        "D"
                    ],
                    "last": "Pietra",
                    "suffix": ""
                },
                {
                    "first": "V.-J",
                    "middle": [
                        "D"
                    ],
                    "last": "Pietra",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Computational Linguistics",
            "volume": "22",
            "issn": "",
            "pages": "39--71",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Atomicity for P2P based XML Repositories",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Biswas",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "ICDE 2007",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "The Role of Classification(s) in Distributed Knowledge Management",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bonifacio",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Bouquet",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Cuel",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Proc. of KES, Podere d'Ombriano",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Thai Named Entity Extraction by incorporating Maximum Entropy Model with Simple Heuristic Information",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Chanlekha",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kawtrakul",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "IJCNLP 2004",
            "volume": "3248",
            "issn": "",
            "pages": "49--55",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Elementary Discourse unit Segmentation for Thai using Discourse Cue and Syntactic Information",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Chareonsuk",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Sukvakree",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kawtrakul",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Proceedings of SNLP",
            "volume": "",
            "issn": "",
            "pages": "974--9942",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "MiTAP for SARS detection",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Damianos",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bayer",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Chisholm",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Henderson",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Hirschman",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Morgan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ubaldino",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zarrella",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Proceedings of the Conference on Human Language Technology",
            "volume": "",
            "issn": "",
            "pages": "241--244",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "OWL Web Ontology Language Reference. W3C Recommendation",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Dean",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Connolly",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Van Harmelen",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Hendler",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Horrocks",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "L"
                    ],
                    "last": "Mcguinness",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "F"
                    ],
                    "last": "Patel-Schneider",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "A"
                    ],
                    "last": "Stein",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "AmbientDB: P2P Data Management Middleware for Ambient Intelligence",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Fontijn",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "A"
                    ],
                    "last": "Boncz",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Proceedings. of PerCom Workshops",
            "volume": "",
            "issn": "",
            "pages": "203--207",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Living with Topic Maps and RDF",
            "authors": [
                {
                    "first": "L",
                    "middle": [
                        "M"
                    ],
                    "last": "Garshol",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Available at 12",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Centering: A Framework for Modeling the Local Coherence of Discourse",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Grosz",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Joshi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Weinstein",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Computational Linguistics",
            "volume": "21",
            "issn": "",
            "pages": "203--225",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Proceedings of the 15th international Conference on Very Large Data Bases. Very Large Data Bases",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "H"
                    ],
                    "last": "G\u00fcting",
                    "suffix": ""
                }
            ],
            "year": 1989,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "33--44",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Second-order signature: a tool for specifying data models, query processing, and optimization",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "H"
                    ],
                    "last": "G\u00fcting",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "SIGMOD 1993. Proceedings of the 1993 ACM SIGMOD international Conference on Management of Data",
            "volume": "",
            "issn": "",
            "pages": "277--286",
            "other_ids": {
                "DOI": [
                    "10.1145/170035.170079"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "A Framework of NLP based Information Tracking and related Knowledge Organizing with Topic Maps",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kawtrakul",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Permpool",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Yingsaeree",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Andres",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "NLDB 2007",
            "volume": "4592",
            "issn": "",
            "pages": "272--283",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Automatic Thai Ontology Construction and Maintenance System",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kawtrakul",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Suktarachan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Imsombut",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Proceedings of Ontolex Workshop on LREC",
            "volume": "",
            "issn": "",
            "pages": "68--74",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "A Unified Framework for Automatic Metadata Extraction from Electronic Document",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kawtrakul",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Yingsaeree",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Proceedings of The International Advanced Digital Library Conference",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Know-what: A Development of Object Property Extraction from Thai Texts and Query System",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kongwan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kawtrakul",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Proceedings of SNLP-2005",
            "volume": "",
            "issn": "",
            "pages": "974--9942",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Information extraction by text classification",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Kushmerick",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Johnston",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mcguinness",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Proceedings of IJCAI-2001 Workshop on Adaptive Text Extraction and Mining",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Profile-based event tracking",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "SIGIR 2005 Proceedings of the 28th Annual international ACM SIGIR Conference on Research and Development in information Retrieval",
            "volume": "",
            "issn": "",
            "pages": "631--632",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Event Recognition with Fragmented Object Tracks, icpr",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "T"
                    ],
                    "last": "Chan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hoogs",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Schmiederer",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Bhotika",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Doretto",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Proceedings of 18th International Conference on Pattern Recognition (ICPR 2006)",
            "volume": "",
            "issn": "",
            "pages": "412--416",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Application Framework Based on Topic Maps",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Naito",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Andres",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "TMRA 2005",
            "volume": "3873",
            "issn": "",
            "pages": "42--52",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "A Flexible Ontology Reasoning Architecture for the Semantic Web",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "Z"
                    ],
                    "last": "Pan",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "IEEE Transactions on Knowledge and Data Engineering",
            "volume": "19",
            "issn": "2",
            "pages": "246--260",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "On Data Management in Pervasive Computing Environments",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Perich",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Joshi",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "W"
                    ],
                    "last": "Finin",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yesha",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Trans. Knowl. Data Eng",
            "volume": "16",
            "issn": "5",
            "pages": "621--634",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "OntoEdit Empowering SWAP: a Case Study in Supporting DIstributed, Loosely-Controlled and evolvInG Engineering of oNTologies (DILIGENT)",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "S"
                    ],
                    "last": "Pinto",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Staab",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sure",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Tempich",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "ESWS 2004",
            "volume": "3053",
            "issn": "",
            "pages": "10--12",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "DBGlobe: a serviceoriented P2P system for global computing",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Pitoura",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Abiteboul",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Pfoser",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Samaras",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Vazirgiannis",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "SIGMOD Rec",
            "volume": "32",
            "issn": "3",
            "pages": "77--82",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Topic Management in Spatial-Temporal Multimedia Blog",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Rajbhandari",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Andres",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Naito",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Wuwongse",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "the 1st IEEE International Conference on Digital Information Management (ICDIM 2006)",
            "volume": "",
            "issn": "",
            "pages": "1--4244",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Bootstrap Cleaning and Quality Control for Thai Tree Bank Construction",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Satayamas",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Thumkanon",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kawtrakul",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Proceedings of NCSEC-2005",
            "volume": "",
            "issn": "",
            "pages": "974--677",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "The eyes have it: a task by data type taxonomy for information visualizations",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Shneiderman",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Proceedings of 1996 IEEE Visual Languages",
            "volume": "",
            "issn": "",
            "pages": "336--343",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Kernels for structured natural language data",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Suzuki",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Sasaki",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Maeda",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Proceeding of NIPS 2003",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Thai Word Segmentation based on Global and Local Unsupervised Learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sudprasert",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kawtrakul",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Proceedings of NCSEC-2003",
            "volume": "",
            "issn": "",
            "pages": "974--3826",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Know-who: Person Information from Web Mining",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Thamvijit",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Chanlekha",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Sirigayon",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Permpool",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kawtrakul",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Proceedings of NCSEC",
            "volume": "",
            "issn": "",
            "pages": "974--677",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Topic Map Query Language (TMQL)",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Event Recognition on News Stories and Semi-Automatic Population of an Ontology, wi",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Vargas-Vera",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Celjuska",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "IEEE/WIC/ACM International Conference on Web Intelligence (WI 2004)",
            "volume": "",
            "issn": "",
            "pages": "615--618",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Using Categorial Context-SHOIQ(D) DL to Integrate Context-aware Web Ontology MetaData",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Proceedings of Second International Conference on Semantics, Knowledge, and Grid",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Information Extraction from Epidemiological Reports",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Yangarber",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Jokipii",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rauramo",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Huttunen",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Proceedings of HLT/EMNLP-2005",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Information extraction by text classification: Corpus mining for features",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zavrel",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Berck",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Lavrijssen",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "Proceedings of the workshop Information Extraction meets Corpus Linguistics",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Information required for tracking bird flu outbreak over Internet",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Experimental results of relation extraction module (the legend in the figure is the number of words in each chunk)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Google Earth visualization for bird flu outbreak trackingGraph-based VisualizationThe graph-based visualization function is useful to show the global structure of topic maps and relations between different nodes in a 3D visual space. End-users can directly select the requested topics and related associations. The graph viewer provides a better global understanding of the content by exploring through graph nodes. The kind of intuitive visualization of topic maps allows browsing through allFig. 6. Graph-based visualization of topic maps about dispersion disease the topics and related relationships defined in the topic map as shown inFig. 6. The graph can be moved and restructured along its topological view according to the user's need and selections.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Fig 2. Architecture of our proposed P2P Semantic Tracking System",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Detail of four query types supported by the Knowledge Service module USING NAMESPACE ne = <http://naist.cpe.ku.ac.th/EventTracking#",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The work described in this paper has been supported by the grant of National Electronics and Computer Technology Center (NECTEC) No. NT-B-22-14-12-46-06, under the project \"A Development of Information and Knowledge Extraction from Unstructured Thai Document\".",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgement"
        }
    ]
}