{"paper_id": "0cbd4fc247be0788df0b7a38e7a1fd398932d511", "metadata": {"title": "Online COVID-19 diagnosis with chest CT images: Lesion-attention deep neural networks", "authors": [{"first": "Bin", "middle": [], "last": "Liu", "suffix": "", "affiliation": {"laboratory": "", "institution": "Southwestern University of Finance and Economics", "location": {"settlement": "Chengdu", "country": "China"}}, "email": ""}, {"first": "Xiaoxue", "middle": [], "last": "Gao", "suffix": "", "affiliation": {"laboratory": "", "institution": "Southwestern University of Finance and Economics", "location": {"settlement": "Chengdu", "country": "China"}}, "email": ""}, {"first": "Mengshuang", "middle": [], "last": "He", "suffix": "", "affiliation": {"laboratory": "", "institution": "Southwestern University of Finance and Economics", "location": {"settlement": "Chengdu", "country": "China"}}, "email": ""}, {"first": "Fengmao", "middle": [], "last": "Lv", "suffix": "", "affiliation": {"laboratory": "", "institution": "Southwestern University of Finance and Economics", "location": {"settlement": "Chengdu", "country": "China"}}, "email": ""}, {"first": "Guosheng", "middle": [], "last": "Yin", "suffix": "", "affiliation": {"laboratory": "", "institution": "The University of Hong Kong", "location": {"settlement": "Hong Kong", "country": "China"}}, "email": ""}]}, "abstract": [{"text": "Chest (computed tomography) CT scanning is one of the most important technologies for COVID-19 diagnosis in the current clinical practice, which motivates more concerted efforts in developing AI-based diagnostic tools to alleviate the enormous burden on the medical system. We develop a lesion-attention deep neural network (LA-DNN) to predict COVID-19 positive or negative with a richly annotated chest CT image dataset. The CT image dataset contains 746 public chest CT images of COVID-19 patients collected from over 760 preprints, and the data annotations are accompanied with the textual radiology reports. We extract two types of important information from these annotations: One is the flag of whether an image indicates a positive or negative case of COVID-19, and the other is the description of five lesions on the CT images associated with the positive cases. The proposed data-driven LA-DNN model focuses on the primary task of binary classification for COVID-19 diagnosis, while an auxiliary multi-label learning task is implemented simultaneously to draw the model's attention to the five lesions of COVID-19 during the training. The joint task learning process makes it a highly sample-efficient deep model that can learn COVID-19 radiology features effectively with very limited samples. The experimental results show that the area under the curve (AUC) and sensitivity (recall) for the diagnosis of COVID-19 patients are 91.2% and 85.7% respectively, which reach the clinical standards for practical use. An online system has been developed for fast online diagnoses using CT images at the web address https://www.covidct.cn/.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "The novel coronavirus disease 2019 (COVID-19) is undergoing an unprecedented global outbreak. By May 11, 2020, more than 200 countries or territories have been affected by COVID-19 with a total of more than four million confirmed cases and over 280,000 deaths. Both the numbers of confirmed cases and deaths continue climbing up quickly. The COVID-19 has been declared as an international public health emergency by the World Health Organization (WHO).", "cite_spans": [], "ref_spans": [], "section": "Background"}, {"text": "The fast increasing numbers of COVID-19 cases and deaths have made the local medical systems in many countries overburdened. The reverse-transcription polymerase chain reaction (RT-PCR) test is the current standard method for detecting the coronavirus for COVID-19 patients. However, the laboratory RT-PCR test usually takes days to deliver the final result, although more efficient tests have been developed to shorten the time of diagnosis. Many countries are experiencing a backlog of test results due to a lack of diagnostic kits at their facilities, and the test results may even take longer than anticipated because of increased demands for testing globally. Not only are these tests insufficient to meet the urgent and vast demands in many countries, but they are also inefficient as the time lag of test reporting may cause treatment delay, especially for patients with critical conditions. Moreover, the sensitivity of the current RT-PCR testing kits is low; that is, a large number of COVID-19 patients cannot be identified accurately after their first tests. As a result, it usually requires several tests to make a final confirmation. Hence, patients may not receive appropriate treatment and necessary quarantine during the RT-PCR testing period. On the other hand, chest CT scan is another critical tool for COVID-19 diagnosis. According to many existing studies [1, 3] , CT scanning serves as a important and necessary supplement for the RT-PCR test and sometimes can even outperform the laboratory test in COVID-19 diagnosis. In contrast to the RT-PCR test, the chest CT scans and the corresponding diagnostic results can be obtained in a much faster way.", "cite_spans": [{"start": 1377, "end": 1380, "text": "[1,", "ref_id": "BIBREF0"}, {"start": 1381, "end": 1383, "text": "3]", "ref_id": "BIBREF2"}], "ref_spans": [], "section": "Background"}, {"text": "To improve the efficiency of the CT-based diagnosis, automatic diagnostic systems have been developed with AI technologies by reading patients' chest CT images as inputs and then output the diagnosis reports [6, 8, 10, 12] . These AI-based methods have demonstrated very promising results on COVID-19 prediction. However, most of the existing work do not share the training data publicly except for the work of He et al. [6] , who constructed the first publicly available COVID-19 chest CT dataset by extracting the diagrams from over 760 preprints in medRxiv and bioRxiv. This public dataset contains 746 samples, among which 349 of them are COVID-19 positive and the rest 397 are negative.", "cite_spans": [{"start": 208, "end": 211, "text": "[6,", "ref_id": "BIBREF5"}, {"start": 212, "end": 214, "text": "8,", "ref_id": "BIBREF7"}, {"start": 215, "end": 218, "text": "10,", "ref_id": "BIBREF9"}, {"start": 219, "end": 222, "text": "12]", "ref_id": "BIBREF11"}, {"start": 421, "end": 424, "text": "[6]", "ref_id": "BIBREF5"}], "ref_spans": [], "section": "Background"}, {"text": "As shown in Figure 1 , the CT images in the dataset are annotated with professional textual analysis. The text reports usually narrate the results on whether the patients are COVID-19 positive or not. In addition to the flag of COVID-19, the text also contains information on lesion descriptions of COVID-19 patients. Based on our comprehensive statistical analysis over the entire text annotations, there are five different lesions associated with COVID-19, including the Groundglass opacities (GGO), Consolidation (Csld), Crazy paving appearance (CrPa), Air bronchograms (AirBr), and Interlobular septal thickening (InSepThi). Figure 1 shows that each of the confirmed COVID-19 cases is attached with one to five lesion labels. Our experiments corroborate that the auxiliary information on the CT image lesions is extremely valuable for COVID-19 diagnosis and can greatly improve the diagnostic accuracy. However, the pioneering work [6] only focused on the COVID-19 diagnosis by conducting a binary classification task on predicting the flag of COVID-19, but ignored the significant amount of information on lesion details.", "cite_spans": [{"start": 936, "end": 939, "text": "[6]", "ref_id": "BIBREF5"}], "ref_spans": [{"start": 12, "end": 20, "text": "Figure 1", "ref_id": "FIGREF1"}, {"start": 629, "end": 637, "text": "Figure 1", "ref_id": "FIGREF1"}], "section": "Background"}, {"text": "We develop a highly accurate COVID-19 diagnosis system based on both the chest CT images and the corresponding rich annotations on the five lesions. Our model is a double-task learning process which contains a primary binary classification task on the flag of COVID-19 and an auxiliary multi-label attention learning task on the five lesions. Both tasks are trained synchronously, while it shows that the auxiliary task promotes the primary task to focus its attention on the lesion areas and, as a result, the diagnostic accuracy of COVID-19 is improved drastically. Due to the incorporation of the attention mechanism through five lesions, we refer to our new model as the lesion-attention deep neural network (LA-DNN).", "cite_spans": [], "ref_spans": [], "section": "Background"}, {"text": "Experimental results demonstrate that our LA-DNN model can achieve great improvements by using the textual information. The area under the curve (AUC), recall (sensitivity), F1, and accuracy for predicting the diagnosis of COVID-19 are 91%, 86%, 85%, and 85%, respectively. These results reach the clinical standards for COVID-19 diagnosis and thus our system can be deployed for practical use to alleviate the enormous burdens of COVID-19 diagnosis [3] . The annotated lesion label file and the implementation codes can be found at https://github.com/ xiaoxuegao499/LA-DNN-for-COVID-19-diagnosis. An online system has been developed for fast online COVID-19 diagnosis using chest CT images at the web address https://www.covidct.cn/.", "cite_spans": [{"start": 450, "end": 453, "text": "[3]", "ref_id": "BIBREF2"}], "ref_spans": [], "section": "Background"}, {"text": "Our online system also welcomes medical staffs to upload their new local patients' image data to validate the diagnostic result, as well as keeping the system updated and the data shared publicly.", "cite_spans": [], "ref_spans": [], "section": "Background"}, {"text": "There have been an increasing amount of work on developing an AI-based COVID-19 diagnostic system using patients' chest CT scans [10] . Unfortunately, most of the data used in the deep learning models are not publicly available, which makes the existing models and results difficult to verify and reproduce. This situation is improved by He et al. [6] , who published the first open-access COVID-19 chest CT scans dataset.", "cite_spans": [{"start": 129, "end": 133, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 348, "end": 351, "text": "[6]", "ref_id": "BIBREF5"}], "ref_spans": [], "section": "Motivations and model"}, {"text": "In a supervised learning fashion, classification based on deep learning typically requires a relatively large number of annotated samples to train the model for accurate prediction. However, the current publicly available dataset [6] only contains no more than 800 samples. The shortage of labeled samples and the urgency for the development of automated COVID-19 diagnostic tools 2 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.", "cite_spans": [{"start": 230, "end": 233, "text": "[6]", "ref_id": "BIBREF5"}], "ref_spans": [], "section": "Motivations and model"}, {"text": "The copyright holder for this preprint this version posted May 14, 2020. . https://doi.org/10.1101/2020.05.11.20097907 doi: medRxiv preprint motivate us to derive a sample-efficient model that can integrate all sources of information for better decision making.", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "The textual annotations of the patients' chest CT scans contain two valuable tags: One is the flag of COVID-19, and the other is the reports of five lesions. In the pioneering work by He et al. [6] , they trained a binary classification model only based on the COVID-19 flag while ignoring all the lesion information. To improve the performance of diagnosis, we propose to integrate the information on the lesion descriptions into the classification of the flag of COVID-19.", "cite_spans": [{"start": 194, "end": 197, "text": "[6]", "ref_id": "BIBREF5"}], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "Similar to the work of He et al. [6] , our goal is to make accurate classification of the COVID-19 positive or negative cases. However, different from their work which focused on making a complex knowledge transfer, we aim to fully exploiting the richly annotated textual information in the data. After annotating the five-category lesions on the COVID-19 positive images, we propose an auxiliary multi-label learning model based on the summarized five different lesion labels, in addition to the primary objective of the binary classification. The auxiliary task applies multi-label learning over the five lesions annotated based on the radiology reports: Ground-glass opacities (GGO), Consolidation (Csld), Crazy paving appearance (CrPa), Air bronchograms (AirBr), and Interlobular septal thickening (InSepThi), As shown in Figure 2 , the primary and auxiliary tasks are trained synchronously. The auxiliary multi-label learning task promotes the fine-grained information on the radiology lesions to be integrated into the primary task, which makes the primary task pay more attention to the lesion areas rather than other uninteresting areas when making a final decision. This lesion-attention mechanism drastically improves the diagnostic accuracy to the level of clinical standards by human experts. Figure 2 shows the architecture of the proposed LA-DNN model. A pre-trained backbone network takes the patient's chest CT images as inputs, for which seven popular backbone networks are used in the experiments, including VGG16 [9] , ResNet18 [5] , ResNet50 [5] , DenseNet-121 [7] , DenseNet-169 [7] , EfficientNet-b0 [11] , and EfficientNet-b1 [11] . The output of the last layer of the backbone 3 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.", "cite_spans": [{"start": 33, "end": 36, "text": "[6]", "ref_id": "BIBREF5"}, {"start": 1532, "end": 1535, "text": "[9]", "ref_id": "BIBREF8"}, {"start": 1547, "end": 1550, "text": "[5]", "ref_id": "BIBREF4"}, {"start": 1562, "end": 1565, "text": "[5]", "ref_id": "BIBREF4"}, {"start": 1581, "end": 1584, "text": "[7]", "ref_id": "BIBREF6"}, {"start": 1600, "end": 1603, "text": "[7]", "ref_id": "BIBREF6"}, {"start": 1622, "end": 1626, "text": "[11]", "ref_id": "BIBREF10"}, {"start": 1649, "end": 1653, "text": "[11]", "ref_id": "BIBREF10"}], "ref_spans": [{"start": 826, "end": 834, "text": "Figure 2", "ref_id": "FIGREF2"}, {"start": 1305, "end": 1313, "text": "Figure 2", "ref_id": "FIGREF2"}], "section": "(which was not certified by peer review)"}, {"text": "The copyright holder for this preprint this version posted May 14, 2020. networks is carried forward to two branches. One is used to predict whether a patient is COVID-19 positive or not, which is the primary task. Simultaneously, the other branch aims to make a multi-label prediction on the five lesion labels. The prediction errors from both the primary task and the auxiliary multi-label task are fed back to fine-tune the backbone network.", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "We train the proposed LA-DNN model on the public dataset collected by He et al. [6] . This dataset contains 349 samples of COVID-19 positive and 397 COVID-19 negative CT scans, which are collected from 760 preprints about COVID-19 from medRxiv and bioRxiv, posted from January 19th to March 25th 2020. The negative samples include CT scans of normal individuals or contain other types of diseases. The COVID-19 positive CT images are further annotated with the corresponding radiology reports, which are textual clinical conclusions for the patients. This information is shown to be extremely valuable for the COVID-19 diagnosis. From the textual annotations, we identify and extract two types of important information:", "cite_spans": [{"start": 80, "end": 83, "text": "[6]", "ref_id": "BIBREF5"}], "ref_spans": [], "section": "COVID-19 chest CT scans"}, {"text": "\u2022 The first type of information is whether the patients are diagnosed positive or negative for COVID-19, which corresponds to the binary classification labels;", "cite_spans": [], "ref_spans": [], "section": "COVID-19 chest CT scans"}, {"text": "\u2022 The second significant but often ignored information is a common description of the five lesions associated with COVID-19. Each CT image of a confirmed patient has been identified at one to five lesions as shown in Figure 1 .", "cite_spans": [], "ref_spans": [{"start": 217, "end": 225, "text": "Figure 1", "ref_id": "FIGREF1"}], "section": "COVID-19 chest CT scans"}, {"text": "We split the dataset into a training set, a validation set, and a testing set by patients' IDs with the same ratios of 60%, 15%, 25% respectively as those in [6] . The only difference is that we need to ensure the COVID-19 patients in the training, validation, and testing sets cover all the five lesion labels, the new annotation based on radiology reports. Given the limited training samples, we first take a classical neural network that has been well pre-trained on a large dataset ImageNet [4] as a feature extraction function, and then fine-tune the weights with the COVID-19 chest CT dataset. We select seven popular architectures as the backbone networks, including VGG16 [9] , ResNet18 [5] , ResNet50 [5] , DenseNet-121 [7] , DenseNet-169 [7] , EfficientNet-b0 [11] , and EfficientNet-b1 [11] .", "cite_spans": [{"start": 158, "end": 161, "text": "[6]", "ref_id": "BIBREF5"}, {"start": 495, "end": 498, "text": "[4]", "ref_id": "BIBREF3"}, {"start": 680, "end": 683, "text": "[9]", "ref_id": "BIBREF8"}, {"start": 695, "end": 698, "text": "[5]", "ref_id": "BIBREF4"}, {"start": 710, "end": 713, "text": "[5]", "ref_id": "BIBREF4"}, {"start": 729, "end": 732, "text": "[7]", "ref_id": "BIBREF6"}, {"start": 748, "end": 751, "text": "[7]", "ref_id": "BIBREF6"}, {"start": 770, "end": 774, "text": "[11]", "ref_id": "BIBREF10"}, {"start": 797, "end": 801, "text": "[11]", "ref_id": "BIBREF10"}], "ref_spans": [], "section": "Results"}, {"text": "We take the pioneering work of He et al. [6] as the baseline for comparison. We train the baseline and the proposed LA-DNN model on the aforementioned dataset with the same data splitting strategies. The backbone networks for both the baseline and our LA-DNN are the seven classical architectures. Table 1 summarizes the overall performances of the baseline and our LA-DNN model with different settings of the backbone networks. Table 1 shows that the proposed LA-DNN model significantly improves the prediction of COVID-19 on all of the metrics, including accuracy, F1, AUC, and sensitivity.", "cite_spans": [{"start": 41, "end": 44, "text": "[6]", "ref_id": "BIBREF5"}], "ref_spans": [{"start": 298, "end": 305, "text": "Table 1", "ref_id": "TABREF1"}, {"start": 429, "end": 436, "text": "Table 1", "ref_id": "TABREF1"}], "section": "Overall performance"}, {"text": ". CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.", "cite_spans": [], "ref_spans": [], "section": "4"}, {"text": "The copyright holder for this preprint this version posted May 14, 2020. . ", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "To further assess the proposed LA-DNN model, a receiver operating characteristic (ROC) curve and a precision-recall curve are exploited to evaluate performances under different threshold values when interpreting probabilistic predictions. Figure 3 (a) exhibits the ROC curves of the baseline and our LA-DNN model by selecting the backbone network as VGG16 [9] and DenseNet169 [7] respectively. The results show that our model can predict the COVID-19 based on patients' chest CT scans with an area under the ROC curve (AUC) of 0.912 (when choosing DenseNet169 as the backbone net) and 0.898 (when choosing VGG16 as the backbone net), which demonstrate significant improvements from the corresponding AUC values of 0.874 and 0.829 from the baseline. Figure 3 (b) shows the precision-recall curves of the baseline and our LA-DNN model when choosing the VGG16 [9] and DenseNet169 [7] as the backbone networks respectively. The precision-recall curve plots the precision and the recall under different settings of the thresholds. The ideal model with a perfect prediction corresponds to the point with coordinates of (1, 1). As shown in Figure  3 (b), the curves of our LA-DNN models using the backbone nets VGG16 and DenseNet169 bow towards the point (1, 1) much closer than those of the baseline. ", "cite_spans": [{"start": 356, "end": 359, "text": "[9]", "ref_id": "BIBREF8"}, {"start": 376, "end": 379, "text": "[7]", "ref_id": "BIBREF6"}, {"start": 857, "end": 860, "text": "[9]", "ref_id": "BIBREF8"}, {"start": 877, "end": 880, "text": "[7]", "ref_id": "BIBREF6"}], "ref_spans": [{"start": 239, "end": 247, "text": "Figure 3", "ref_id": "FIGREF4"}, {"start": 749, "end": 757, "text": "Figure 3", "ref_id": "FIGREF4"}, {"start": 1133, "end": 1142, "text": "Figure  3", "ref_id": "FIGREF4"}], "section": "Curves for assessment"}, {"text": ". CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.", "cite_spans": [], "ref_spans": [], "section": "5"}, {"text": "The copyright holder for this preprint this version posted May 14, 2020. 6 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "The copyright holder for this preprint this version posted May 14, 2020. . https://doi.org/10.1101/2020.05.11.20097907 doi: medRxiv preprint 4 Analysis", "cite_spans": [], "ref_spans": [], "section": "(which was not certified by peer review)"}, {"text": "We visualize the lesion attention map (i.e., the class activation map) concerning the five lesion labels with a convolutional neural network (CNN) visualization tool, Grad-CAM++ [2] . Grad-CAM++ can localize lesions in a CT image even if there are multiple occurrences of one lesion. Subsequently, Grad-CAM++ renders a class activation map, which illustrates the importance of each pixel in a feature map towards the final classification result. The attention heat-map exhibits the pixel-wise weighting of the gradients back-propagated from the output with respect to a particular spatial position in the final convolutional feature map of the CNN. In other words, the class activation map is a saliency map indicating which areas the model has paid attention to. Figure 4 shows the class-specific attention maps for the baseline and our LA-DNN model with both choosing DenseNet169 as the backbone network. The first column represents the original COVID-19 CT images, and the lesion areas of these images are bounded with green boxes. Columns (b) and (c) in Figure 4 show the results of the baseline. In particular, column (b) is the class-specific attention map learned by the baseline. In column (c), the class attention map of the baseline is superimposed on the original images to show the activated areas. The colour of the maps from deep red to dark blue corresponds to the values of pixels' class-specific saliency from large to small. Columns (d) and (e) exhibit the results of the proposed LA-DNN model. The class-specific saliency map is a visual explanation of the lesions of COVID-19 CT scans that are predicted by the network. By comparing the results of the baseline with our model, we observe that the proposed LA-DNN model can capture almost all the salient areas for the COVID-19 prediction.", "cite_spans": [{"start": 178, "end": 181, "text": "[2]", "ref_id": "BIBREF1"}], "ref_spans": [{"start": 764, "end": 772, "text": "Figure 4", "ref_id": "FIGREF5"}, {"start": 1058, "end": 1066, "text": "Figure 4", "ref_id": "FIGREF5"}], "section": "Lesion attention map"}, {"text": "During the testing, the primary task of our LA-DNN model outputs a binary label on COVID-19 diagnosis, and meanwhile the auxiliary task outputs a five-dimensional vector to predict the five lesions. As shown in Figure 5 , we plot the numeric components of these five-dimensional vectors paired with the COVID-19 classfication labels. The paired plot creates a grid of axes for the five lesions including GGO, Csld, CrPa, AirBr and InSepThi. The diagonal figures are treated differently to show the distributions of values of each lesion from the auxiliary task. The off-diagonal axes display the distribution of each lesion over the two categories: COVID-19 or NonCOVID-19. The paired plots in Figure 5 corroborate that the three lesions of CrPa, AirBr, and InSepThi are more important than GGO and Csld in distinguishing COVID-19 from NonCOVID-19.", "cite_spans": [], "ref_spans": [{"start": 211, "end": 219, "text": "Figure 5", "ref_id": "FIGREF6"}, {"start": 694, "end": 702, "text": "Figure 5", "ref_id": "FIGREF6"}], "section": "Visualization of the primary vs. auxiliary tasks"}, {"text": "To accommodate the urgent demands for COVID-19 testing, we develop a multi-lesion attention deep neural network for automating the COVID-19 diagnosis using a richly annotated chest CT image dataset. The samples of this dataset are collected from over 760 preprinted papers. To overcome the limitation of the samples, we extract two types of supervised information from these preprinted papers: One is the flag of COVID-19, and the other is the multiple labels for the five lesions of COVID-19. The rich annotations allow us to propose a sample-efficient deep neural network to learn valuable features with a limited number of samples. The proposed highly datadriven deep model contains a primary task on the binary classification for COVID-19 and an auxiliary multi-label attention task that forces the primary task to pay attention to the five lesions of COVID-19 during the training process. The experimental results demonstrate that the proposed LA-DNN model is capable of achieving the current clinical standards for diagnostic testing and thus our system should be broadly deployed for practical use. Currently, an online version of the COVID-19 AI-diagnostic system is set up for validation and continual collection of the data. All our codes and annotated data are publicly available to help other researchers further develop better systems to conquer the COVID-19. 8 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "The copyright holder for this preprint this version posted May 14, 2020. . https://doi.org/10.1101/2020.05.11.20097907 doi: medRxiv preprint", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Correlation of chest ct and rt-pcr testing in coronavirus disease 2019 (covid-19) in china: a report of 1014 cases", "authors": [{"first": "T", "middle": [], "last": "Ai", "suffix": ""}, {"first": "Z", "middle": [], "last": "Yang", "suffix": ""}, {"first": "H", "middle": [], "last": "Hou", "suffix": ""}, {"first": "C", "middle": [], "last": "Zhan", "suffix": ""}, {"first": "C", "middle": [], "last": "Chen", "suffix": ""}, {"first": "W", "middle": [], "last": "Lv", "suffix": ""}, {"first": "Q", "middle": [], "last": "Tao", "suffix": ""}, {"first": "Z", "middle": [], "last": "Sun", "suffix": ""}, {"first": "L", "middle": [], "last": "Xia", "suffix": ""}], "year": 2020, "venue": "Radiology", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks", "authors": [{"first": "A", "middle": [], "last": "Chattopadhay", "suffix": ""}, {"first": "A", "middle": [], "last": "Sarkar", "suffix": ""}, {"first": "P", "middle": [], "last": "Howlader", "suffix": ""}, {"first": "V", "middle": ["N"], "last": "Balasubramanian", "suffix": ""}], "year": 2018, "venue": "2018 IEEE Winter Conference on Applications of Computer Vision (WACV)", "volume": "", "issn": "", "pages": "839--847", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Accuracy and reproducibility of lowdose submillisievert chest ct for the diagnosis of covid-19", "authors": [{"first": "A", "middle": [], "last": "Dangis", "suffix": ""}, {"first": "C", "middle": [], "last": "Gieraerts", "suffix": ""}, {"first": "Y", "middle": ["D"], "last": "Bruecker", "suffix": ""}, {"first": "L", "middle": [], "last": "Janssen", "suffix": ""}, {"first": "H", "middle": [], "last": "Valgaeren", "suffix": ""}, {"first": "D", "middle": [], "last": "Obbels", "suffix": ""}, {"first": "M", "middle": [], "last": "Gillis", "suffix": ""}, {"first": "M", "middle": ["V"], "last": "Ranst", "suffix": ""}, {"first": "J", "middle": [], "last": "Frans", "suffix": ""}, {"first": "A", "middle": [], "last": "Demeyere", "suffix": ""}, {"first": "R", "middle": [], "last": "Symons", "suffix": ""}], "year": 2020, "venue": "Radiology: Cardiothoracic Imaging", "volume": "2", "issn": "2", "pages": "", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Imagenet: A large-scale hierarchical image database", "authors": [{"first": "J", "middle": [], "last": "Deng", "suffix": ""}, {"first": "W", "middle": [], "last": "Dong", "suffix": ""}, {"first": "R", "middle": [], "last": "Socher", "suffix": ""}, {"first": "L.-J", "middle": [], "last": "Li", "suffix": ""}, {"first": "K", "middle": [], "last": "Li", "suffix": ""}, {"first": "L", "middle": [], "last": "Fei-Fei", "suffix": ""}], "year": 2009, "venue": "2009 IEEE conference on computer vision and pattern recognition", "volume": "", "issn": "", "pages": "248--255", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "Deep residual learning for image recognition", "authors": [{"first": "K", "middle": [], "last": "He", "suffix": ""}, {"first": "X", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "S", "middle": [], "last": "Ren", "suffix": ""}, {"first": "J", "middle": [], "last": "Sun", "suffix": ""}], "year": 2016, "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition", "volume": "", "issn": "", "pages": "770--778", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Sample-efficient deep learning for covid-19 diagnosis based on ct scans. medRxiv", "authors": [{"first": "X", "middle": [], "last": "He", "suffix": ""}, {"first": "X", "middle": [], "last": "Yang", "suffix": ""}, {"first": "S", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "J", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "Y", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "E", "middle": [], "last": "Xing", "suffix": ""}, {"first": "P", "middle": [], "last": "Xie", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "Densely connected convolutional networks", "authors": [{"first": "G", "middle": [], "last": "Huang", "suffix": ""}, {"first": "Z", "middle": [], "last": "Liu", "suffix": ""}, {"first": "L", "middle": [], "last": "Van Der Maaten", "suffix": ""}, {"first": "K", "middle": ["Q"], "last": "Weinberger", "suffix": ""}], "year": 2017, "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition", "volume": "", "issn": "", "pages": "4700--4708", "other_ids": {}}, "BIBREF7": {"ref_id": "b7", "title": "Review of artificial intelligence techniques in imaging data acquisition, segmentation and diagnosis for covid-19", "authors": [{"first": "F", "middle": [], "last": "Shi", "suffix": ""}, {"first": "J", "middle": [], "last": "Wang", "suffix": ""}, {"first": "J", "middle": [], "last": "Shi", "suffix": ""}, {"first": "Z", "middle": [], "last": "Wu", "suffix": ""}, {"first": "Q", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Z", "middle": [], "last": "Tang", "suffix": ""}, {"first": "K", "middle": [], "last": "He", "suffix": ""}, {"first": "Y", "middle": [], "last": "Shi", "suffix": ""}, {"first": "D", "middle": [], "last": "Shen", "suffix": ""}], "year": 2020, "venue": "IEEE Reviews in Biomedical Engineering", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Very deep convolutional networks for large-scale image recognition", "authors": [{"first": "K", "middle": [], "last": "Simonyan", "suffix": ""}, {"first": "A", "middle": [], "last": "Zisserman", "suffix": ""}], "year": 2014, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1409.1556"]}}, "BIBREF9": {"ref_id": "b9", "title": "Deep learning enables accurate diagnosis of novel coronavirus (covid-19) with ct images. medRxiv", "authors": [{"first": "Y", "middle": [], "last": "Song", "suffix": ""}, {"first": "S", "middle": [], "last": "Zheng", "suffix": ""}, {"first": "L", "middle": [], "last": "Li", "suffix": ""}, {"first": "X", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "X", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Z", "middle": [], "last": "Huang", "suffix": ""}, {"first": "J", "middle": [], "last": "Chen", "suffix": ""}, {"first": "H", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "Y", "middle": [], "last": "Jie", "suffix": ""}, {"first": "R", "middle": [], "last": "Wang", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "Rethinking model scaling for convolutional neural networks", "authors": [{"first": "M", "middle": [], "last": "Tan", "suffix": ""}, {"first": "Q", "middle": ["V"], "last": "Le", "suffix": ""}, {"first": "", "middle": [], "last": "Efficientnet", "suffix": ""}], "year": 2019, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1905.11946"]}}, "BIBREF11": {"ref_id": "b11", "title": "A deep learning algorithm using ct images to screen for corona virus disease", "authors": [{"first": "S", "middle": [], "last": "Wang", "suffix": ""}, {"first": "B", "middle": [], "last": "Kang", "suffix": ""}, {"first": "J", "middle": [], "last": "Ma", "suffix": ""}, {"first": "X", "middle": [], "last": "Zeng", "suffix": ""}, {"first": "M", "middle": [], "last": "Xiao", "suffix": ""}, {"first": "J", "middle": [], "last": "Guo", "suffix": ""}, {"first": "M", "middle": [], "last": "Cai", "suffix": ""}, {"first": "J", "middle": [], "last": "Yang", "suffix": ""}, {"first": "Y", "middle": [], "last": "Li", "suffix": ""}, {"first": "X", "middle": [], "last": "Meng", "suffix": ""}], "year": null, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "Middle) Example images from a 60 years old female patient with clinical and CT findings suggestive of COVID-19 infection, but with repeated negative RT-PCR analysis. Axial (A) and coronal (B) CT images show typical bilateral subpleural areas of ground-glass opacities. The patient was considered to be probably COVID-19 positive and quarantined. Note incidental finding of moderate thoracic dextroscoliosis. (Bottom) The progress of CT findings in a patient with COVID-19. On the tenth day of admission, a follow-up chest CT scan showed an increase of extent of GGO with crazy-paving appearance.", "latex": null, "type": "figure"}, "FIGREF1": {"text": "Illustration of the multi-label chest CT images collected from different online papers. All of them have been confirmed as COVID-19 positive. We highlight the six labels with different color: COVID-19 in red, Ground-glass opacitites (GGO) in blue, Consolidation (Csld) in brown, Crazy paving appearance (CrPa) in violet, Air bronchograms (AirBr) in orange, and Interlobular septal thickening (InSepThi) in magenta. Taking the CT scans of the second patient (Middle) as an example, these chest CT images have been annotated with three labels: COVID-19, GGO, and InSepThi.", "latex": null, "type": "figure"}, "FIGREF2": {"text": "The architecture of the proposed lesion-attention deep neural networks.", "latex": null, "type": "figure"}, "FIGREF3": {"text": "Precision-recall curves of the baseline and LA-DNN", "latex": null, "type": "figure"}, "FIGREF4": {"text": "Performance of our proposed LA-DNN model for COVID-19 diagnosis in comparison with the baseline.", "latex": null, "type": "figure"}, "FIGREF5": {"text": "Grad-CAM++ visualization for the baseline and our LA-DNN model with the backbone net of DenseNet-169; Column (a) represents the original CT scans; Columns (b) and (c) are the class activation maps of the baseline [6]; Columns (d) and (e) are the class activation maps of our LA-DNN model. The color from deep red to dark blue corresponds to the activation values from large to small.", "latex": null, "type": "figure"}, "FIGREF6": {"text": "Plots of the pairwise relationships among the five lesions on making the final binary classification of COVID-19.", "latex": null, "type": "figure"}, "TABREF1": {"text": "Performance comparisons between the baseline (Base) model and our lesion-attention deep neural network (LA-DNN) model on accuracy, F1, AUC, and sensitivity. Base LA-DNN Base LA-DNN Base LA-DNN Base LA-DNN", "latex": null, "type": "table", "html": "<html><body><table><tr><td>\u00a0</td><td>Accuracy </td><td>\u00a0</td><td>F1 </td><td>\u00a0</td><td>AUC </td><td>Sensitivity\n</td></tr><tr><td>\u00a0</td><td>Base </td><td>LA-DNN </td><td>Base </td><td>LA-DNN </td><td>Base </td><td>LA-DNN </td><td>Base </td><td>LA-DNN\n</td></tr><tr><td>VGG-16 </td><td>76 </td><td>83 </td><td>76 </td><td>83 </td><td>82 </td><td>90 </td><td>75 </td><td>85\n</td></tr><tr><td>ResNet-18 </td><td>74 </td><td>80 </td><td>73 </td><td>80 </td><td>82 </td><td>88 </td><td>71 </td><td>81\n</td></tr><tr><td>ResNet-50 </td><td>80 </td><td>85 </td><td>81 </td><td>83 </td><td>88 </td><td>91 </td><td>67 </td><td>79\n</td></tr><tr><td>DenseNet-121 </td><td>79 </td><td>82 </td><td>79 </td><td>81 </td><td>88 </td><td>89 </td><td>77 </td><td>80\n</td></tr><tr><td>DenseNet-169 </td><td>83 </td><td>85 </td><td>81 </td><td>85 </td><td>87 </td><td>91 </td><td>77 </td><td>86\n</td></tr><tr><td>EfficientNet-b0 </td><td>77 </td><td>84 </td><td>78 </td><td>84 </td><td>89 </td><td>90 </td><td>68 </td><td>88\n</td></tr><tr><td>EfficientNet-b1 </td><td>79 </td><td>81 </td><td>79 </td><td>80 </td><td>84 </td><td>88 </td><td>70 </td><td>78\n</td></tr></table></body></html>"}}, "back_matter": []}