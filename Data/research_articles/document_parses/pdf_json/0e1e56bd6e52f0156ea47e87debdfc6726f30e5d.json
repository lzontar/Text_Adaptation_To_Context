{"paper_id": "0e1e56bd6e52f0156ea47e87debdfc6726f30e5d", "metadata": {"title": "Fault Tolerance Patterns Mining in Dynamic Databases", "authors": [{"first": "Delvi", "middle": [], "last": "Ester", "suffix": "", "affiliation": {"laboratory": "", "institution": "National Dong Hwa University", "location": {"settlement": "Shoufeng", "country": "Taiwan, R.O.C"}}, "email": ""}, {"first": "Guanling", "middle": [], "last": "Lee", "suffix": "", "affiliation": {"laboratory": "", "institution": "National Dong Hwa University", "location": {"settlement": "Shoufeng", "country": "Taiwan, R.O.C"}}, "email": "guanling@mail.ndhu.edu.tw"}]}, "abstract": [{"text": "Mining of frequent patterns in database has been studied for several years. However, real-world data tends to be dirty and frequent pattern mining which extracts patterns that are absolutely matched is not enough. An approach, called frequent fault-tolerant pattern (FT-pattern) mining, is more suitable for extracting interesting information from real-world data that may be polluted by noise. Previous research on frequent fault-tolerant pattern mining has been widely studied. However, all of the researches focus on static database. In this paper, we propose an efficient framework to analyze the frequent FT-patterns mining in dynamic database. To avoid re-scanning the whole database, beside of keeping the fault-tolerance pattern, we will also keep the potential faulttolerance pattern that has higher possibility of becoming a fault-tolerance pattern. The experimental results show that by re-using the existing pattern that had been generated, the proposed algorithms are highly efficient in terms of execution time and maximum memory usage for mining fault-tolerance frequent pattern in dynamic database compare to FFM algorithm.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "Frequent pattern mining from a transactional datasets with support greater than a certain user defined threshold plays an important role in many data mining applications such as finding web log pattern, intrusion detection, etc. However, real-world databases contain noise that can make important information ambiguous; resulting in it will not appear in the mining result. Therefore, we need a method that copes with such variations in an association pattern (within predefined limits), which is called a fault-tolerant pattern. For example, coughing, fever, a headache, and a sore throat are all signs of catching a cold. However, these symptoms are seldom present at the same time, and hence a doctor will not diagnose the disease exactly following the rule RI: {coughing, fever, headache, sore throat} \u2192 {catch a cold}. Instead, a better rule corresponding to the real world situation would be R2: Patients who have at least three of the following symptoms {coughing, fever, headache, sore throat} are catching a cold. R2 requires matching just part of the data, which illustrates the sense of allowing for fault tolerance in data mining. [5] is the first to propose the discovering of frequent FT pattern to find frequent groups of transactions instead of just focusing on the item themselves. Unfortunately, their approach may generate sparse patterns, which may contain sub-patterns that do not appear frequently. [4] developed FT-Apriori for frequent FT-pattern mining which allows a complete set of FT-patterns to be mines out. [1] uses bit vector representation to represent data and developed a vector-based mining algorithm, VB-FT-Mine. [2] introduces the problem of mining proportional FT-pattern which number of faults tolerable in the pattern is proportional to the pattern length. Moreover, the concept and proposed methods are demonstrated in [3] for predicting epitopes of spike proteins of SARS-CoV and concludes that the patterns reported by proportional FT-patterns mining are more concise than that of fixed FT-patterns mining for this application. [6] [7]propose a proportional and fixed FT-pattern with candidate pruning that produce a better result than previous research. However, all the previous papers related to fault-tolerant are assume that the rules having been found in the datasets are valid all the time and do not change, as it consider as a static database.", "cite_spans": [{"start": 1143, "end": 1146, "text": "[5]", "ref_id": "BIBREF4"}, {"start": 1421, "end": 1424, "text": "[4]", "ref_id": "BIBREF3"}, {"start": 1537, "end": 1540, "text": "[1]", "ref_id": "BIBREF0"}, {"start": 1649, "end": 1652, "text": "[2]", "ref_id": "BIBREF1"}, {"start": 1860, "end": 1863, "text": "[3]", "ref_id": "BIBREF2"}, {"start": 2071, "end": 2074, "text": "[6]", "ref_id": "BIBREF5"}], "ref_spans": [], "section": "Introduction and Related Work"}, {"text": "Mining for association rules between items in a large database of transactions is an important database mining problem. However, all the previous researches related with fault-tolerant pattern were conducted in static database. That is, when new transactions are added or old transaction are deleted, the mining process must start all over again, without taking the advantages of previous execution and results of the mining algorithm. In this paper, we propose an efficient framework to analyze the frequent FT-patterns mining in dynamic database. This framework can solve the problems of mining patterns that tolerate fixed numbers of faults as well as to avoid re-scanning of entire database when there are new additional data or deletion of necessary transactions. The remainder of this paper is organized as follows. Section 2 introduces the problem definition and preliminaries. Section 3 describes the main idea and the proposed algorithms in detail. Section 4 discusses the experimental results and analysis. Conclusions are finally drawn in Section 5.", "cite_spans": [], "ref_spans": [], "section": "Introduction and Related Work"}, {"text": "The goal of this work is to find the frequent FT-pattern if there are new transactions coming in or any deletion in the databases without the need of re-scanning the entire database.We use the following definitions and lemmas to explain the main idea of dynamic frequent FT-pattern. Table 1 shows a transaction database TDB. Suppose that the FTsupport threshold min_sup FT = 4, the minimal item-support threshold min_sup item = 2, and the FT parameter \u03b4 = 2. For pattern P = abcde, B(P) includes transaction 10, 20, 50, 60, 70, since they all FT-contain P, we have sup FT (P) = 5. Each item of P appears in at least two transactions of B(P). Therefore, pattern P is a frequent FT-pattern and recorded as 5 | 3 4 3 4 2 (FT support | array of item support) or abcde = 5 | 3 4 3 4 2, alternatively.", "cite_spans": [], "ref_spans": [{"start": 283, "end": 290, "text": "Table 1", "ref_id": null}], "section": "Problem Definition and Analysis"}, {"text": "To avoid rescanning the whole database when data insertion and deletion, except the information of frequent fault tolerance patterns, we also record the information of potential frequent fault tolerance pattern (PFFT, in short). Following is the definition of PFFT. ", "cite_spans": [], "ref_spans": [], "section": "Problem Definition and Analysis"}, {"text": "Let \u03b1(itm) and \u03b1(FT) (0<\u03b1(itm), \u03b1(FT)<1) denote", "cite_spans": [], "ref_spans": [], "section": "Definition 2.2 (Potential Frequent Fault Tolerance patterns/PFFT)"}, {"text": "The whole process of proposed approach can be decomposed into two separate algorithms. The first algorithm, Patterns Generation (Patterns-Gen) Algorithm, is based on the main concept of Frequent Fault Tolerance Pattern mining algorithm (FFM) proposed in [6] . The major difference is that we not only mine out the FFT(D), we also record the information of PFFT(D) during the mining process. The second algorithm is the Dynamic Fault Tolerance Patterns (DFT) Algorithm. In the second algorithm, we will get all the patterns generated from FFM algorithm for both D and d + /d -, combine it, recalculating the supports and get the Final Frequent Fault Tolerance Pattern (Final FFT) and Final Potential Frequent Fault Tolerance Pattern (Final PFFT). Because of the space limitation, we only explain the second algorithm in detail in this article.", "cite_spans": [{"start": 254, "end": 257, "text": "[6]", "ref_id": "BIBREF5"}], "ref_spans": [], "section": "Dynamic Fault Tolerance Pattern Mining"}, {"text": "When new transactions are added into the original database; or current transactions being deleted, we will re-execute Pattern-Gen algorithm in order to find the FFT and PFFT from the modified database. After re-executing, we will have two sets of FFT and PFFT from D and d + /d -.In this algorithm, the mining process is decomposed into three parts. The first part is database merging, to merge the FFT and PFFT's results from both databases into combined temporary results as candidates' patterns. The second part is checking candidates' pattern. We are going to check and determine the final FFT and final PFFT based on the minimum supports. The last part is to update the current bitmap and that had being loaded from file into the memory by adding/deleting transactions from incremental database |d|. The updated bitmap is then saved back to the file for future FT-pattern mining.", "cite_spans": [], "ref_spans": [], "section": "Dynamic Fault Tolerance Pattern Mining"}, {"text": "A detailed description of DFT (Dynamic Fault Tolerance Algorithm) for mining frequent FT-pattern in adding algorithm and deleting algorithm while avoid rescanning the original/existing database is described in Figure 1 . We explain the further detail of DFT algorithm in three sub parts below.", "cite_spans": [], "ref_spans": [{"start": 210, "end": 218, "text": "Figure 1", "ref_id": "FIGREF1"}], "section": "Dynamic Fault Tolerance Pattern Mining"}, {"text": "In line 2, we read original/latest bitmap, FFT, PFFT as well as all minimum supports (min_sup FT , min_sup item , Pmin_sup item , Pmin_sup item ) from previous generated data-base. Then in lines 3 ~ 9, we merge all patterns found from each original/existing database D and incremental database |d|. The result is then saved to a temporary variable called tmp. While merging, we also update the FT support of each pattern sup FT (P) and item support for each item in each pattern sup item B(P). After merging, we re-count all minimum supports (min_sup FT , min_sup item , Pmin_sup item , Pmin_sup item ) from merging database as described in lines 10 ~ 19.", "cite_spans": [], "ref_spans": [], "section": "Merging Databases"}, {"text": "All candidates' pattern in tmp are then checked for their sup FT (P) and sup item B(P) (x) to determine whether pattern Pis still a FFT or PFFTin the modified database. After getting the pattern support, the next step is to check whether the support of pattern is complied with the minimum support. In line 21, by checking the status \" if sup FT (P) <Pmin_sup FT \", the boolean variable named is Discarded value is set to true and no further checking is required as pattern with support smaller than potential support. For the pattern whose sup FT (P) \u2265min_sup FT , we will check whether the pattern is frequent or potential FT-pattern. For each item x in pattern P, we compare item support sup item B(P)(x) with minimum support. If sup item B(P)(x) \u2265 min_sup item of each item, the pattern might be a FFT and we increase the variable countSup Itm (P) by 1; otherwise if sup item B(P)(x) \u2265 Pmin_sup item ,thenit might be a PFFT pattern, and we increase variable countPSup Item (P) by 1 (lines 22 ~ 28). At the end, described in lines 29 ~ 38, we determine whether the added pattern is truly FFT.", "cite_spans": [], "ref_spans": [], "section": "Checking Candidates' Pattern"}, {"text": "After getting the merged patterns of Final FFT and Final PFFT, we check is Discarded variable to determine whether the discarded pattern is PFFT pattern. This variable is used to comply with Lemmas 1-4. As describes in lines 39 ~ 49, we only check the patterns that is Discarded. Therefore, only small part of bitmap for pattern Pis extracted from bitmap(D). For pattern whose sup FT (P) \u2265Pmin_sup FT , we will check the possibility that the pattern will be a potential FT-pattern. After that, we compare the support count with the minimum item support. If sup item B(P) (x) \u2265 Pmin_sup item , for each item, the pattern might be a PFFT pattern and therefore we increase variable countPSup Itm (P) by 1. Finally line 51 checks whether countPSup Itm (P) \u2265 |P| , therefore we can insert pattern P to Final PFFT.", "cite_spans": [], "ref_spans": [], "section": "Checking Candidates' Pattern"}, {"text": "This section will be executed after we got all the appropriate final FFT and PFFT. Line 49 is performed to merge the bitmaps. During the bitmap updating process, for new coming transactions, we insert the data into the last row in the bitmap. And for new coming item, we create a new bitmap's column and set the entrances to 0 for the original transactions (i.e., the transactions of D). Furthermore, for those transactions which are deleted, we eliminate transactions row in the original database based on the user input.", "cite_spans": [], "ref_spans": [], "section": "Updating Bitmap"}, {"text": "Minimum item-support threshold: min_ sup item Minimum FT support threshold: min_ sup FT Minimum Potential item-support threshold: Pmin_ sup item Minimum Potential FT support threshold: Pmin_ sup FT FT parameter: \u03b4 TID from and to for transaction rows to be delete from database D Output: bitmap(D U |d|), Final FFT and Final PFFT Method: 1. Execute Patterns-Gen Algorithm for additional/delete database 2. //read latest bitmap, latest FFT, PFFT and minimum supports from files 3.", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "tmp", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "if AddingData { 5.", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "supFT(P) = supFT(P) D +supFT(P) |d| ; 6.supitemB(P) = supitemB(P) D + supitemB(P) |d| ;} 7.", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "if DeletingData { 8.", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "supFT ( if supFT(P) <Pmin_ supFT 23.", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "isDiscarded if P \u2208 FFT |d| and P \u2209 FFT |D| 41.", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "Extract bitmap(P) from bitmap(D); 42.", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "if P \u2208 FFT D and P \u2209 FFT d 43.", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "Extract bitmap(P) from bitmap(d); 44.", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "get XsupFT(P) and XsupitemB(P) from bitmap(P) ; 45.", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "supFT(P) = supFT(P) d + XsupFT(P) ; 46.", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "if supFT(P) \u2265Pmin_ supFT 47.", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "for each item count of x in P from supitemB(P) d + XsupitemB (P) ", "cite_spans": [], "ref_spans": [], "section": "Algorithm 2. (Dynamic Fault Tolerance Algorithm (DFT)) Input: additional database |d|"}, {"text": "In this section, a set of simulations were performed to show the benefit of our approach. The test data was generated by using IBM synthetic-data generator. All experiments were performed by an Intel i 5 3.2 GHz computer with 4GB of memory, running Windows 7. Table 2 lists the parameter settings for generating the test datasets and evaluating our approach with prior works. Moreover, we split the proposed DFP algorithm into two parts, data insertion and data deletion, to make an easier comparison. Figures 2 and 3 show the effects of number of distinct items in the database. Refer to figure 2, the execution times increases as the number of distinct items in the database increases for both approaches. The reason is that the larger the number of items in the database, the larger the number of patterns will be generated during the mining process which result in longer execution time. Moreover, our approach outperforms the FFM algorithm due to the reason that we need not to rescan the whole database. Figure 3 shows the memory usages for both approaches. Because we only need to check the patterns belong to \"is Discarded\" type, only a small part of bitmap is extracted from bitmap(D). Therefore, our approach outperforms the previous approach. 5 show the effects of the modification database sizes. As shown in the results, the execution times and memory usages increase as the database modification sizes increase for both approaches. Obviously, our approach outperforms the previous one due to that we avoid rescanning the whole database and only load part of the bitmap during the mining process.", "cite_spans": [], "ref_spans": [{"start": 260, "end": 267, "text": "Table 2", "ref_id": "TABREF4"}, {"start": 502, "end": 517, "text": "Figures 2 and 3", "ref_id": null}, {"start": 1010, "end": 1018, "text": "Figure 3", "ref_id": null}, {"start": 1254, "end": 1255, "text": "5", "ref_id": null}], "section": "Experimental Results"}, {"text": "In this paper, a framework is proposed to handle database updates while keeping the performance on hand. To avoid rescanning the whole database, in our approach, we generate the frequent fault tolerance patterns and potential frequent fault tolerance patterns in the original databases and re-using it by merging the patterns with the updated patterns when database is modified. The whole process of the approach can be decomposed into two separate algorithms. The first algorithm, Patterns Generation (Patterns-Gen) Algorithm, is based on the main concept of Frequent Fault Tolerance Pattern mining algorithm(FFM). And, the second algorithm is the Dynamic Fault Tolerance Patterns (DFT) Algorithm. In the second algorithm, we will get the information of the patterns generated from FFM algorithm for both D and d + /d -, combine it, recalculating the supports and get the Final Frequent Fault Tolerance Patterns and Final Potential Frequent Fault Tolerance Patterns. Experimental results show that by re-using the existing pattern that had been generated, the proposed algorithms are highly efficient in terms of execution time and maximum memory usage for mining fault-tolerance frequent pattern in dynamic database.", "cite_spans": [], "ref_spans": [], "section": "Conclusion and Future Works"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "An efficient approach for mining fault-tolerant frequent patterns based on bit vector representations", "authors": [{"first": "J.-L", "middle": [], "last": "Koh", "suffix": ""}, {"first": "P.-W", "middle": [], "last": "Yo", "suffix": ""}], "year": 2005, "venue": "DASFAA 2005", "volume": "3453", "issn": "", "pages": "568--575", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "A study on proportional fault-tolerant data mining", "authors": [{"first": "G", "middle": [], "last": "Lee", "suffix": ""}, {"first": "Y.-T", "middle": [], "last": "Lin", "suffix": ""}], "year": 2006, "venue": "Proc. of Int. Conf. Innovation in Information Technology", "volume": "", "issn": "", "pages": "1--5", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Proportional Fault-tolerant Data Mining with Applications to Bioinformatics. Special Issue of Knowledge Discovery and Management in Biomedical Information Systems with the journal of Information Systems Frontiers", "authors": [{"first": "G", "middle": [], "last": "Lee", "suffix": ""}, {"first": "S.-L", "middle": [], "last": "Peng", "suffix": ""}, {"first": "Y.-T", "middle": [], "last": "Lin", "suffix": ""}], "year": 2009, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Fault-tolerant frequent pattern mining: problems and challenges", "authors": [{"first": "J", "middle": [], "last": "Pei", "suffix": ""}, {"first": "A", "middle": ["K H"], "last": "Tung", "suffix": ""}, {"first": "J", "middle": [], "last": "Han", "suffix": ""}], "year": 2001, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "Efficient discovery of error-tolerant frequent item sets in high dimensions", "authors": [{"first": "C", "middle": [], "last": "Yang", "suffix": ""}, {"first": "U", "middle": [], "last": "Fayyad", "suffix": ""}, {"first": "P", "middle": ["S"], "last": "Bradley", "suffix": ""}], "year": 2001, "venue": "Proceedings of the Seventh ACM SIGKDD International Conference On Knowledge Discovery And Data Mining", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Mining fault-tolerant frequent patterns efficiently with powerful pruning", "authors": [{"first": "J.-J", "middle": [], "last": "Zeng", "suffix": ""}, {"first": "G", "middle": [], "last": "Lee", "suffix": ""}, {"first": "C.-C", "middle": [], "last": "Lee", "suffix": ""}], "year": 2008, "venue": "Proc. of ACM", "volume": "", "issn": "", "pages": "927--931", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "A depth-first search approach for mining proportional fault-tolerant frequent pat-terns efficiently in large database", "authors": [{"first": "C.-C", "middle": [], "last": "Tseng", "suffix": ""}, {"first": "G", "middle": [], "last": "Lee", "suffix": ""}], "year": 2015, "venue": "International Conference on Information Management", "volume": "", "issn": "", "pages": "", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "P) = supFT(P) D \u2212 supFT(P) |d| ; 9.supitemB(P) = supitemB(P) D \u2212 supitemB(P) |d| ;} 10. if Adding Data { 11. min_ sup item = min_ sup D FT + min_ sup |d| item ; 12. min_ sup FT = min_ sup D FT + min_ sup |d| FT ; 13. Pmin_ sup item = Pmin_ sup D FT + Pmin_ sup |d| item ; 14. Pmin_ sup FT = Pmin_ sup D FT + Pmin_ sup |d| FT ;} 15. if Deleting Data { 16. min_ sup item = min_ sup D FT \u2212min_ sup |d| item ; 17. min_ sup FT = min_ sup D FT \u2212min_ sup |d| FT ; 18. Pmin_ sup item = Pmin_ sup D FT \u2212Pmin_ sup |d| item ; 19. Pmin_ sup FT = Pmin_ sup D FT \u2212Pmin_ sup |d| FT ;} 20. for each pattern P in tmp { 21.", "latex": null, "type": "figure"}, "FIGREF1": {"text": "(Continued.)", "latex": null, "type": "figure"}, "TABREF0": {"text": "Table 1. An example TDB", "latex": null, "type": "table", "html": "<html><body><table><tr><td>TID </td><td>Items </td></tr><tr><td>10 </td><td>a, b, c, f c, d, e, f e, f, g e, f, h a, b, c, d a, b, d, e a, b, d e, f, g, h f, g, h, i, j j, x, y, z </td></tr><tr><td>20 </td></tr><tr><td>30 </td></tr><tr><td>40 </td></tr><tr><td>50 </td></tr><tr><td>60 </td></tr><tr><td>70 </td></tr><tr><td>80 </td></tr><tr><td>90 </td></tr><tr><td>\u00a0</td><td>100 </td></tr></table></body></html>"}, "TABREF1": {"text": "In our approach, we use D, d + and dto indicate the original, inserted and deleted databases, respectively. Moreover, we use FFT(H) and PFFT(H) to indicate the set of FFT and PFFT mined out from database H, respectively.The following lemmas show the relationship between FFT and PFFT.Lemma 1. If a pattern belongs to,and does not belong to , might belong to .", "latex": null, "type": "table"}, "TABREF3": {"text": "Merge bitmap from both DB and |d|; 54. Save bitmap, FFT, PFFT and all minimum support to file", "latex": null, "type": "table"}, "TABREF4": {"text": "Parameter Settings for FFM and DFP algorithm Fig. 2. Execution times Fig. 3. Maximum memory usagesFig. 4. Execution times Fig. 5. Maximum memory usagesvs. the modification database sizevs. the modification database size.", "latex": null, "type": "table"}}, "back_matter": []}